{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyPPkq2QyMxZpYnaxO4JOHXR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rrwiren/ilmanlaatu-ennuste-helsinki/blob/main/GRU_v4_llaj_FE_pilkottu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 0. Esitiedot ja Tavoite (GRU v4 - Laaj. FE + Soluittain) (2025-04-10 19:44)\n",
        "\"\"\"\n",
        "Otsoniennuste Helsinki - GRU-malli v4 (Laajennetulla FE:llä ja Vahvistuksilla)\n",
        "\n",
        "Tavoite:\n",
        "1. Ladata data, sisältäen pilvisyyden.\n",
        "2. Suorittaa laajennettu ominaisuusmuokkaus (FE).\n",
        "3. Määritellä ja kouluttaa GRU-malli käyttäen laajennettuja ominaisuuksia.\n",
        "4. Arvioida malli ja analysoida tulokset.\n",
        "5. Visualisoida.\n",
        "6. Toimitetaan solu kerrallaan selkeyden ja virheiden minimoimiseksi.\n",
        "\"\"\"\n",
        "print(\"--- Osa 0: Esitiedot (GRU v4) - OK ---\")"
      ],
      "metadata": {
        "id": "mu5Z3SzAz3bb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 1. Tuonnit ja Asetukset (Refaktoroitu - GRU) (2025-04-10 19:59) # Päivitetty aika\n",
        "\n",
        "# Peruskirjastot\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "import io\n",
        "import os\n",
        "import math\n",
        "import copy\n",
        "import traceback\n",
        "import warnings\n",
        "import time # <--- LISÄTTY IMPORT\n",
        "\n",
        "# Sklearn\n",
        "try:\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    from sklearn.metrics import mean_squared_error, mean_absolute_error, confusion_matrix, classification_report\n",
        "except ImportError: raise ImportError(\"scikit-learn puuttuu.\")\n",
        "\n",
        "# PyTorch\n",
        "try:\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "    import torch.optim as optim\n",
        "    from torch.utils.data import TensorDataset, DataLoader\n",
        "except ImportError: raise ImportError(\"PyTorch puuttuu.\")\n",
        "\n",
        "# Muut\n",
        "try:\n",
        "    from tqdm.notebook import tqdm\n",
        "    import seaborn as sns\n",
        "except ImportError: tqdm = None; sns = None; print(\"Tqdm/Seaborn puuttuu.\")\n",
        "\n",
        "\n",
        "# --- Yleisasetukset ---\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (14, 7)\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
        "    torch.backends.cudnn.deterministic = True; torch.backends.cudnn.benchmark = False\n",
        "print(f\"Käytettävä laite: {device}\")\n",
        "\n",
        "# --- Data-asetukset ---\n",
        "BASE_GITHUB_URL = 'https://raw.githubusercontent.com/rrwiren/ilmanlaatu-ennuste-helsinki/main/'\n",
        "PARQUET_PATH = 'data/processed/processed_Helsinki_O3_Weather_Cloudiness_2024_2025_v3.parquet'\n",
        "DATA_URL = BASE_GITHUB_URL + PARQUET_PATH\n",
        "LOCAL_DATA_PATH = 'processed_Helsinki_O3_Weather_Cloudiness_2024_2025_v3.parquet'\n",
        "TARGET_COLUMN = 'Otsoni [µg/m³]'\n",
        "BASE_COLUMNS_TO_LOAD = [\n",
        "    'Otsoni [µg/m³]', 'Lämpötilan keskiarvo [°C]', 'Keskituulen nopeus [m/s]',\n",
        "    'Ilmanpaineen keskiarvo [hPa]', 'Tuulen suunnan keskiarvo [°]', 'Pilvisyys [okta]'\n",
        "]\n",
        "\n",
        "# --- Ennustus- ja Jakoasetukset ---\n",
        "FORECAST_HORIZON = 24\n",
        "SEQUENCE_LENGTH = 72\n",
        "TEST_SPLIT_RATIO = 0.15\n",
        "VALID_SPLIT_RATIO = 0.15\n",
        "\n",
        "# --- RNN/LSTM/GRU Mallin Hyperparametrit ---\n",
        "RNN_HYPERPARAMS = {\n",
        "    'model_type': 'GRU',  # Varmistetaan GRU\n",
        "    'input_size': None,    # Lasketaan myöhemmin\n",
        "    'hidden_size': 64,\n",
        "    'num_layers': 2,\n",
        "    'output_size': FORECAST_HORIZON,\n",
        "    'dropout_prob': 0.2\n",
        "}\n",
        "\n",
        "# --- Neuroverkkojen Koulutusparametrit ---\n",
        "TRAIN_HYPERPARAMS = {\n",
        "    'batch_size': 64,\n",
        "    'learning_rate': 0.001,\n",
        "    'epochs': 75,\n",
        "    'patience': 10\n",
        "}\n",
        "\n",
        "# --- Arviointiasetukset ---\n",
        "O3_THRESHOLD_8H_AVG = 85 # µg/m³\n",
        "\n",
        "# --- Ajanotto ---\n",
        "script_start_time = time.time() # <--- LISÄTTY AJANOTON ALOITUS\n",
        "\n",
        "print(\"\\nOsa 1: Tuonnit ja Asetukset (GRU v4) - SUORITETTU ONNISTUNEESTI.\") # Päivitetty vahvistusviesti\n",
        "print(f\"Kohdemuuttuja: {TARGET_COLUMN}\")\n",
        "print(f\"Käytettävä RNN-tyyppi: {RNN_HYPERPARAMS['model_type']}\")\n",
        "print(f\"8h Keskiarvon kynnysarvo: {O3_THRESHOLD_8H_AVG} µg/m³\")"
      ],
      "metadata": {
        "id": "_hgb2MkC5x9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 2. Funktiot Datan Lataukseen ja Käsittelyyn (Laajennettu FE) (2025-04-10 19:44)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "import io\n",
        "import os\n",
        "import re\n",
        "import traceback\n",
        "# Varmistetaan tuonnit\n",
        "try: from sklearn.preprocessing import StandardScaler\n",
        "except ImportError: StandardScaler = None\n",
        "try: import seaborn as sns; import matplotlib.pyplot as plt\n",
        "except ImportError: sns = None; plt = None\n",
        "\n",
        "# --- Funktiot datan lataamiseen ---\n",
        "def download_data(url, local_path):\n",
        "    try:\n",
        "        print(f\"Yritetään ladata: {url[:60]}...\"); response = requests.get(url); response.raise_for_status()\n",
        "        target_dir = os.path.dirname(local_path);\n",
        "        if target_dir and not os.path.exists(target_dir): os.makedirs(target_dir, exist_ok=True)\n",
        "        with open(local_path, 'wb') as f: f.write(response.content)\n",
        "        print(f\"Ladattu: {local_path}\"); return True\n",
        "    except Exception as e: print(f\"Latausvirhe: {e}\"); return False\n",
        "\n",
        "def load_parquet_data(filepath_or_url, local_cache_path=\"default_cache.parquet\"):\n",
        "    filepath_to_read = None\n",
        "    if filepath_or_url.startswith('http'):\n",
        "         if os.path.exists(local_cache_path): filepath_to_read = local_cache_path; print(f\"Käytetään välimuistia: {local_cache_path}\")\n",
        "         else: filepath_to_read = local_cache_path if download_data(filepath_or_url, local_cache_path) else None\n",
        "    else: filepath_to_read = filepath_or_url\n",
        "    if not filepath_to_read or not os.path.exists(filepath_to_read): print(f\"VIRHE: Tiedostoa '{filepath_to_read}' ei löytynyt.\"); return None\n",
        "    try:\n",
        "        print(f\"Ladataan: {filepath_to_read}\"); df = pd.read_parquet(filepath_to_read); print(f\"Parquet ladattu ({df.shape})\")\n",
        "        if not isinstance(df.index, pd.DatetimeIndex): df.index = pd.to_datetime(df.index)\n",
        "        if df.index.tz is None: print(\"Asetetaan TZ=Europe/Helsinki...\"); df = df.tz_localize('Europe/Helsinki', ambiguous='NaT', nonexistent='NaT')\n",
        "        nat_rows = df.index.isnull();\n",
        "        if nat_rows.any(): print(f\"Poistetaan {nat_rows.sum()} NaT-riviä...\"); df = df[~nat_rows]\n",
        "        df.sort_index(inplace=True); print(f\"Data aikaväliltä: [{df.index.min()} - {df.index.max()}]\")\n",
        "        if df.isnull().any().any(): print(\"NaN-arvoja. Täytetään...\"); df=df.ffill().bfill(); df.dropna(inplace=True)\n",
        "        print(f\"Lopullinen ladattu muoto: {df.shape}\"); return df\n",
        "    except Exception as e: print(f\"VIRHE luvussa/käsittelyssä: {e}\"); traceback.print_exc(); return None\n",
        "\n",
        "# --- Laajennettu Feature Engineering funktio ---\n",
        "def feature_engineer_advanced_gru(df, target_column):\n",
        "    print(\"\\nSuoritetaan laajennettu FE...\"); df_eng = df.copy()\n",
        "    if not isinstance(df_eng.index, pd.DatetimeIndex): print(\"VIRHE: Indeksi ei DatetimeIndex.\"); return None\n",
        "    try: # Aika\n",
        "        df_eng['hour'] = df_eng.index.hour; df_eng['dayofweek'] = df_eng.index.dayofweek; df_eng['dayofyear'] = df_eng.index.dayofyear\n",
        "        # Korjattu: Käytä df_eng.index.dayofyear (ei Series), ja days_in_year (Series)\n",
        "        days_in_year = df_eng.index.is_leap_year.map({True: 366.0, False: 365.0})\n",
        "        df_eng['hour_sin']=np.sin(2*np.pi*df_eng['hour']/24.0); df_eng['hour_cos']=np.cos(2*np.pi*df_eng['hour']/24.0)\n",
        "        df_eng['dayofweek_sin']=np.sin(2*np.pi*df_eng['dayofweek']/7.0); df_eng['dayofweek_cos']=np.cos(2*np.pi*df_eng['dayofweek']/7.0)\n",
        "        df_eng['dayofyear_sin']=np.sin(2*np.pi*df_eng['dayofyear']/days_in_year); df_eng['dayofyear_cos']=np.cos(2*np.pi*df_eng['dayofyear']/days_in_year)\n",
        "        df_eng.drop(columns=['hour', 'dayofweek', 'dayofyear'], inplace=True); print(\"Lisätty sykliset aikaominaisuudet.\")\n",
        "    except Exception as e: print(f\"VIRHE aika FE: {e}\")\n",
        "    wind_dir_col_orig = 'Tuulen suunnan keskiarvo [°]' # Tuuli\n",
        "    if wind_dir_col_orig in df_eng.columns:\n",
        "        try:\n",
        "            wind_dir_numeric = pd.to_numeric(df_eng[wind_dir_col_orig], errors='coerce').ffill().bfill()\n",
        "            if wind_dir_numeric.notna().all():\n",
        "                 df_eng['wind_dir_sin']=np.sin(np.deg2rad(wind_dir_numeric)); df_eng['wind_dir_cos']=np.cos(np.deg2rad(wind_dir_numeric))\n",
        "                 df_eng.drop(columns=[wind_dir_col_orig], inplace=True); print(\"Muunnettu tuulen suunta sykliseksi.\")\n",
        "            else: print(f\"VAROITUS: Tuulensuuntia ei voitu muuntaa numeroksi.\")\n",
        "        except Exception as e: print(f\"VIRHE tuulensuunta FE: {e}\"); df_eng.drop(columns=['wind_dir_sin','wind_dir_cos'], inplace=True, errors='ignore')\n",
        "    else: print(f\"Saraketta '{wind_dir_col_orig}' ei löytynyt.\")\n",
        "    # Viiveet\n",
        "    lag_config = { target_column: [1, 2, 3, 6, 12, 24, 48, 72, 168], 'Lämpötilan keskiarvo [°C]': [1, 6, 24], 'Pilvisyys [okta]': [1, 6, 24], 'Keskituulen nopeus [m/s]': [1, 6, 24] }\n",
        "    print(\"Luodaan viiveitä...\"); original_cols = list(df_eng.columns); lag_cols_added = 0\n",
        "    for col, lags in lag_config.items():\n",
        "        if col in original_cols:\n",
        "            for lag in lags: df_eng[f'{col}_lag_{lag}h'] = df_eng[col].shift(lag); lag_cols_added+=1\n",
        "        else: print(f\"VAROITUS: Sarake '{col}' puuttuu viiveitä varten.\")\n",
        "    print(f\"Viiveitä lisätty ({lag_cols_added} kpl).\")\n",
        "    # Liukuvat tilastot\n",
        "    rolling_config = { target_column: [3, 6, 12, 24], 'Lämpötilan keskiarvo [°C]': [6, 24], 'Pilvisyys [okta]': [6, 24] }\n",
        "    print(\"Luodaan liukuvia tilastoja...\"); rolling_cols_added = 0\n",
        "    for col, windows in rolling_config.items():\n",
        "         if col in original_cols:\n",
        "            for window in windows:\n",
        "                 df_eng[f'{col}_roll_mean_{window}h'] = df_eng[col].rolling(window=window, min_periods=1).mean()\n",
        "                 df_eng[f'{col}_roll_std_{window}h'] = df_eng[col].rolling(window=window, min_periods=1).std()\n",
        "                 rolling_cols_added += 2\n",
        "         else: print(f\"VAROITUS: Sarake '{col}' puuttuu tilastoja varten.\")\n",
        "    print(f\"Tilastoja lisätty ({rolling_cols_added} kpl).\")\n",
        "    # Siivous\n",
        "    initial_rows = len(df_eng); df_eng.dropna(inplace=True); rows_removed = initial_rows - len(df_eng)\n",
        "    if rows_removed > 0: print(f\"\\nPoistettu {rows_removed} riviä alun NaN-arvojen vuoksi.\")\n",
        "    print(f\"\\nFE valmis. Lopullinen muoto: {df_eng.shape}\"); return df_eng\n",
        "\n",
        "def create_sequences_pytorch(features_scaled, targets_original, sequence_length, prediction_horizon):\n",
        "    X, y_orig = [], []; print(f\"\\nLuodaan sekvenssejä: seq={sequence_length}, pred={prediction_horizon}\")\n",
        "    required_len = sequence_length + prediction_horizon\n",
        "    if len(features_scaled) < required_len: print(f\"VAROITUS: Ei dataa ({len(features_scaled)}).\"); return np.array(X), np.array(y_orig)\n",
        "    if targets_original.ndim == 1: targets_original = targets_original.reshape(-1, 1)\n",
        "    for i in range(len(features_scaled) - required_len + 1): X.append(features_scaled[i:(i + sequence_length)]); y_orig.append(targets_original[i + sequence_length : i + sequence_length + prediction_horizon, 0])\n",
        "    print(f\"Luotu {len(X)} sekvenssiä.\"); X = np.array(X); y_orig = np.array(y_orig)\n",
        "    if y_orig.ndim == 2: y_orig = y_orig[..., np.newaxis]\n",
        "    elif y_orig.size > 0: print(f\"VAROITUS: y_orig muoto ({y_orig.shape}) ei odotettu.\")\n",
        "    return X, y_orig\n",
        "\n",
        "print(\"--- Osa 2: Valmis (Funktiot määritelty) ---\")"
      ],
      "metadata": {
        "id": "Kseyl-fgz40g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 2. Funktiot Datan Lataukseen ja Käsittelyyn (Laajennettu FE) (2025-04-10 19:44)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "import io\n",
        "import os\n",
        "import re\n",
        "import traceback\n",
        "# Varmistetaan tuonnit\n",
        "try: from sklearn.preprocessing import StandardScaler\n",
        "except ImportError: StandardScaler = None\n",
        "try: import seaborn as sns; import matplotlib.pyplot as plt\n",
        "except ImportError: sns = None; plt = None\n",
        "\n",
        "# --- Funktiot datan lataamiseen ---\n",
        "def download_data(url, local_path):\n",
        "    try:\n",
        "        print(f\"Yritetään ladata: {url[:60]}...\"); response = requests.get(url); response.raise_for_status()\n",
        "        target_dir = os.path.dirname(local_path);\n",
        "        if target_dir and not os.path.exists(target_dir): os.makedirs(target_dir, exist_ok=True)\n",
        "        with open(local_path, 'wb') as f: f.write(response.content)\n",
        "        print(f\"Ladattu: {local_path}\"); return True\n",
        "    except Exception as e: print(f\"Latausvirhe: {e}\"); return False\n",
        "\n",
        "def load_parquet_data(filepath_or_url, local_cache_path=\"default_cache.parquet\"):\n",
        "    filepath_to_read = None\n",
        "    if filepath_or_url.startswith('http'):\n",
        "         if os.path.exists(local_cache_path): filepath_to_read = local_cache_path; print(f\"Käytetään välimuistia: {local_cache_path}\")\n",
        "         else: filepath_to_read = local_cache_path if download_data(filepath_or_url, local_cache_path) else None\n",
        "    else: filepath_to_read = filepath_or_url\n",
        "    if not filepath_to_read or not os.path.exists(filepath_to_read): print(f\"VIRHE: Tiedostoa '{filepath_to_read}' ei löytynyt.\"); return None\n",
        "    try:\n",
        "        print(f\"Ladataan: {filepath_to_read}\"); df = pd.read_parquet(filepath_to_read); print(f\"Parquet ladattu ({df.shape})\")\n",
        "        if not isinstance(df.index, pd.DatetimeIndex): df.index = pd.to_datetime(df.index)\n",
        "        if df.index.tz is None: print(\"Asetetaan TZ=Europe/Helsinki...\"); df = df.tz_localize('Europe/Helsinki', ambiguous='NaT', nonexistent='NaT')\n",
        "        nat_rows = df.index.isnull();\n",
        "        if nat_rows.any(): print(f\"Poistetaan {nat_rows.sum()} NaT-riviä...\"); df = df[~nat_rows]\n",
        "        df.sort_index(inplace=True); print(f\"Data aikaväliltä: [{df.index.min()} - {df.index.max()}]\")\n",
        "        if df.isnull().any().any(): print(\"NaN-arvoja. Täytetään...\"); df=df.ffill().bfill(); df.dropna(inplace=True)\n",
        "        print(f\"Lopullinen ladattu muoto: {df.shape}\"); return df\n",
        "    except Exception as e: print(f\"VIRHE luvussa/käsittelyssä: {e}\"); traceback.print_exc(); return None\n",
        "\n",
        "# --- Laajennettu Feature Engineering funktio ---\n",
        "def feature_engineer_advanced_gru(df, target_column):\n",
        "    print(\"\\nSuoritetaan laajennettu FE...\"); df_eng = df.copy()\n",
        "    if not isinstance(df_eng.index, pd.DatetimeIndex): print(\"VIRHE: Indeksi ei DatetimeIndex.\"); return None\n",
        "    try: # Aika\n",
        "        df_eng['hour'] = df_eng.index.hour; df_eng['dayofweek'] = df_eng.index.dayofweek; df_eng['dayofyear'] = df_eng.index.dayofyear\n",
        "        # Korjattu: Käytä df_eng.index.dayofyear (ei Series), ja days_in_year (Series)\n",
        "        days_in_year = df_eng.index.is_leap_year.map({True: 366.0, False: 365.0})\n",
        "        df_eng['hour_sin']=np.sin(2*np.pi*df_eng['hour']/24.0); df_eng['hour_cos']=np.cos(2*np.pi*df_eng['hour']/24.0)\n",
        "        df_eng['dayofweek_sin']=np.sin(2*np.pi*df_eng['dayofweek']/7.0); df_eng['dayofweek_cos']=np.cos(2*np.pi*df_eng['dayofweek']/7.0)\n",
        "        df_eng['dayofyear_sin']=np.sin(2*np.pi*df_eng['dayofyear']/days_in_year); df_eng['dayofyear_cos']=np.cos(2*np.pi*df_eng['dayofyear']/days_in_year)\n",
        "        df_eng.drop(columns=['hour', 'dayofweek', 'dayofyear'], inplace=True); print(\"Lisätty sykliset aikaominaisuudet.\")\n",
        "    except Exception as e: print(f\"VIRHE aika FE: {e}\")\n",
        "    wind_dir_col_orig = 'Tuulen suunnan keskiarvo [°]' # Tuuli\n",
        "    if wind_dir_col_orig in df_eng.columns:\n",
        "        try:\n",
        "            wind_dir_numeric = pd.to_numeric(df_eng[wind_dir_col_orig], errors='coerce').ffill().bfill()\n",
        "            if wind_dir_numeric.notna().all():\n",
        "                 df_eng['wind_dir_sin']=np.sin(np.deg2rad(wind_dir_numeric)); df_eng['wind_dir_cos']=np.cos(np.deg2rad(wind_dir_numeric))\n",
        "                 df_eng.drop(columns=[wind_dir_col_orig], inplace=True); print(\"Muunnettu tuulen suunta sykliseksi.\")\n",
        "            else: print(f\"VAROITUS: Tuulensuuntia ei voitu muuntaa numeroksi.\")\n",
        "        except Exception as e: print(f\"VIRHE tuulensuunta FE: {e}\"); df_eng.drop(columns=['wind_dir_sin','wind_dir_cos'], inplace=True, errors='ignore')\n",
        "    else: print(f\"Saraketta '{wind_dir_col_orig}' ei löytynyt.\")\n",
        "    # Viiveet\n",
        "    lag_config = { target_column: [1, 2, 3, 6, 12, 24, 48, 72, 168], 'Lämpötilan keskiarvo [°C]': [1, 6, 24], 'Pilvisyys [okta]': [1, 6, 24], 'Keskituulen nopeus [m/s]': [1, 6, 24] }\n",
        "    print(\"Luodaan viiveitä...\"); original_cols = list(df_eng.columns); lag_cols_added = 0\n",
        "    for col, lags in lag_config.items():\n",
        "        if col in original_cols:\n",
        "            for lag in lags: df_eng[f'{col}_lag_{lag}h'] = df_eng[col].shift(lag); lag_cols_added+=1\n",
        "        else: print(f\"VAROITUS: Sarake '{col}' puuttuu viiveitä varten.\")\n",
        "    print(f\"Viiveitä lisätty ({lag_cols_added} kpl).\")\n",
        "    # Liukuvat tilastot\n",
        "    rolling_config = { target_column: [3, 6, 12, 24], 'Lämpötilan keskiarvo [°C]': [6, 24], 'Pilvisyys [okta]': [6, 24] }\n",
        "    print(\"Luodaan liukuvia tilastoja...\"); rolling_cols_added = 0\n",
        "    for col, windows in rolling_config.items():\n",
        "         if col in original_cols:\n",
        "            for window in windows:\n",
        "                 df_eng[f'{col}_roll_mean_{window}h'] = df_eng[col].rolling(window=window, min_periods=1).mean()\n",
        "                 df_eng[f'{col}_roll_std_{window}h'] = df_eng[col].rolling(window=window, min_periods=1).std()\n",
        "                 rolling_cols_added += 2\n",
        "         else: print(f\"VAROITUS: Sarake '{col}' puuttuu tilastoja varten.\")\n",
        "    print(f\"Tilastoja lisätty ({rolling_cols_added} kpl).\")\n",
        "    # Siivous\n",
        "    initial_rows = len(df_eng); df_eng.dropna(inplace=True); rows_removed = initial_rows - len(df_eng)\n",
        "    if rows_removed > 0: print(f\"\\nPoistettu {rows_removed} riviä alun NaN-arvojen vuoksi.\")\n",
        "    print(f\"\\nFE valmis. Lopullinen muoto: {df_eng.shape}\"); return df_eng\n",
        "\n",
        "def create_sequences_pytorch(features_scaled, targets_original, sequence_length, prediction_horizon):\n",
        "    X, y_orig = [], []; print(f\"\\nLuodaan sekvenssejä: seq={sequence_length}, pred={prediction_horizon}\")\n",
        "    required_len = sequence_length + prediction_horizon\n",
        "    if len(features_scaled) < required_len: print(f\"VAROITUS: Ei dataa ({len(features_scaled)}).\"); return np.array(X), np.array(y_orig)\n",
        "    if targets_original.ndim == 1: targets_original = targets_original.reshape(-1, 1)\n",
        "    for i in range(len(features_scaled) - required_len + 1): X.append(features_scaled[i:(i + sequence_length)]); y_orig.append(targets_original[i + sequence_length : i + sequence_length + prediction_horizon, 0])\n",
        "    print(f\"Luotu {len(X)} sekvenssiä.\"); X = np.array(X); y_orig = np.array(y_orig)\n",
        "    if y_orig.ndim == 2: y_orig = y_orig[..., np.newaxis]\n",
        "    elif y_orig.size > 0: print(f\"VAROITUS: y_orig muoto ({y_orig.shape}) ei odotettu.\")\n",
        "    return X, y_orig\n",
        "\n",
        "print(\"--- Osa 2: Valmis (Funktiot määritelty) ---\")"
      ],
      "metadata": {
        "id": "wT-wdtMOz5LS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 3. Pääskriptin Suoritus: Datan Käsittely (Laajennettu FE) (2025-04-10 19:44)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import traceback\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "try: import torch; from torch.utils.data import TensorDataset, DataLoader\n",
        "except ImportError: raise ImportError(\"PyTorch ei ladattu.\")\n",
        "try: from sklearn.preprocessing import StandardScaler\n",
        "except ImportError: raise ImportError(\"scikit-learn ei ladattu.\")\n",
        "\n",
        "print(\"--- Aloitetaan Datan Käsittely (Laajennettu FE) ---\")\n",
        "\n",
        "# Alustetaan muuttujat\n",
        "df_raw_full=None; df_engineered=None; train_loader=None; valid_loader=None; test_loader=None\n",
        "feature_scaler=None; o3_scaler=None; INPUT_SIZE=None; test_timestamps=None\n",
        "X_train, y_train_original, X_valid, y_valid_original, X_test, y_test_original = [None]*6\n",
        "y_train_scaled, y_valid_scaled = None, None\n",
        "data_processing_ok = False\n",
        "\n",
        "try:\n",
        "    # Varmistetaan parametrit uudelleen\n",
        "    if 'SEQUENCE_LENGTH' not in locals(): SEQUENCE_LENGTH = 72\n",
        "    if 'PREDICTION_HORIZON' not in locals(): PREDICTION_HORIZON = 24\n",
        "    if 'TARGET_COLUMN' not in locals(): TARGET_COLUMN = 'Otsoni [µg/m³]'\n",
        "    if 'BASE_COLUMNS_TO_LOAD' not in locals(): BASE_COLUMNS_TO_LOAD = ['Otsoni [µg/m³]', 'Lämpötilan keskiarvo [°C]', 'Keskituulen nopeus [m/s]', 'Ilmanpaineen keskiarvo [hPa]', 'Tuulen suunnan keskiarvo [°]', 'Pilvisyys [okta]']\n",
        "    if 'TRAIN_HYPERPARAMS' not in locals() or 'batch_size' not in TRAIN_HYPERPARAMS: TRAIN_HYPERPARAMS = {'batch_size': 64}\n",
        "    print(f\"Käytetään: SeqLen={SEQUENCE_LENGTH}, PredHoriz={PREDICTION_HORIZON}, Batch={TRAIN_HYPERPARAMS['batch_size']}\")\n",
        "\n",
        "    # 1. Lataa data\n",
        "    df_raw_full = load_parquet_data(DATA_URL, LOCAL_DATA_PATH)\n",
        "    if df_raw_full is None or df_raw_full.empty: raise ValueError(\"Datan lataus epäonnistui.\")\n",
        "\n",
        "    # 2. Korrelaatioanalyysi\n",
        "    print(\"\\n--- Korrelaatioanalyysi ---\")\n",
        "    if sns is not None and plt is not None:\n",
        "        try:\n",
        "             numeric_cols_df = df_raw_full.select_dtypes(include=np.number)\n",
        "             if TARGET_COLUMN in numeric_cols_df.columns:\n",
        "                 correlation_matrix = numeric_cols_df.corr(); plt.figure(figsize=(8, 6))\n",
        "                 sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", lw=.5, annot_kws={\"size\": 8})\n",
        "                 plt.title('Muuttujien korrelaatiot', fontsize=12); plt.xticks(fontsize=8); plt.yticks(fontsize=8); plt.show()\n",
        "                 print(f\"\\nKorrelaatiot '{TARGET_COLUMN}' kanssa:\"); print(correlation_matrix[TARGET_COLUMN].sort_values(ascending=False))\n",
        "             else: print(f\"Kohdetta '{TARGET_COLUMN}' ei löytynyt.\")\n",
        "        except Exception as e_corr: print(f\"VIRHE korrelaatioanalyysissä: {e_corr}\")\n",
        "    else: print(\"Ohitetaan korrelaatiomatriisi.\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    # 3. Laajennettu Feature Engineering\n",
        "    df_engineered = feature_engineer_advanced_gru(df_raw_full.copy(), TARGET_COLUMN) # Käytä funktiota Osasta 2\n",
        "    if df_engineered is None or df_engineered.empty: raise ValueError(\"Laajennettu FE epäonnistui.\")\n",
        "\n",
        "    # 4. Määritä INPUT_SIZE\n",
        "    FINAL_FEATURE_COLUMNS = df_engineered.columns.tolist()\n",
        "    if TARGET_COLUMN not in FINAL_FEATURE_COLUMNS: print(f\"VAROITUS: Kohde '{TARGET_COLUMN}' ei FE:n jälkeisissä ominaisuuksissa!\")\n",
        "    INPUT_SIZE = len(FINAL_FEATURE_COLUMNS)\n",
        "    if INPUT_SIZE == 0: raise ValueError(\"Ei lopullisia ominaisuuksia.\");\n",
        "    print(f\"\\nLopullinen ominaisuuksien määrä (INPUT_SIZE): {INPUT_SIZE}\") # Tulostetaan koko\n",
        "\n",
        "    # 5. Jaa data\n",
        "    n = len(df_engineered); test_split_idx=int(n*(1-TEST_SPLIT_RATIO)); valid_split_idx=int(test_split_idx*(1-VALID_SPLIT_RATIO/(1-TEST_SPLIT_RATIO)))\n",
        "    df_train=df_engineered[:valid_split_idx]; df_valid=df_engineered[valid_split_idx:test_split_idx]; df_test=df_engineered[test_split_idx:]\n",
        "    min_len_for_seq=SEQUENCE_LENGTH+PREDICTION_HORIZON\n",
        "    if len(df_train)<min_len_for_seq or len(df_valid)<min_len_for_seq or len(df_test)<min_len_for_seq: raise ValueError(\"Liian vähän dataa jaossa sekvensseille.\")\n",
        "    print(f\"\\nDatan jako (FE): Train={len(df_train)}, Valid={len(df_valid)}, Test={len(df_test)}\")\n",
        "\n",
        "    # 6. Skaalaa data\n",
        "    print(\"\\nSkaalataan...\"); feature_scaler=StandardScaler(); scaled_train_features=feature_scaler.fit_transform(df_train)\n",
        "    scaled_valid_features=feature_scaler.transform(df_valid); scaled_test_features=feature_scaler.transform(df_test)\n",
        "    print(\"Ominaisuudet skaalattu.\")\n",
        "    o3_scaler = StandardScaler(); o3_scaler.fit(df_engineered.loc[df_train.index, [TARGET_COLUMN]]); print(\"O3 skaalain sovitettu.\")\n",
        "\n",
        "    # 7. Hae alkuperäiset O3-kohdearvot\n",
        "    o3_train_targets_original=df_engineered.loc[df_train.index,[TARGET_COLUMN]].values\n",
        "    o3_valid_targets_original=df_engineered.loc[df_valid.index,[TARGET_COLUMN]].values\n",
        "    o3_test_targets_original=df_engineered.loc[df_test.index,[TARGET_COLUMN]].values\n",
        "\n",
        "    # 8. Luo sekvenssit\n",
        "    X_train,y_train_original=create_sequences_pytorch(scaled_train_features,o3_train_targets_original,SEQUENCE_LENGTH,PREDICTION_HORIZON)\n",
        "    X_valid,y_valid_original=create_sequences_pytorch(scaled_valid_features,o3_valid_targets_original,SEQUENCE_LENGTH,PREDICTION_HORIZON)\n",
        "    X_test,y_test_original=create_sequences_pytorch(scaled_test_features,o3_test_targets_original,SEQUENCE_LENGTH,PREDICTION_HORIZON)\n",
        "    if X_train.size==0 or X_valid.size==0 or X_test.size==0: raise ValueError(\"Sekvenssien luonti epäonnistui.\")\n",
        "\n",
        "    # 9. Skaalaa kohdesekvenssit\n",
        "    y_train_scaled=o3_scaler.transform(y_train_original.reshape(-1,1)).reshape(y_train_original.shape)\n",
        "    y_valid_scaled=o3_scaler.transform(y_valid_original.reshape(-1,1)).reshape(y_valid_original.shape)\n",
        "    print(\"Kohdesekvenssit skaalattu.\")\n",
        "\n",
        "    # 10. Muunna Tensoreiksi\n",
        "    print(\"\\nMuunnetaan Tensoreiksi...\"); X_train_tensor=torch.tensor(X_train,dtype=torch.float32); y_train_tensor=torch.tensor(y_train_scaled,dtype=torch.float32)\n",
        "    X_valid_tensor=torch.tensor(X_valid,dtype=torch.float32); y_valid_tensor=torch.tensor(y_valid_scaled,dtype=torch.float32)\n",
        "    X_test_tensor=torch.tensor(X_test,dtype=torch.float32); y_test_tensor_original=torch.tensor(y_test_original,dtype=torch.float32)\n",
        "    print(\"Tensorit luotu.\")\n",
        "\n",
        "    # 11. Luo DataLoaderit\n",
        "    batch_size = TRAIN_HYPERPARAMS.get('batch_size', 64)\n",
        "    train_dataset=TensorDataset(X_train_tensor,y_train_tensor); train_loader=DataLoader(train_dataset,batch_size=batch_size,shuffle=True,drop_last=True)\n",
        "    valid_dataset=TensorDataset(X_valid_tensor,y_valid_tensor); valid_loader=DataLoader(valid_dataset,batch_size=batch_size,shuffle=False)\n",
        "    test_dataset=TensorDataset(X_test_tensor,y_test_tensor_original); test_loader=DataLoader(test_dataset,batch_size=batch_size,shuffle=False)\n",
        "    print(\"DataLoaderit luotu.\")\n",
        "\n",
        "    # 12. Tallenna testiaikaleimat\n",
        "    print(\"\\nTallennetaan testiaikaleimoja...\")\n",
        "    if 'df_engineered' in locals() and not df_engineered.empty and 'df_test' in locals() and not df_test.empty and len(df_test)>=SEQUENCE_LENGTH and 'X_test' in locals() and len(X_test)>0:\n",
        "        try:\n",
        "            if df_test.index[0] in df_engineered.index:\n",
        "                 test_start_idx_loc=df_engineered.index.get_loc(df_test.index[0]); test_start_indices=test_start_idx_loc+SEQUENCE_LENGTH; end_index=test_start_indices+len(X_test)\n",
        "                 if end_index<=len(df_engineered.index): test_timestamps=df_engineered.index[test_start_indices:end_index]; print(f\"Testiaikaleimat tallennettu ({len(test_timestamps)} kpl).\")\n",
        "                 else: print(\"VAROITUS: Ei voitu määrittää aikaleimoja.\"); test_timestamps=None\n",
        "            else: print(\"VAROITUS: Testialkua ei löytynyt indeksistä.\"); test_timestamps=None\n",
        "        except Exception as e_ts: print(f\"VIRHE aikaleimoissa: {e_ts}\"); test_timestamps=None\n",
        "    else: print(\"VAROITUS: Data liian lyhyt/tyhjä aikaleimoille.\"); test_timestamps=None\n",
        "\n",
        "    print(f\"\\nLopulliset muodot:\"); print(f\"X_train: {X_train_tensor.shape}, y_train: {y_train_tensor.shape}\"); print(f\"X_valid: {X_valid_tensor.shape}, y_valid: {y_valid_tensor.shape}\"); print(f\"X_test: {X_test_tensor.shape}, y_test: {y_test_tensor_original.shape}\")\n",
        "    data_processing_ok=True\n",
        "except Exception as e: print(f\"\\n---> VIRHE DATAN KÄSITTELYSSÄ (Osa 3): {e} <---\"); traceback.print_exc(); train_loader=None;INPUT_SIZE=None; data_processing_ok=False\n",
        "\n",
        "# --- VAHVISTUSTULOSTE ---\n",
        "if data_processing_ok: print(\"\\n--- Osa 3: Valmis ---\")\n",
        "else: print(\"\\n--- Osa 3: EPÄONNISTUI ---\")"
      ],
      "metadata": {
        "id": "cmhvgwx9z5iP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 4. GRU-Mallin Määrittely (GRU v4 - Laaj. FE) (2025-04-10 19:44)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import traceback\n",
        "\n",
        "print(\"--- Määritellään GRU-malli ---\")\n",
        "\n",
        "model_definition_ok = False\n",
        "# Tarkista edellisen osan onnistuminen ja INPUT_SIZE\n",
        "if 'data_processing_ok' in locals() and data_processing_ok and 'INPUT_SIZE' in locals() and INPUT_SIZE is not None:\n",
        "    try:\n",
        "        input_size=INPUT_SIZE; hidden_size=RNN_HYPERPARAMS['hidden_size']; num_layers=RNN_HYPERPARAMS['num_layers']\n",
        "        output_size=RNN_HYPERPARAMS['output_size']; dropout_prob=RNN_HYPERPARAMS['dropout_prob']\n",
        "        print(f\"GRU-parametrit: Input={input_size}, Hidden={hidden_size}, Layers={num_layers}, Output={output_size}, Dropout={dropout_prob}\")\n",
        "        assert all(isinstance(v, int) and v > 0 for v in [input_size, hidden_size, num_layers, output_size]), \"Koot > 0\"\n",
        "        assert isinstance(dropout_prob, float) and 0.0 <= dropout_prob < 1.0, \"Dropout [0, 1)\"\n",
        "\n",
        "        class GRUModel(nn.Module):\n",
        "            def __init__(self, input_size, hidden_size, num_layers, output_size, dropout_prob):\n",
        "                super(GRUModel, self).__init__(); self.hidden_size=hidden_size; self.num_layers=num_layers\n",
        "                gru_dropout = dropout_prob if num_layers > 1 else 0.0; self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, dropout=gru_dropout)\n",
        "                self.fc = nn.Linear(hidden_size, output_size)\n",
        "            def forward(self, x): h0=torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device); out, _ = self.gru(x, h0); out=out[:, -1, :]; out=self.fc(out); return out\n",
        "        try: # Testataan alustus\n",
        "             temp_model_test = GRUModel(input_size, hidden_size, num_layers, output_size, dropout_prob)\n",
        "             print(\"GRUModel alustus OK.\"); print(temp_model_test); del temp_model_test; model_definition_ok = True\n",
        "        except Exception as e_mdl: print(f\"VIRHE GRUModel alustuksessa: {e_mdl}\"); traceback.print_exc()\n",
        "    except Exception as e_prm: print(f\"VIRHE hyperparametreissa: {e_prm}\")\n",
        "else: print(\"Ohitetaan mallin määrittely (aiempi vaihe epäonnistui).\")\n",
        "\n",
        "# --- VAHVISTUSTULOSTE ---\n",
        "if model_definition_ok: print(\"\\n--- Osa 4: Valmis ---\")\n",
        "else: print(\"\\n--- Osa 4: EPÄONNISTUI / OHITETTIIN ---\")"
      ],
      "metadata": {
        "id": "N13UNlYvz6EV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 5. Koulutusfunktion Määrittely (GRU v4 - Laaj. FE) (2025-04-10 19:44)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.notebook import tqdm # Varmista tqdm tuonti\n",
        "import copy\n",
        "import traceback\n",
        "\n",
        "print(\"--- Määritellään train_model -funktio ---\")\n",
        "training_function_ok = False\n",
        "try:\n",
        "    # Varmistetaan tarvittavat tuonnit tälle funktiolle\n",
        "    if 'DataLoader' not in globals(): raise NameError(\"DataLoader puuttuu.\")\n",
        "    if 'nn' not in globals() or 'optim' not in globals(): raise NameError(\"PyTorch moduulit puuttuvat.\")\n",
        "    if 'tqdm' not in globals() or tqdm is None: print(\"Tqdm puuttuu, käytetään perustulostusta.\"); tqdm = lambda x, **kwargs: x # Korvike jos tqdm puuttuu\n",
        "\n",
        "    def train_model(model, train_loader, valid_loader, criterion, optimizer, epochs, device, patience):\n",
        "        train_losses=[]; valid_losses=[]; best_valid_loss=float('inf'); epochs_no_improve=0; best_model_state=None\n",
        "        print(f\"\\nAloitetaan koulutus {epochs} epochilla (patience={patience})...\")\n",
        "        if not train_loader or not valid_loader or len(train_loader.dataset)==0 or len(valid_loader.dataset)==0: print(\"VIRHE: Loader/Dataset tyhjä!\"); return None,None,None\n",
        "        for epoch in tqdm(range(epochs), desc=\"Epochs\"):\n",
        "            model.train(); running_train_loss=0.0; batch_count=0\n",
        "            try:\n",
        "                for inputs, targets_scaled in train_loader:\n",
        "                    batch_count+=1; inputs, targets_scaled = inputs.to(device), targets_scaled.to(device)\n",
        "                    optimizer.zero_grad(); outputs_scaled = model(inputs)\n",
        "                    if targets_scaled.ndim==outputs_scaled.ndim+1 and targets_scaled.shape[-1]==1: targets_squeezed = targets_scaled.squeeze(-1)\n",
        "                    elif targets_scaled.shape==outputs_scaled.shape: targets_squeezed=targets_scaled\n",
        "                    else: raise RuntimeError(f\"Muotovirhe (Train E{epoch+1} B{batch_count}): Out={outputs_scaled.shape}, Target={targets_scaled.shape}\")\n",
        "                    loss = criterion(outputs_scaled, targets_squeezed); loss.backward(); optimizer.step()\n",
        "                    running_train_loss += loss.item() * inputs.size(0)\n",
        "                denominator = len(train_loader.sampler) if hasattr(train_loader,'sampler') and train_loader.drop_last else len(train_loader.dataset)\n",
        "                epoch_train_loss = running_train_loss / denominator if denominator > 0 else 0; train_losses.append(epoch_train_loss)\n",
        "            except Exception as e_tr: print(f\"\\nVIRHE koulutusloopissa (E{epoch+1}): {e_tr}\"); traceback.print_exc(); return None,train_losses,valid_losses\n",
        "            model.eval(); running_valid_loss=0.0; valid_batch_count=0\n",
        "            try:\n",
        "                with torch.no_grad():\n",
        "                    for inputs, targets_scaled in valid_loader:\n",
        "                        valid_batch_count+=1; inputs,targets_scaled=inputs.to(device),targets_scaled.to(device); outputs_scaled=model(inputs)\n",
        "                        if targets_scaled.ndim==outputs_scaled.ndim+1 and targets_scaled.shape[-1]==1: targets_squeezed=targets_scaled.squeeze(-1)\n",
        "                        elif targets_scaled.shape==outputs_scaled.shape: targets_squeezed=targets_scaled\n",
        "                        else: raise RuntimeError(f\"Muotovirhe (Valid E{epoch+1} B{valid_batch_count}): Out={outputs_scaled.shape}, Target={targets_scaled.shape}\")\n",
        "                        loss=criterion(outputs_scaled,targets_squeezed); running_valid_loss+=loss.item()*inputs.size(0)\n",
        "                epoch_valid_loss=running_valid_loss/len(valid_loader.dataset) if len(valid_loader.dataset)>0 else 0; valid_losses.append(epoch_valid_loss)\n",
        "                print(f\"Epoch {epoch+1:02d}/{epochs} Train:{epoch_train_loss:.5f} Valid:{epoch_valid_loss:.5f}\", end=\"\")\n",
        "                if epoch_valid_loss<best_valid_loss:\n",
        "                    best_valid_loss=epoch_valid_loss; epochs_no_improve=0\n",
        "                    try: best_model_state=copy.deepcopy(model.state_dict()); print(\" (Paras!)\")\n",
        "                    # *** Korjattu except-syntaksi ***\n",
        "                    except Exception as e_save_state: print(f\" (TILA EI TALLENNETTU: {e_save_state})\"); best_model_state=None\n",
        "                else: epochs_no_improve+=1; print(f\" (Ei par.{epochs_no_improve}/{patience})\")\n",
        "                if epochs_no_improve>=patience: print(\"\\nEarly stopping.\"); break\n",
        "            except Exception as e_val: print(f\"\\nVIRHE validointiloopissa (E{epoch+1}): {e_val}\"); traceback.print_exc(); return model,train_losses,valid_losses\n",
        "        if best_model_state: print(\"\\nLadataan paras malli.\"); model.load_state_dict(best_model_state)\n",
        "        elif epochs>0 and train_losses is not None : print(\"\\nEi Early Stoppingia. Käytetään viimeisintä.\")\n",
        "        else: print(\"\\nKoulutusta ei ajettu / keskeytyi.\")\n",
        "        return model, train_losses, valid_losses\n",
        "    training_function_ok = True\n",
        "except NameError as ne: print(f\"VIRHE: Tuonti puuttuu: {ne}\")\n",
        "except Exception as e_def: print(f\"VIRHE train_model määrittelyssä: {e_def}\"); traceback.print_exc()\n",
        "# --- VAHVISTUSTULOSTE ---\n",
        "if training_function_ok: print(\"\\n--- Osa 5: Valmis (Funktio määritelty) ---\")\n",
        "else: print(\"\\n--- Osa 5: EPÄONNISTUI ---\")"
      ],
      "metadata": {
        "id": "0i9hyR2Mz6Yf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 6. Mallin Koulutus (Suoritus) (GRU v4 - Laaj. FE) (2025-04-10 19:44)\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import traceback\n",
        "\n",
        "print(\"\\n--- Osa 6: Mallin Koulutus (Suoritus) ---\")\n",
        "model = None; model_gru = None; train_losses = None; valid_losses = None; training_run_ok = False\n",
        "# Tarkistetaan edellytykset huolellisemmin\n",
        "prereqs_ok_for_training = ('data_processing_ok' in locals() and data_processing_ok and\n",
        "                           'model_definition_ok' in locals() and model_definition_ok and\n",
        "                           'training_function_ok' in locals() and training_function_ok and\n",
        "                           'GRUModel' in locals() and GRUModel is not None and # Tarkista luokan olemassaolo\n",
        "                           'train_model' in locals() and train_model is not None and # Tarkista funktion olemassaolo\n",
        "                           'train_loader' in locals() and train_loader is not None and # Tarkista loaderit\n",
        "                           'valid_loader' in locals() and valid_loader is not None and\n",
        "                           'INPUT_SIZE' in locals() and INPUT_SIZE is not None) # Tarkista input size\n",
        "\n",
        "if prereqs_ok_for_training:\n",
        "    try:\n",
        "        input_size=INPUT_SIZE; hidden_size=RNN_HYPERPARAMS['hidden_size']; num_layers=RNN_HYPERPARAMS['num_layers']\n",
        "        output_size=RNN_HYPERPARAMS['output_size']; dropout_prob=RNN_HYPERPARAMS['dropout_prob']\n",
        "        learning_rate=TRAIN_HYPERPARAMS['learning_rate']; epochs=TRAIN_HYPERPARAMS['epochs']; patience=TRAIN_HYPERPARAMS['patience']\n",
        "        model=GRUModel(input_size, hidden_size, num_layers, output_size, dropout_prob).to(device) # Käytä GRUModelia\n",
        "        criterion=nn.MSELoss(); optimizer=optim.Adam(model.parameters(), lr=learning_rate)\n",
        "        print(f\"\\n--- GRU-Malli (Input={input_size}), Params: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")\n",
        "        # Kutsu koulutusfunktiota\n",
        "        model, train_losses, valid_losses = train_model(model, train_loader, valid_loader, criterion, optimizer, epochs, device, patience)\n",
        "        if model is not None and train_losses is not None and valid_losses is not None:\n",
        "            print(\"\\nKoulutus suoritettu.\"); model_gru=model; training_run_ok=True\n",
        "            if train_losses and valid_losses:\n",
        "                plt.figure(figsize=(10, 5)); plt.plot(train_losses, label='Training'); plt.plot(valid_losses, label='Validation')\n",
        "                plt.title(f'Loss (GRU v4 - Laaj. FE)'); plt.xlabel('Epoch'); plt.ylabel('Loss (MSE)')\n",
        "                try: min_loss=min(min(train_losses,default=1),min(valid_losses,default=1)); plt.yscale('log' if min_loss>1e-9 else 'linear')\n",
        "                except: plt.yscale('linear')\n",
        "                plt.legend(); plt.grid(True,alpha=0.6); plt.show()\n",
        "            else: print(\"Häviölistoja ei saatu.\")\n",
        "        else: print(\"\\nKoulutus epäonnistui.\")\n",
        "    except Exception as e_train_run: print(f\"\\nVIRHE koulutuksen ajossa: {e_train_run}\"); traceback.print_exc(); model_gru=None\n",
        "else: print(f\"\\nKoulutusta ei aloiteta, edellytykset puuttuvat.\")\n",
        "# --- VAHVISTUSTULOSTE ---\n",
        "if training_run_ok: print(\"\\n--- Osa 6: Valmis ---\")\n",
        "else: print(\"\\n--- Osa 6: EPÄONNISTUI / OHITETTIIN ---\")"
      ],
      "metadata": {
        "id": "LJXmdqgsz6o1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 7. Arviointifunktioiden Määrittely (GRU v4 - Laaj. FE) (2025-04-10 19:51) - SyntaxError Korjattu\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import traceback\n",
        "try:\n",
        "    from sklearn.metrics import mean_squared_error, mean_absolute_error, confusion_matrix, classification_report\n",
        "except ImportError:\n",
        "    raise ImportError(\"Sklearn puuttuu.\")\n",
        "try:\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "except ImportError:\n",
        "    StandardScaler = None # Estää kaatumisen, mutta arviointi epäonnistuu myöhemmin jos tätä tarvitaan\n",
        "    print(\"VAROITUS: StandardScaler tuonti epäonnistui!\")\n",
        "try:\n",
        "    import torch\n",
        "    from torch.utils.data import DataLoader\n",
        "    from tqdm.notebook import tqdm\n",
        "except ImportError:\n",
        "    raise ImportError(\"PyTorch/tqdm puuttuu.\")\n",
        "\n",
        "print(\"--- Määritellään arviointifunktiot ---\")\n",
        "evaluation_functions_ok = False\n",
        "try:\n",
        "    # *** KORJATTU calculate_baseline_persistence_pytorch FUNKTIO ***\n",
        "    def calculate_baseline_persistence_pytorch(targets_original_np, prediction_horizon):\n",
        "        \"\"\"Laskee naiivin persistenssi-baselinen PyTorch-datarakenteelle.\"\"\"\n",
        "        print(\"Lasketaan Baseline-ennuste (jakson eka arvo toistuu)...\")\n",
        "        # try: statement on nyt omalla rivillään ja seuraavat sisennetty\n",
        "        try:\n",
        "            if not isinstance(targets_original_np, np.ndarray): raise TypeError(\"Vaaditaan numpy array\")\n",
        "            # Tarkista muoto ja korjaa tarvittaessa\n",
        "            if targets_original_np.ndim != 3 or targets_original_np.shape[-1] != 1:\n",
        "                 if targets_original_np.ndim == 2 and targets_original_np.shape[1] == prediction_horizon:\n",
        "                      print(f\"Muutetaan baseline-syötteen muoto {targets_original_np.shape} -> 3D\")\n",
        "                      targets_original_np = targets_original_np[..., np.newaxis]\n",
        "                 else:\n",
        "                      raise ValueError(f\"Odotettiin (samples, {prediction_horizon}, 1), saatiin {targets_original_np.shape}\")\n",
        "\n",
        "            if targets_original_np.shape[0] == 0:\n",
        "                 print(\"Tyhjä syöte baselineen, palautetaan tyhjä.\")\n",
        "                 return np.zeros((0, prediction_horizon)) # Palauta oikea muoto\n",
        "\n",
        "            # Ota ensimmäinen arvo ja toista\n",
        "            first_vals = targets_original_np[:, 0, 0] # Muoto: (samples,)\n",
        "            first_vals_for_repeat = first_vals[:, np.newaxis] # Muoto: (samples, 1)\n",
        "            baseline_preds = np.repeat(first_vals_for_repeat, prediction_horizon, axis=1) # Muoto (samples, horizon)\n",
        "            return baseline_preds\n",
        "        except Exception as e_base:\n",
        "            print(f\"VIRHE baseline-laskennassa: {e_base}\")\n",
        "            # Yritetään palauttaa oikean muotoisia nollia\n",
        "            try:\n",
        "                # Oletetaan, että samples-määrä on ensimmäinen dimensio, jos se on olemassa\n",
        "                num_samples = targets_original_np.shape[0] if hasattr(targets_original_np, 'shape') and len(targets_original_np.shape) > 0 else 0\n",
        "                return np.zeros((num_samples, prediction_horizon))\n",
        "            except:\n",
        "                 return None # Viimeinen oljenkorsi\n",
        "\n",
        "    def evaluate_model_performance_pytorch(model, model_name, test_loader, device, o3_scaler, o3_threshold_8h, prediction_horizon):\n",
        "        \"\"\"Arvioi PyTorch-mallia testidatalla, laskee metriikat ja vertaa baselineen.\"\"\"\n",
        "        print(f\"\\n--- evaluate_model_performance_pytorch ({model_name}) alkaa ---\")\n",
        "        if model is None: print(\"Malli puuttuu.\"); return None, None\n",
        "        if test_loader is None: print(\"Testilataaja puuttuu.\"); return None, None\n",
        "        if o3_scaler is None: print(\"O3-skaalain puuttuu.\"); return None, None\n",
        "        # Varmistetaan skaalaimen tyyppi\n",
        "        if StandardScaler is not None and not isinstance(o3_scaler, StandardScaler):\n",
        "             print(\"VAROITUS: Annettu o3_scaler ei ole odotettua StandardScaler-tyyppiä.\")\n",
        "\n",
        "        model.eval(); all_preds_orig_list=[]; all_targets_orig_list=[]\n",
        "        print(\"Ennustetaan testidatalla...\");\n",
        "        try:\n",
        "            if not hasattr(test_loader, 'dataset') or len(test_loader.dataset) == 0:\n",
        "                 print(\"Testidata on tyhjä.\"); return None,None\n",
        "            with torch.no_grad():\n",
        "                for inputs, targets_original_batch in tqdm(test_loader, desc=f\"Testaus ({model_name})\"):\n",
        "                    inputs=inputs.to(device); outputs_scaled=model(inputs); preds_scaled_np=outputs_scaled.cpu().numpy()\n",
        "                    preds_reshaped=preds_scaled_np.reshape(-1,1); preds_orig_np=o3_scaler.inverse_transform(preds_reshaped).reshape(preds_scaled_np.shape)\n",
        "                    all_preds_orig_list.append(preds_orig_np); all_targets_orig_list.append(targets_original_batch.cpu().numpy())\n",
        "            print(\"Ennusteet kerätty.\");\n",
        "            if not all_preds_orig_list or not all_targets_orig_list: raise ValueError(\"Listat tyhjiä.\")\n",
        "            all_preds_orig=np.concatenate(all_preds_orig_list,axis=0); all_targets_original=np.concatenate(all_targets_orig_list,axis=0)\n",
        "            print(f\"Kerätty {all_preds_orig.shape[0]} kpl.\")\n",
        "            if all_targets_original.ndim==3 and all_targets_original.shape[-1]==1: targets_eval=all_targets_original.squeeze(-1)\n",
        "            elif all_targets_original.ndim==2: targets_eval=all_targets_original\n",
        "            else: raise ValueError(f\"Odottamaton kohdemuoto: {all_targets_original.shape}\")\n",
        "            if all_preds_orig.shape!=targets_eval.shape: raise ValueError(f\"Muodot eivät täsmää: Pred={all_preds_orig.shape}, Target={targets_eval.shape}\")\n",
        "            print(f\"Kohdemuoto {targets_eval.shape}\")\n",
        "\n",
        "            print(\"\\nLasketaan metriikat...\"); rmse_model=np.sqrt(mean_squared_error(targets_eval.ravel(),all_preds_orig.ravel())); mae_model=mean_absolute_error(targets_eval.ravel(),all_preds_orig.ravel())\n",
        "            print(f\"\\n--- {model_name} Arviointi ---\"); print(f\"RMSE: {rmse_model:.4f}\"); print(f\"MAE:  {mae_model:.4f}\")\n",
        "\n",
        "            baseline_preds=calculate_baseline_persistence_pytorch(all_targets_original,prediction_horizon); rmse_baseline,mae_baseline=None,None\n",
        "            if baseline_preds is not None and baseline_preds.shape==targets_eval.shape:\n",
        "                if np.isnan(baseline_preds).any(): print(\"VAROITUS: Baseline NaN.\"); baseline_preds=pd.DataFrame(baseline_preds).ffill().bfill().values\n",
        "                if not np.isnan(baseline_preds).any():\n",
        "                    rmse_baseline=np.sqrt(mean_squared_error(targets_eval.ravel(),baseline_preds.ravel())); mae_baseline=mean_absolute_error(targets_eval.ravel(),baseline_preds.ravel())\n",
        "                    print(f\"\\n--- Baseline Arviointi ---\"); print(f\"RMSE: {rmse_baseline:.4f}\"); print(f\"MAE:  {mae_baseline:.4f}\")\n",
        "                else: print(\"Baseline NaN.\")\n",
        "            else: print(\"Baseline epäonnistui / muoto väärä.\")\n",
        "\n",
        "            print(\"\\n--- Vertailu Baselineen ---\")\n",
        "            if rmse_model is not None and rmse_baseline is not None: print(f\"{model_name} vs Baseline RMSE: {rmse_baseline - rmse_model:+.4f} ({'Malli parempi' if (rmse_baseline - rmse_model) > 0 else 'Baseline parempi/sama'})\")\n",
        "            else: print(\"RMSE-vertailua ei voida tehdä.\")\n",
        "            if mae_model is not None and mae_baseline is not None: print(f\"{model_name} vs Baseline MAE:  {mae_baseline - mae_model:+.4f} ({'Malli parempi' if (mae_baseline - mae_model) > 0 else 'Baseline parempi/sama'})\")\n",
        "            else: print(\"MAE-vertailua ei voida tehdä.\")\n",
        "\n",
        "            warnings_actual=[]; warnings_pred=[]; n_samples_total=all_preds_orig.shape[0]\n",
        "            print(f\"\\nLasketaan 8h ka ({n_samples_total} jaksoa, kynnys={o3_threshold_8h})...\");\n",
        "            for i in range(n_samples_total):\n",
        "                actual_series=pd.Series(targets_eval[i,:]); pred_series=pd.Series(all_preds_orig[i,:])\n",
        "                actual_8h_avg=actual_series.rolling(window=8,min_periods=1).mean(); pred_8h_avg=pred_series.rolling(window=8,min_periods=1).mean()\n",
        "                warnings_actual.append(actual_8h_avg.max()>o3_threshold_8h); warnings_pred.append(pred_8h_avg.max()>o3_threshold_8h)\n",
        "            warnings_actual=np.array(warnings_actual); warnings_pred=np.array(warnings_pred); print(\"Laskenta valmis.\")\n",
        "            print(f\"\\n--- 8h Varoitus Arviointi ({model_name} - Jaksoittain) ---\"); print(f\"Todellisia (> {o3_threshold_8h}): {warnings_actual.sum()}/{n_samples_total}\"); print(f\"Ennustettuja ({model_name}): {warnings_pred.sum()}/{n_samples_total}\")\n",
        "            if warnings_actual.sum()>0 or warnings_pred.sum()>0:\n",
        "                print(\"\\nSekaannusmatriisi:\"); cm=confusion_matrix(warnings_actual,warnings_pred,labels=[False,True]); print(pd.DataFrame(cm, index=['Todellinen EI','Todellinen KYLLÄ'], columns=['Ennuste EI','Ennuste KYLLÄ']))\n",
        "                print(\"\\nLuokitteluraportti:\"); report=classification_report(warnings_actual,warnings_pred,target_names=['Ei Varoitusta','Varoitus'],labels=[False,True],zero_division=0); print(report)\n",
        "                TN,FP,FN,TP=cm.ravel(); recall=TP/(TP+FN) if (TP+FN)>0 else 0; precision=TP/(TP+FP) if (TP+FP)>0 else 0; print(f\"---> Recall: {recall:.4f}, Precision: {precision:.4f}\")\n",
        "            else: print(f\"Ei ylityksiä kynnysarvolla {o3_threshold_8h}.\")\n",
        "            print(f\"\\n--- evaluate_model_performance_pytorch ({model_name}) päättyi ---\"); return all_preds_orig, targets_eval\n",
        "        except Exception as e: print(f\"\\n-----> VIRHE evaluate_model_performance_pytorch <-----\"); traceback.print_exc(); return None,None\n",
        "    evaluation_functions_ok = True\n",
        "except NameError as ne: print(f\"VIRHE: Tuonti puuttuu: {ne}\")\n",
        "except Exception as e_def: print(f\"VIRHE arviointifunktioiden määrittelyssä: {e_def}\"); traceback.print_exc()\n",
        "# --- VAHVISTUSTULOSTE ---\n",
        "if evaluation_functions_ok: print(\"\\n--- Osa 7: Valmis (Funktiot määritelty) ---\")\n",
        "else: print(\"\\n--- Osa 7: EPÄONNISTUI ---\")"
      ],
      "metadata": {
        "id": "3Nltyhtq24K6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 8. Mallin Arviointi (Suoritus) (GRU v4 - Laaj. FE) (2025-04-10 19:44)\n",
        "\n",
        "import traceback\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "print(\"\\n--- Osa 8: Mallin Arviointi (Suoritus) ---\")\n",
        "test_preds_gru=None; test_targets_gru=None; evaluation_gru_successful=False\n",
        "# Tarkista kaikki edellytykset huolellisesti\n",
        "prereqs_ok_for_eval = ('evaluation_functions_ok' in locals() and evaluation_functions_ok and\n",
        "                       'model_gru' in locals() and model_gru is not None and\n",
        "                       'test_loader' in locals() and test_loader is not None and\n",
        "                       'o3_scaler' in locals() and o3_scaler is not None and 'device' in locals() and\n",
        "                       'O3_THRESHOLD_8H_AVG' in locals() and 'PREDICTION_HORIZON' in locals() and\n",
        "                       'evaluate_model_performance_pytorch' in locals() and evaluate_model_performance_pytorch is not None)\n",
        "\n",
        "if prereqs_ok_for_eval:\n",
        "    try:\n",
        "        print(f\"\\nKutsutaan evaluate_model_performance_pytorch GRU-mallille (kynnys={O3_THRESHOLD_8H_AVG})...\")\n",
        "        test_preds_gru, test_targets_gru = evaluate_model_performance_pytorch(\n",
        "            model_gru, \"GRU (Laaj. FE)\", test_loader, device, o3_scaler, O3_THRESHOLD_8H_AVG, PREDICTION_HORIZON\n",
        "        )\n",
        "        if test_preds_gru is not None and test_targets_gru is not None:\n",
        "            print(\"Arviointifunktion ajo suoritettu.\"); evaluation_gru_successful = True\n",
        "            print(f\"Tulosten muodot: Preds={test_preds_gru.shape}, Targets={test_targets_gru.shape}\")\n",
        "        else: print(\"\\nArviointi epäonnistui (funktio palautti None).\")\n",
        "    except Exception as e: print(f\"\\nVIRHE arvioinnin suorituksessa: {e}\"); traceback.print_exc()\n",
        "else: print(f\"\\nArviointia ei voida suorittaa, edellytykset puuttuvat.\")\n",
        "# --- VAHVISTUSTULOSTE ---\n",
        "if evaluation_gru_successful: print(\"\\n--- Osa 8: Valmis ---\")\n",
        "else: print(\"\\n--- Osa 8: EPÄONNISTUI / OHITETTIIN ---\")"
      ],
      "metadata": {
        "id": "tvefD3RA0gXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 9. Viimeisimmän Ennustejakson Huippuarvo (GRU v4 - Laaj. FE) (2025-04-10 20:14) - NameError Korjattu\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import traceback\n",
        "\n",
        "print(\"\\n--- Osa 9: Viimeisimmän Ennustejakson Huippuarvo ---\")\n",
        "latest_analysis_possible = False\n",
        "\n",
        "# Tarkista edellytykset (arvioinnin onnistuminen ja tulosmuuttujat)\n",
        "# Käytetään Osassa 8 määriteltyjä/tallennettuja tuloksia\n",
        "if 'evaluation_gru_successful' in locals() and evaluation_gru_successful and \\\n",
        "   'test_preds_gru' in locals() and isinstance(test_preds_gru, np.ndarray) and \\\n",
        "   'test_timestamps' in locals() and test_timestamps is not None:\n",
        "\n",
        "    # Varmistetaan, ettei data ole tyhjää ja pituudet täsmäävät\n",
        "    if len(test_preds_gru) > 0 and len(test_timestamps) == len(test_preds_gru):\n",
        "        latest_analysis_possible = True\n",
        "        try:\n",
        "            latest_prediction_sequence = test_preds_gru[-1] # Viimeinen 24h jakso\n",
        "            prediction_start_time = test_timestamps[-1]     # Viimeisen jakson alkuaika\n",
        "\n",
        "            # Lasketaan max_idx ja max_val\n",
        "            max_idx = np.argmax(latest_prediction_sequence) # Oikea nimi on max_idx\n",
        "            max_value = latest_prediction_sequence[max_idx]\n",
        "\n",
        "            # *** KORJAUS TÄSSÄ: Käytetään max_idx eikä max_index ***\n",
        "            time_of_max = prediction_start_time + pd.Timedelta(hours=int(max_idx))\n",
        "\n",
        "            print(f\"\\nViimeisin ennustettu 24h jakso alkaa: {prediction_start_time.strftime('%Y-%m-%d %H:%M')}\")\n",
        "            print(\"-\" * 40);\n",
        "            print(f\"Korkein ennustettu O3-arvo: {max_value:.2f} µg/m³\")\n",
        "            print(f\"Ajankohta: {time_of_max.strftime('%A, %d.%m.%Y klo %H:%M')}\") # Tulostaa esim. Maanantai, 01.01.2024 klo 15:00\n",
        "            print(\"-\" * 40)\n",
        "\n",
        "        except IndexError:\n",
        "            print(\"\\nVirhe indeksissä (todennäköisesti tyhjä data).\"); latest_analysis_possible = False\n",
        "        except Exception as e:\n",
        "            print(f\"\\nVirhe viimeisimmän jakson analyysissa: {e}\"); traceback.print_exc(); latest_analysis_possible = False\n",
        "    else:\n",
        "        print(\"\\nEi voitu analysoida: Ennusteiden tai aikaleimojen pituudet eivät täsmää tai data puuttuu.\")\n",
        "else:\n",
        "    # Tulostetaan selkeämmin, miksi ei voida analysoida\n",
        "    missing_vars_for_peak = []\n",
        "    if 'evaluation_gru_successful' not in locals() or not evaluation_gru_successful: missing_vars_for_peak.append('evaluation_gru_successful (False)')\n",
        "    if 'test_preds_gru' not in locals() or not isinstance(test_preds_gru, np.ndarray): missing_vars_for_peak.append('test_preds_gru')\n",
        "    if 'test_timestamps' not in locals() or test_timestamps is None: missing_vars_for_peak.append('test_timestamps')\n",
        "    print(f\"\\nEi voitu analysoida huippuarvoa, koska arvioinnin tuloksia tai edellytyksiä puuttuu: {missing_vars_for_peak}\")\n",
        "\n",
        "# --- VAHVISTUSTULOSTE ---\n",
        "if latest_analysis_possible:\n",
        "    print(\"\\n--- Osa 9: Valmis ---\")\n",
        "else:\n",
        "    print(\"\\n--- Osa 9: EPÄONNISTUI / OHITETTIIN ---\")"
      ],
      "metadata": {
        "id": "BOXewD3l-5oI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 10. Visualisointi (Suoritus) (GRU v4 - Laaj. FE) (2025-04-10 20:44) # Päivitetty aika\n",
        "\n",
        "import matplotlib.pyplot as plt # Varmista tuonti\n",
        "import numpy as np # Varmista tuonti\n",
        "import pandas as pd # Varmista tuonti\n",
        "import traceback\n",
        "import time # Tuodaan ajan laskentaa varten\n",
        "\n",
        "print(\"\\n--- Osa 10: Visualisointi (Suoritus) ---\")\n",
        "visualization_possible = False # Lipuke\n",
        "\n",
        "# Tarkista edellytykset: Arvioinnin onnistuminen ja tulosmuuttujien olemassaolo\n",
        "# Käytetään _gru päätteisiä muuttujia\n",
        "if 'evaluation_gru_successful' in locals() and evaluation_gru_successful and \\\n",
        "   'test_preds_gru' in locals() and isinstance(test_preds_gru, np.ndarray) and \\\n",
        "   'test_targets_gru' in locals() and isinstance(test_targets_gru, np.ndarray) and \\\n",
        "   'test_timestamps' in locals() and test_timestamps is not None:\n",
        "\n",
        "    print(\"\\nPiirretään kuvaajat...\")\n",
        "    num_test_samples = len(test_preds_gru)\n",
        "    # Varmistetaan pituudet\n",
        "    lengths_ok = (num_test_samples > 0 and\n",
        "                  test_targets_gru.shape[0] == num_test_samples and\n",
        "                  len(test_timestamps) == num_test_samples)\n",
        "\n",
        "    if lengths_ok:\n",
        "        visualization_possible = True # Merkitään onnistuneeksi tähän asti\n",
        "        # Valitaan satunnainen indeksi piirrettäväksi\n",
        "        sample_idx = np.random.randint(0, num_test_samples)\n",
        "        print(f\"\\nNäytejakso #{sample_idx}...\")\n",
        "\n",
        "        try: # --- Kuvaaja 1: Esimerkkijakson ennuste vs. Todellinen ---\n",
        "            plt.figure(figsize=(16, 7))\n",
        "            start_time = test_timestamps[sample_idx]\n",
        "            # Varmistetaan PREDICTION_HORIZON olemassaolo\n",
        "            if 'PREDICTION_HORIZON' not in locals(): PREDICTION_HORIZON=24 # Oletusarvo\n",
        "            time_axis = pd.date_range(start=start_time, periods=PREDICTION_HORIZON, freq='h')\n",
        "\n",
        "            targets_plot = test_targets_gru[sample_idx, :] # Pitäisi olla 1D (horizon,)\n",
        "            if targets_plot.ndim != 1:\n",
        "                 # Yritetään korjata, jos muoto on (horizon, 1)\n",
        "                 if targets_plot.ndim == 2 and targets_plot.shape[-1] == 1:\n",
        "                      targets_plot = targets_plot.squeeze(-1)\n",
        "                 else:\n",
        "                      raise ValueError(f\"targets_plot muoto {targets_plot.shape}, odotettiin 1D\")\n",
        "\n",
        "            plt.plot(time_axis, targets_plot, label='Todellinen O3', marker='.', alpha=0.8, color='royalblue', zorder=3)\n",
        "            plt.plot(time_axis, test_preds_gru[sample_idx, :], label='Ennuste O3 (GRU Laaj. FE)', marker='.', linestyle='--', alpha=0.8, color='darkorange', zorder=4)\n",
        "\n",
        "            try: # Liukuvat keskiarvot\n",
        "                actual_series = pd.Series(targets_plot, index=time_axis)\n",
        "                pred_series = pd.Series(test_preds_gru[sample_idx, :], index=time_axis)\n",
        "                actual_8h = actual_series.rolling(window=8, min_periods=1).mean()\n",
        "                pred_8h = pred_series.rolling(window=8, min_periods=1).mean()\n",
        "                plt.plot(time_axis, actual_8h, label='Todellinen 8h ka.', color='blue', ls='-', lw=2.5, alpha=0.5, zorder=1)\n",
        "                plt.plot(time_axis, pred_8h, label='Ennustettu 8h ka.', color='red', ls=':', lw=2.5, alpha=0.5, zorder=2)\n",
        "            except Exception as e_roll:\n",
        "                 print(f\"VAROITUS: Virhe 8h ka piirrossa: {e_roll}\")\n",
        "\n",
        "            # Varmistetaan O3_THRESHOLD_8H_AVG olemassaolo\n",
        "            if 'O3_THRESHOLD_8H_AVG' not in locals(): O3_THRESHOLD_8H_AVG = 85 # Oletusarvo\n",
        "            plt.axhline(O3_THRESHOLD_8H_AVG, color='crimson', ls='-.', lw=2, label=f'8h Kynnys ({O3_THRESHOLD_8H_AVG})', zorder=5)\n",
        "            plt.title(f'GRU (Laaj. FE) Ennuste vs Todellinen #{sample_idx} ({start_time.strftime(\"%Y-%m-%d %H:%M\")})', fontsize=14)\n",
        "            plt.xlabel('Aika', fontsize=12); plt.ylabel('O3 (µg/m³)', fontsize=12)\n",
        "            plt.legend(loc='best', fontsize=10); plt.grid(True, linestyle=':', alpha=0.6); plt.xticks(rotation=30, ha='right'); plt.tight_layout(); plt.show()\n",
        "\n",
        "        except Exception as e_fig1:\n",
        "            print(f\"VIRHE Kuvaaja 1: {e_fig1}\"); traceback.print_exc(); visualization_possible = False\n",
        "\n",
        "        try: # --- Kuvaaja 2: Hajontakuvaaja (t+1) ---\n",
        "             plt.figure(figsize=(7, 7));\n",
        "             preds_t1 = test_preds_gru[:, 0]; targets_t1 = test_targets_gru[:, 0] # Pitäisi olla 1D (samples,)\n",
        "             if targets_t1.ndim != 1 or preds_t1.ndim != 1: raise ValueError(\"Datamuodot väärin hajontakuvaajalle.\")\n",
        "\n",
        "             plt.scatter(targets_t1, preds_t1, alpha=0.3, label='Ennusteet (t+1)', s=20, edgecolors='k', lw=0.5)\n",
        "             # NaN/Inf tarkistukset\n",
        "             valid_targets=targets_t1[~np.isnan(targets_t1)&~np.isinf(targets_t1)]; valid_preds=preds_t1[~np.isnan(preds_t1)&~np.isinf(preds_t1)]\n",
        "             if len(valid_targets)>0 and len(valid_preds)>0:\n",
        "                  min_val=min(valid_targets.min(),valid_preds.min())-5; max_val=max(valid_targets.max(),valid_preds.max())+5\n",
        "                  if np.isfinite(min_val) and np.isfinite(max_val) and max_val>min_val:\n",
        "                      plt.plot([min_val,max_val],[min_val,max_val],color='red',ls='--',lw=2,label='Ihanteellinen (y=x)')\n",
        "                      plt.xlim(min_val,max_val); plt.ylim(min_val,max_val)\n",
        "                  else: print(\"VAROITUS: Ei voitu asettaa hajontakuvaajan rajoja.\")\n",
        "             else: print(\"VAROITUS: Ei validia dataa hajontakuvaajan rajoille.\")\n",
        "\n",
        "             plt.title('Hajontakuvaaja: Ennuste vs Todellinen (tunti t+1)', fontsize=14); plt.xlabel('Todellinen O3 (t+1)'); plt.ylabel('Ennustettu O3 (t+1)')\n",
        "             plt.grid(True, ls=':', alpha=0.6); plt.legend(fontsize=10); plt.gca().set_aspect('equal', adjustable='box'); plt.tight_layout(); plt.show()\n",
        "\n",
        "        except Exception as e_fig2:\n",
        "             print(f\"VIRHE Kuvaaja 2: {e_fig2}\"); traceback.print_exc(); visualization_possible = False\n",
        "    else:\n",
        "        # Jos pituudet eivät täsmänneet\n",
        "        print(\"Testidataa ei löytynyt tai pituudet eivät täsmää visualisointia varten.\")\n",
        "        visualization_possible = False\n",
        "\n",
        "else:\n",
        "    # Jos arvioinnin tuloksia tai aikaleimoja puuttui\n",
        "    missing_vars_vis = []\n",
        "    if 'evaluation_gru_successful' not in locals() or not evaluation_gru_successful: missing_vars_vis.append('evaluation_gru_successful')\n",
        "    if 'test_preds_gru' not in locals() or not isinstance(test_preds_gru, np.ndarray): missing_vars_vis.append('test_preds_gru')\n",
        "    if 'test_targets_gru' not in locals() or not isinstance(test_targets_gru, np.ndarray): missing_vars_vis.append('test_targets_gru')\n",
        "    if 'test_timestamps' not in locals() or test_timestamps is None: missing_vars_vis.append('test_timestamps')\n",
        "    print(f\"\\nVisualisointia ei suoriteta puuttuvien edellytysten vuoksi: {missing_vars_vis}\")\n",
        "    visualization_possible = False\n",
        "\n",
        "\n",
        "# --- VAHVISTUSTULOSTE ---\n",
        "if visualization_possible:\n",
        "    print(\"\\n--- Osa 10: Valmis ---\")\n",
        "else:\n",
        "    print(\"\\n--- Osa 10: EPÄONNISTUI / OHITETTIIN ---\")\n",
        "\n",
        "# --- Ajanotto (korjattu time importilla) ---\n",
        "print(f\"\\n--- Koko skriptin ajo päättyi ---\")\n",
        "script_end_time = time.time() # Nyt time on tuotu\n",
        "# Tarkistetaan onko script_start_time määritelty (pitäisi olla jos Osa 1 ajettu)\n",
        "if 'script_start_time' in locals() and script_start_time is not None:\n",
        "     try: print(f\"Kokonaisajoaika: {script_end_time - script_start_time:.2f} sekuntia.\")\n",
        "     except Exception as e_time: print(f\"Ajoajan laskenta epäonnistui: {e_time}\")\n",
        "else: print(\"Kokonaisajoaikaa ei voitu laskea (script_start_time puuttui).\")"
      ],
      "metadata": {
        "id": "fPL3fqISCBqh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}