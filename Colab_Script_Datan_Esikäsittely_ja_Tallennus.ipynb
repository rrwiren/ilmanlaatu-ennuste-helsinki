{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rrwiren/ilmanlaatu-ennuste-helsinki/blob/main/Colab_Script_Datan_Esik%C3%A4sittely_ja_Tallennus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Colab Script: Data Preprocessing and Saving\n",
        "\n",
        "Loads Kallio ozone and Kaisaniemi weather data, merges them,\n",
        "resamples to hourly frequency, interpolates missing values,\n",
        "and saves the final processed DataFrame to a Parquet file.\n",
        "\"\"\"\n",
        "\n",
        "# Kirjastojen tuonti\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "import requests\n",
        "import csv\n",
        "import traceback\n",
        "import re # Tarvitaan sarakkeiden nimien puhdistukseen, jos käytetään vanhaa funktiota\n",
        "\n",
        "# Varmista, että tarvittava kirjasto Parquet-tiedostoille on asennettu\n",
        "# Voit poistaa kommentin alta ajaaksesi asennuksen Colabissa tarvittaessa\n",
        "# !pip install pyarrow -q\n",
        "# tai\n",
        "# !pip install fastparquet -q\n",
        "\n",
        "print(\"--- Data Preprocessing and Saving Script ---\")\n",
        "\n",
        "# --- Funktiot datan lataamiseen ja peruspuhdistukseen ---\n",
        "# (Sama kuin aiemmissa skripteissä, varmistetaan että se on tässä)\n",
        "def load_and_clean_data(raw_url, data_type='weather', cols_to_keep=None):\n",
        "    \"\"\"Lataa ja esikäsittelee datan, pitäen vain tarvittavat sarakkeet.\"\"\"\n",
        "    print(f\"\\nLadataan {data_type} dataa: {raw_url}\")\n",
        "    df_local = None\n",
        "    try:\n",
        "        response = requests.get(raw_url)\n",
        "        response.raise_for_status()\n",
        "        encoding = 'utf-8' if data_type == 'weather' else 'iso-8859-1'\n",
        "        print(f\"Lukeminen CSV:stä (encoding={encoding})...\")\n",
        "        csv_content = io.StringIO(response.content.decode(encoding))\n",
        "\n",
        "        if data_type == 'ozone':\n",
        "             column_names_ozone = [\"Havaintoasema\", \"Vuosi\", \"Kuukausi\", \"Päivä\", \"Aika [Paikallinen aika]\", \"Otsoni [µg/m³]\"]\n",
        "             df_local = pd.read_csv(\n",
        "                  csv_content, sep=',', decimal=',', skiprows=1, header=None,\n",
        "                  names=column_names_ozone, quoting=csv.QUOTE_NONNUMERIC, low_memory=False\n",
        "             )\n",
        "             target_col = \"Otsoni [µg/m³]\"\n",
        "             if target_col in df_local.columns:\n",
        "                  df_local[target_col] = pd.to_numeric(df_local[target_col], errors='coerce')\n",
        "             else: raise ValueError(f\"Otsonisarake '{target_col}' ei löytynyt.\")\n",
        "\n",
        "        elif data_type == 'weather':\n",
        "            df_local = pd.read_csv(csv_content, sep=',', decimal='.', low_memory=False)\n",
        "            df_local.columns = df_local.columns.str.strip()\n",
        "            # Muunna kaikki sarakkeet numeroiksi, joita aiotaan säilyttää\n",
        "            weather_cols_to_convert = ['Lämpötilan keskiarvo [°C]', 'Keskituulen nopeus [m/s]', 'Tuulen suunnan keskiarvo [°]', 'Ilmanpaineen keskiarvo [hPa]']\n",
        "            for col in weather_cols_to_convert:\n",
        "                 if col in df_local.columns:\n",
        "                      # Varmista, että yritetään muuntaa vain ne, jotka on pyydetty säilyttämään\n",
        "                      if cols_to_keep is None or col in cols_to_keep:\n",
        "                           df_local[col] = pd.to_numeric(df_local[col], errors='coerce')\n",
        "\n",
        "        else: raise ValueError(f\"Tuntematon data_type: {data_type}\")\n",
        "\n",
        "        # Luo Timestamp\n",
        "        year_col, month_col, day_col, time_col = 'Vuosi', 'Kuukausi', 'Päivä', 'Aika [Paikallinen aika]'\n",
        "        required_dt_cols = [year_col, month_col, day_col, time_col]\n",
        "        if not all(col in df_local.columns for col in required_dt_cols):\n",
        "            raise ValueError(f\"Aikaleiman luontiin vaadittavia sarakkeita puuttuu: {required_dt_cols}\")\n",
        "\n",
        "        df_local[year_col] = pd.to_numeric(df_local[year_col], errors='coerce').astype('Int64')\n",
        "        df_local[month_col] = pd.to_numeric(df_local[month_col], errors='coerce').astype('Int64')\n",
        "        df_local[day_col] = pd.to_numeric(df_local[day_col], errors='coerce').astype('Int64')\n",
        "        if df_local[required_dt_cols].isnull().any().any():\n",
        "            df_local.dropna(subset=required_dt_cols, inplace=True)\n",
        "\n",
        "        df_local[year_col] = df_local[year_col].astype(str)\n",
        "        df_local[month_col] = df_local[month_col].astype(str).str.zfill(2)\n",
        "        df_local[day_col] = df_local[day_col].astype(str).str.zfill(2)\n",
        "        df_local[time_col] = df_local[time_col].astype(str)\n",
        "        time_str = df_local[time_col].str.replace('24:00', '00:00', regex=False)\n",
        "        datetime_str = df_local[year_col] + '-' + df_local[month_col] + '-' + df_local[day_col] + ' ' + time_str\n",
        "        df_local['Timestamp'] = pd.to_datetime(datetime_str, format='%Y-%m-%d %H:%M', errors='coerce')\n",
        "        df_local.loc[df_local[time_col] == '24:00', 'Timestamp'] += pd.Timedelta(days=1)\n",
        "\n",
        "        # Valitse vain pyydetyt sarakkeet + Timestamp\n",
        "        cols_to_select = ['Timestamp'] + (cols_to_keep if cols_to_keep else [])\n",
        "        missing_cols = [col for col in cols_to_select if col not in df_local.columns]\n",
        "        if missing_cols:\n",
        "             raise ValueError(f\"Vaadittuja sarakkeita puuttuu datasta: {missing_cols}\")\n",
        "        df_local = df_local[cols_to_select].copy()\n",
        "\n",
        "        # Poista rivit, joissa Timestamp tai jokin säilytettävä sarake on NaN\n",
        "        df_local.dropna(subset=['Timestamp'] + (cols_to_keep if cols_to_keep else []), inplace=True)\n",
        "\n",
        "        # Aseta indeksi ja poista duplikaatit\n",
        "        df_local.set_index('Timestamp', inplace=True)\n",
        "        df_local.sort_index(inplace=True)\n",
        "        duplicates = df_local.index.duplicated(keep='first')\n",
        "        if duplicates.sum() > 0:\n",
        "            df_local = df_local[~duplicates]\n",
        "\n",
        "        print(f\"Datan ({data_type}) käsittely valmis, muoto: {df_local.shape}\")\n",
        "        if df_local.empty: print(f\"VAROITUS: {data_type} DataFrame on tyhjä!\")\n",
        "        return df_local\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Virhe datan haussa URL:sta ({data_type}): {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Virhe datan käsittelyssä ({data_type}): {e}\")\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "# --- Pääohjelma ---\n",
        "try:\n",
        "    # 1. Lataa datat\n",
        "    ozone_url = \"https://raw.githubusercontent.com/rrwiren/ilmanlaatu-ennuste-helsinki/main/data/raw/Helsinki%20Kallio%202_%201.4.2020%20-%201.4.2025_f5d0d5ac-9f7d-4833-a70b-c1afe4dc935a.csv\"\n",
        "    weather_url = \"https://raw.githubusercontent.com/rrwiren/ilmanlaatu-ennuste-helsinki/main/data/raw/Helsinki%20Kaisaniemi_%201.4.2020%20-%201.4.2025_d5590617-bf91-46c7-96f4-1fb70892265d.csv\"\n",
        "    o3_col = \"Otsoni [µg/m³]\"\n",
        "    # Otetaan kaikki relevantit säämuuttujat mukaan prosessoituun dataan\n",
        "    weather_cols = ['Lämpötilan keskiarvo [°C]', 'Keskituulen nopeus [m/s]', 'Ilmanpaineen keskiarvo [hPa]', 'Tuulen suunnan keskiarvo [°]']\n",
        "\n",
        "    df_ozone = load_and_clean_data(ozone_url, data_type='ozone', cols_to_keep=[o3_col])\n",
        "    df_weather = load_and_clean_data(weather_url, data_type='weather', cols_to_keep=weather_cols)\n",
        "\n",
        "    # 2. Yhdistä ja Resample\n",
        "    df_processed = None # Alustus\n",
        "    if df_ozone is not None and not df_ozone.empty and df_weather is not None and not df_weather.empty:\n",
        "        print(\"\\nYhdistetään otsoni- ja säädata...\")\n",
        "        df_merged_raw = pd.merge(df_ozone, df_weather, left_index=True, right_index=True, how='inner')\n",
        "        df_merged_raw.dropna(inplace=True) # Poista rivit joissa NaN jossain sarakkeessa\n",
        "        print(f\"Yhdistetty data, rivejä NaN-poiston jälkeen: {len(df_merged_raw)}\")\n",
        "\n",
        "        if not df_merged_raw.empty:\n",
        "            print(\"Uudelleenotanta ('resample') tunneittaiseen taajuuteen...\")\n",
        "            df_processed = df_merged_raw.resample('h').mean()\n",
        "            print(f\"Rivejä resamplen jälkeen: {len(df_processed)}\")\n",
        "\n",
        "            # Käsittele resamplen luomat NaN-arvot\n",
        "            nan_after_resample = df_processed.isnull().sum().sum()\n",
        "            if nan_after_resample > 0:\n",
        "                print(f\"Löytyi {nan_after_resample} NaN-arvoa resamplen jälkeen. Interpoloidaan (time)...\")\n",
        "                df_processed.interpolate(method='time', inplace=True)\n",
        "                # Täytä mahdolliset alku-/loppu-NaN:t\n",
        "                remaining_nan = df_processed.isnull().sum().sum()\n",
        "                if remaining_nan > 0:\n",
        "                     print(f\"Varoitus: Jäljellä {remaining_nan} NaN-arvoa interpoloinnin jälkeen. Täytetään (ffill/bfill)...\")\n",
        "                     df_processed.fillna(method='ffill', inplace=True)\n",
        "                     df_processed.fillna(method='bfill', inplace=True)\n",
        "            # Viimeinen tarkistus ja mahdollisten jäljelle jääneiden NaN-rivien poisto\n",
        "            if df_processed.isnull().any().any():\n",
        "                 print(\"VAROITUS: NaN-arvoja jäi datan käsittelyn jälkeen! Poistetaan rivit.\")\n",
        "                 df_processed.dropna(inplace=True)\n",
        "\n",
        "            if df_processed.empty:\n",
        "                print(\"Virhe: Data tyhjä resamplen/NaN-käsittelyn jälkeen.\")\n",
        "                df_processed = None\n",
        "            else:\n",
        "                print(\"Datan yhdistäminen ja resample onnistui.\")\n",
        "                print(\"\\nLopullisen prosessoidun datan info:\")\n",
        "                df_processed.info()\n",
        "                print(\"\\nLopullisen prosessoidun datan 5 ensimmäistä riviä:\")\n",
        "                print(df_processed.head())\n",
        "        else:\n",
        "            print(\"Virhe: Yhdistetty data tyhjä ennen resamplea.\")\n",
        "            df_processed = None\n",
        "\n",
        "    # 3. Tallenna prosessoitu data\n",
        "    if df_processed is not None and not df_processed.empty:\n",
        "        save_filename = 'processed_hourly_ozone_weather_data.parquet'\n",
        "        # save_filename_csv = 'processed_hourly_ozone_weather_data.csv' # Vaihtoehtoinen CSV\n",
        "\n",
        "        print(f\"\\nTallennetaan prosessoitu data tiedostoon: {save_filename}\")\n",
        "        try:\n",
        "            # Käytä index=True säilyttääksesi DatetimeIndexin\n",
        "            df_processed.to_parquet(save_filename, index=True)\n",
        "            print(\"Tallennus Parquet-muotoon onnistui.\")\n",
        "            # Voit tallentaa myös CSV:ksi:\n",
        "            # df_processed.to_csv(save_filename_csv, index=True)\n",
        "            # print(\"Tallennus CSV-muotoon onnistui.\")\n",
        "\n",
        "            print(\"\\nVoit nyt ladata tämän tiedoston Colabista tai käyttää sitä suoraan\")\n",
        "            print(\"seuraavissa mallinnusscripteissä lukemalla sen esim:\")\n",
        "            print(\"`df = pd.read_parquet('processed_hourly_ozone_weather_data.parquet')`\")\n",
        "\n",
        "        except ImportError:\n",
        "             print(\"\\nVirhe: Parquet-tallennus vaatii 'pyarrow' tai 'fastparquet' kirjaston.\")\n",
        "             print(\"Asenna se Colabissa komennolla: !pip install pyarrow\")\n",
        "        except Exception as e_save:\n",
        "            print(f\"Virhe tiedoston tallennuksessa: {e_save}\")\n",
        "            traceback.print_exc()\n",
        "    else:\n",
        "        print(\"\\nProsessoitu data on tyhjä tai sitä ei luotu, mitään ei tallennettu.\")\n",
        "\n",
        "\n",
        "except Exception as e_main:\n",
        "    print(f\"\\nSkriptin suorituksessa tapahtui odottamaton virhe: {e_main}\")\n",
        "    traceback.print_exc()\n",
        "\n",
        "print(\"\\n--- Esikäsittelyskripti päättyi ---\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Data Preprocessing and Saving Script ---\n",
            "\n",
            "Ladataan ozone dataa: https://raw.githubusercontent.com/rrwiren/ilmanlaatu-ennuste-helsinki/main/data/raw/Helsinki%20Kallio%202_%201.4.2020%20-%201.4.2025_f5d0d5ac-9f7d-4833-a70b-c1afe4dc935a.csv\n",
            "Lukeminen CSV:stä (encoding=iso-8859-1)...\n",
            "Datan (ozone) käsittely valmis, muoto: (43180, 1)\n",
            "\n",
            "Ladataan weather dataa: https://raw.githubusercontent.com/rrwiren/ilmanlaatu-ennuste-helsinki/main/data/raw/Helsinki%20Kaisaniemi_%201.4.2020%20-%201.4.2025_d5590617-bf91-46c7-96f4-1fb70892265d.csv\n",
            "Lukeminen CSV:stä (encoding=utf-8)...\n",
            "Datan (weather) käsittely valmis, muoto: (43455, 4)\n",
            "\n",
            "Yhdistetään otsoni- ja säädata...\n",
            "Yhdistetty data, rivejä NaN-poiston jälkeen: 42795\n",
            "Uudelleenotanta ('resample') tunneittaiseen taajuuteen...\n",
            "Rivejä resamplen jälkeen: 43848\n",
            "Löytyi 5265 NaN-arvoa resamplen jälkeen. Interpoloidaan (time)...\n",
            "Datan yhdistäminen ja resample onnistui.\n",
            "\n",
            "Lopullisen prosessoidun datan info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 43848 entries, 2020-04-01 00:00:00 to 2025-04-01 23:00:00\n",
            "Freq: h\n",
            "Data columns (total 5 columns):\n",
            " #   Column                        Non-Null Count  Dtype  \n",
            "---  ------                        --------------  -----  \n",
            " 0   Otsoni [µg/m³]                43848 non-null  float64\n",
            " 1   Lämpötilan keskiarvo [°C]     43848 non-null  float64\n",
            " 2   Keskituulen nopeus [m/s]      43848 non-null  float64\n",
            " 3   Ilmanpaineen keskiarvo [hPa]  43848 non-null  float64\n",
            " 4   Tuulen suunnan keskiarvo [°]  43848 non-null  float64\n",
            "dtypes: float64(5)\n",
            "memory usage: 2.0 MB\n",
            "\n",
            "Lopullisen prosessoidun datan 5 ensimmäistä riviä:\n",
            "                     Otsoni [µg/m³]  Lämpötilan keskiarvo [°C]  \\\n",
            "Timestamp                                                        \n",
            "2020-04-01 00:00:00            78.2                        2.0   \n",
            "2020-04-01 01:00:00            79.0                        2.8   \n",
            "2020-04-01 02:00:00            76.6                        3.1   \n",
            "2020-04-01 03:00:00            73.6                        3.2   \n",
            "2020-04-01 04:00:00            72.9                        3.0   \n",
            "\n",
            "                     Keskituulen nopeus [m/s]  Ilmanpaineen keskiarvo [hPa]  \\\n",
            "Timestamp                                                                     \n",
            "2020-04-01 00:00:00                       6.2                        1003.7   \n",
            "2020-04-01 01:00:00                       5.6                        1002.3   \n",
            "2020-04-01 02:00:00                       5.3                        1001.1   \n",
            "2020-04-01 03:00:00                       3.9                        1000.2   \n",
            "2020-04-01 04:00:00                       3.9                         999.4   \n",
            "\n",
            "                     Tuulen suunnan keskiarvo [°]  \n",
            "Timestamp                                          \n",
            "2020-04-01 00:00:00                         242.0  \n",
            "2020-04-01 01:00:00                         246.0  \n",
            "2020-04-01 02:00:00                         247.0  \n",
            "2020-04-01 03:00:00                         264.0  \n",
            "2020-04-01 04:00:00                         275.0  \n",
            "\n",
            "Tallennetaan prosessoitu data tiedostoon: processed_hourly_ozone_weather_data.parquet\n",
            "Tallennus Parquet-muotoon onnistui.\n",
            "\n",
            "Voit nyt ladata tämän tiedoston Colabista tai käyttää sitä suoraan\n",
            "seuraavissa mallinnusscripteissä lukemalla sen esim:\n",
            "`df = pd.read_parquet('processed_hourly_ozone_weather_data.parquet')`\n",
            "\n",
            "--- Esikäsittelyskripti päättyi ---\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOZOX_9z_scX",
        "outputId": "6385482f-6794-4704-cb86-5a3a48db82db"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}