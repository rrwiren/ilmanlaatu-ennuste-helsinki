{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNVdYWYqVP+UHKjfqzS6f0e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rrwiren/ilmanlaatu-ennuste-helsinki/blob/main/GRU_pilkottuna.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HQYlFOK4zE4"
      },
      "outputs": [],
      "source": [
        "# @title 0. Esitiedot ja Ajo-ohjeet (YKSI TIEDOSTO VERSIO v7 - Pilkottu)\n",
        "\"\"\"\n",
        "Otsoniennuste Helsinki - Paranneltu GRU-malli (PyTorch) v7 - Pilkottu\n",
        "\n",
        "Tämä on yksi yhtenäinen skripti, joka sisältää kaikki aiemmat korjaukset\n",
        "ja parannukset. Se lataa esikäsitellyn otsoni- ja säädatan, muokkaa\n",
        "ominaisuuksia, kouluttaa GRU-mallin ja arvioi sitä monipuolisesti.\n",
        "Tämä versio toimitetaan osissa (@title-lohko kerrallaan) kopioinnin\n",
        "helpottamiseksi ja oikeiden sisennysten varmistamiseksi.\n",
        "\n",
        "AJO-OHJEET COLABISSA:\n",
        "1. Luo uusi Colab-muistikirja.\n",
        "2. Kopioi KUKIN alla oleva `@title`-lohko OMAAN ERILLISEEN soluunsa\n",
        "   Colab-muistikirjassa (yhteensä 10 solua, 0-9).\n",
        "3. Aja kaikki solut järjestyksessä (Runtime -> Run all tai solu kerrallaan).\n",
        "4. Tarkastele tulosteita ja kuvaajia lopussa.\n",
        "\"\"\"\n",
        "print(\"Osa 0: Esitiedot - OK\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 1. Asennukset ja Tuonnit (Installations and Imports)\n",
        "# Asennetaan tarvittavat kirjastot (tarvittaessa Colabissa)\n",
        "# !pip install pandas numpy scikit-learn matplotlib torch pyarrow fastparquet -q\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# from sklearn.model_selection import train_test_split # Ei käytetä lopullisessa jaossa\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, confusion_matrix, classification_report\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "import requests\n",
        "import io\n",
        "import os\n",
        "from tqdm.notebook import tqdm # Edistymispalkki Colabissa\n",
        "import math\n",
        "import copy # Tarvitaan mallin tilan kopiointiin Early Stoppingissa\n",
        "import traceback # Tuodaan traceback virheen jäljitystä varten\n",
        "\n",
        "# Asetetaan laite (GPU jos saatavilla, muuten CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Käytetään laitetta: {device}\")\n",
        "print(\"Osa 1: Tuonnit - OK\")"
      ],
      "metadata": {
        "id": "NPtoPeRI5e49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 2. Parametrit ja Asetukset (Parameters and Settings)\n",
        "\n",
        "# --- Data ja GitHub ---\n",
        "GITHUB_DATA_URL = 'https://raw.githubusercontent.com/rrwiren/ilmanlaatu-ennuste-helsinki/main/data/processed/processed_hourly_ozone_weather_data.parquet'\n",
        "LOCAL_DATA_PATH = 'processed_hourly_ozone_weather_data.parquet' # Ladataan tähän tiedostoon\n",
        "\n",
        "# --- Datan sarakkeet (tarkistettu vastaamaan tiedostoa) ---\n",
        "TARGET_COLUMN = 'Otsoni [µg/m³]' # Tämä on ennustettava kohde\n",
        "ORIGINAL_FEATURE_COLUMNS = [      # Alkuperäiset sarakkeet datassa, joita käytetään\n",
        "    'Otsoni [µg/m³]',             # Käytetään myös historiallista O3:sta piirteenä\n",
        "    'Lämpötilan keskiarvo [°C]',\n",
        "    'Keskituulen nopeus [m/s]',\n",
        "    'Ilmanpaineen keskiarvo [hPa]',\n",
        "    'Tuulen suunnan keskiarvo [°]'\n",
        "]\n",
        "# Huom: Muokatut ominaisuudet (aika, tuulensuunta sin/cos) lisätään myöhemmin koodissa\n",
        "\n",
        "# Aikasarjaparametrit\n",
        "SEQUENCE_LENGTH = 72  # Kuinka monta tuntia historiaa käytetään syötteenä (esim. 3 vrk)\n",
        "PREDICTION_HORIZON = 24 # Kuinka monta tuntia eteenpäin ennustetaan\n",
        "\n",
        "# --- GRU-mallin Hyperparametrit ---\n",
        "# INPUT_SIZE lasketaan myöhemmin feature engineeringin jälkeen\n",
        "HIDDEN_SIZE = 64          # GRU-kerroksen piilotilan koko\n",
        "NUM_LAYERS = 2            # GRU-kerrosten määrä\n",
        "OUTPUT_SIZE = PREDICTION_HORIZON # Ennustetaan kaikki 24 tuntia kerralla\n",
        "DROPOUT_PROB = 0.2        # Dropout-todennäköisyys regularisointiin\n",
        "\n",
        "# --- Koulutusparametrit ---\n",
        "BATCH_SIZE = 64\n",
        "LEARNING_RATE = 0.001\n",
        "EPOCHS = 50              # Voit lisätä epochien määrää tarvittaessa\n",
        "TEST_SPLIT_RATIO = 0.15   # Testijoukon osuus (viimeisimmät tiedot)\n",
        "VALID_SPLIT_RATIO = 0.15  # Validointijoukon osuus (ennen testijoukkoa)\n",
        "EARLY_STOPPING_PATIENCE = 7 # Kärsivällisyys Early Stoppingille\n",
        "\n",
        "# --- Varoitusraja (8h liukuva keskiarvo) ---\n",
        "O3_THRESHOLD_8H_AVG = 120 # µg/m³ (Virallinen varoitusraja)\n",
        "\n",
        "# --- Satunnaisuuden kiinnitys vertailtavuuden vuoksi ---\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "    # Nämä voivat hidastaa ajoa, mutta parantavat toistettavuutta GPU:lla\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "print(\"Osa 2: Parametrit ja Asetukset - OK\")"
      ],
      "metadata": {
        "id": "S68Gk5Yd5k1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 3. Funktiot Datan Lataukseen ja Käsittelyyn\n",
        "\n",
        "def download_data(url, local_path):\n",
        "    \"\"\"Lataa tiedoston URL:sta paikalliseen polkuun.\"\"\"\n",
        "    try:\n",
        "        print(f\"Yritetään ladata dataa osoitteesta {url}...\")\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status() # Tarkistaa virheet (esim. 404 Not Found)\n",
        "        with open(local_path, 'wb') as f:\n",
        "            f.write(response.content)\n",
        "        print(f\"Data ladattu onnistuneesti: {local_path}\")\n",
        "        return True\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Virhe datan latauksessa: {e}\")\n",
        "        return False\n",
        "\n",
        "def load_data(filepath):\n",
        "    \"\"\"Lataa datan parquet-tiedostosta ja suorittaa perustarkistukset (KORJATTU VERSIO).\"\"\"\n",
        "    if not os.path.exists(filepath):\n",
        "        print(f\"Tiedostoa {filepath} ei löytynyt paikallisesti.\")\n",
        "        if not download_data(GITHUB_DATA_URL, filepath):\n",
        "            return None # Lopeta jos lataus epäonnistui\n",
        "\n",
        "    try:\n",
        "        print(f\"Ladataan dataa tiedostosta: {filepath}\")\n",
        "        df = pd.read_parquet(filepath)\n",
        "        print(\"Parquet-tiedosto ladattu.\")\n",
        "\n",
        "        # --- Aikaindeksin varmistus ---\n",
        "        if not isinstance(df.index, pd.DatetimeIndex):\n",
        "             if 'timestamp' in df.columns: # Yleinen nimi aikaleimalle\n",
        "                  df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "                  df.set_index('timestamp', inplace=True)\n",
        "                  print(\"Muutettu 'timestamp'-sarake indeksiksi.\")\n",
        "             else:\n",
        "                 try:\n",
        "                    df.index = pd.to_datetime(df.index)\n",
        "                    print(\"Muutettu olemassaoleva indeksi datetime-indeksiksi.\")\n",
        "                 except Exception as e:\n",
        "                    print(f\"Indeksin muuttaminen datetimeksi epäonnistui: {e}\")\n",
        "                    print(\"Varmista, että datassa on aikaleimaindeksi tai 'timestamp'-sarake.\")\n",
        "                    return None\n",
        "\n",
        "        df.sort_index(inplace=True) # Varmista aikajärjestys\n",
        "\n",
        "        print(f\"\\nDatan perustiedot:\")\n",
        "        print(f\"Muoto: {df.shape}\")\n",
        "        print(f\"Aikaväli: {df.index.min()} - {df.index.max()}\")\n",
        "        print(f\"Kaikki ladatut sarakkeet: {df.columns.tolist()}\")\n",
        "\n",
        "        # --- Puuttuvien arvojen käsittely ---\n",
        "        print(\"\\nPuuttuvat arvot per sarake (ennen täyttöä):\")\n",
        "        null_counts_before = df.isnull().sum()\n",
        "        print(null_counts_before)\n",
        "        if null_counts_before.sum() > 0:\n",
        "            print(\"Täytetään puuttuvat arvot (ffill + bfill)...\")\n",
        "            df.ffill(inplace=True)\n",
        "            df.bfill(inplace=True)\n",
        "            print(\"\\nPuuttuvat arvot täytön jälkeen:\")\n",
        "            null_counts_after = df.isnull().sum()\n",
        "            print(null_counts_after)\n",
        "            # Tarkistetaan uudelleen, jos bfill ei auttanut alkuun\n",
        "            if null_counts_after.sum() > 0:\n",
        "                 print(\"VAROITUS: Datan sisältää edelleen puuttuvia arvoja! Poistetaan rivit.\")\n",
        "                 df.dropna(inplace=True)\n",
        "                 print(f\"Datan muoto NaN-rivien poiston jälkeen: {df.shape}\")\n",
        "        else:\n",
        "            print(\"Ei puuttuvia arvoja.\")\n",
        "\n",
        "        print(\"\\nDatan lataus ja peruspuhdistus valmiit.\")\n",
        "        # Palautetaan koko ladattu ja puhdistettu DataFrame\n",
        "        return df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Virhe datan käsittelyssä load_data funktiossa: {e}\")\n",
        "        traceback.print_exc() # Tulosta traceback debuggausta varten\n",
        "        return None\n",
        "\n",
        "def feature_engineer(df):\n",
        "    \"\"\"Lisää aika- ja syklisiä ominaisuuksia DataFrameen.\"\"\"\n",
        "    print(\"\\nSuoritetaan ominaisuuksien muokkaus (Feature Engineering)...\")\n",
        "    if not isinstance(df, pd.DataFrame):\n",
        "        print(\"VIRHE: feature_engineer sai syötteenä jotain muuta kuin DataFramen.\")\n",
        "        return None\n",
        "    df_eng = df.copy()\n",
        "    engineered_cols = [] # Kerätään uusien sarakkeiden nimet\n",
        "\n",
        "    # 1. Kellonaika (syklinen)\n",
        "    try:\n",
        "        df_eng['hour'] = df_eng.index.hour\n",
        "        df_eng['hour_sin'] = np.sin(2 * np.pi * df_eng['hour'] / 24.0)\n",
        "        df_eng['hour_cos'] = np.cos(2 * np.pi * df_eng['hour'] / 24.0)\n",
        "        df_eng.drop('hour', axis=1, inplace=True) # Poista alkuperäinen tuntisarake\n",
        "        engineered_cols.extend(['hour_sin', 'hour_cos'])\n",
        "        print(\"Lisätty syklinen kellonaika (hour_sin, hour_cos).\")\n",
        "    except AttributeError:\n",
        "         print(\"VAROITUS: Ei voitu lisätä kellonaikaominaisuuksia (indeksi ei ehkä ole DatetimeIndex?).\")\n",
        "    except Exception as e:\n",
        "         print(f\"VIRHE kellonaikaominaisuuksien luonnissa: {e}\")\n",
        "\n",
        "\n",
        "    # 2. Tuulen suunta (syklinen)\n",
        "    wind_dir_col = 'Tuulen suunnan keskiarvo [°]'\n",
        "    if wind_dir_col in df_eng.columns:\n",
        "        try:\n",
        "            df_eng['wind_dir_rad'] = np.deg2rad(df_eng[wind_dir_col])\n",
        "            df_eng['wind_dir_sin'] = np.sin(df_eng['wind_dir_rad'])\n",
        "            df_eng['wind_dir_cos'] = np.cos(df_eng['wind_dir_rad'])\n",
        "            # Poista alkuperäinen tuulensuunta asteina ja radiaaneina\n",
        "            df_eng.drop([wind_dir_col, 'wind_dir_rad'], axis=1, inplace=True)\n",
        "            engineered_cols.extend(['wind_dir_sin', 'wind_dir_cos'])\n",
        "            print(\"Muunnettu tuulen suunta sykliseksi (wind_dir_sin, wind_dir_cos).\")\n",
        "        except Exception as e:\n",
        "            print(f\"VIRHE tuulensuuntaominaisuuksien luonnissa: {e}\")\n",
        "            # Jos virhe, poista mahdollisesti luodut väliaikaiset sarakkeet\n",
        "            if 'wind_dir_rad' in df_eng.columns: df_eng.drop('wind_dir_rad', axis=1, inplace=True)\n",
        "            if 'wind_dir_sin' in df_eng.columns: df_eng.drop('wind_dir_sin', axis=1, inplace=True)\n",
        "            if 'wind_dir_cos' in df_eng.columns: df_eng.drop('wind_dir_cos', axis=1, inplace=True)\n",
        "\n",
        "    else:\n",
        "        print(f\"Saraketta '{wind_dir_col}' ei löytynyt, tuulensuunnan muokkausta ei tehty.\")\n",
        "\n",
        "    print(\"Ominaisuuksien muokkaus valmis.\")\n",
        "    print(f\"Muokattu DataFrame sisältää nyt sarakkeet: {df_eng.columns.tolist()}\")\n",
        "    return df_eng\n",
        "\n",
        "def create_sequences(features_scaled, targets_original, sequence_length, prediction_horizon):\n",
        "    \"\"\"\n",
        "    Luo syötesekvenssejä (skaalattu) ja alkuperäisiä kohde-ennusteita.\n",
        "    \"\"\"\n",
        "    X, y_orig = [], []\n",
        "    print(f\"Luodaan sekvenssejä: sequence_length={sequence_length}, prediction_horizon={prediction_horizon}\")\n",
        "    print(f\"features_scaled shape: {features_scaled.shape}, targets_original shape: {targets_original.shape}\")\n",
        "    # Varmistetaan, että dataa on tarpeeksi\n",
        "    required_len = sequence_length + prediction_horizon\n",
        "    if len(features_scaled) < required_len:\n",
        "        print(f\"VAROITUS: Ei tarpeeksi dataa ({len(features_scaled)}) sekvenssien luomiseen. Tarvitaan vähintään {required_len}.\")\n",
        "        return np.array(X), np.array(y_orig) # Palautetaan tyhjät arrayt\n",
        "\n",
        "    # Loopataan niin, että viimeinen y alkaa kohdasta len - prediction_horizon\n",
        "    for i in range(len(features_scaled) - required_len + 1):\n",
        "        X.append(features_scaled[i:(i + sequence_length)])\n",
        "        # Otetaan vain O3-arvot (target) ennustejaksolle alkuperäisestä datasta\n",
        "        y_orig.append(targets_original[i + sequence_length : i + sequence_length + prediction_horizon])\n",
        "\n",
        "    print(f\"Luotu {len(X)} sekvenssiä.\")\n",
        "    # Muunnetaan numpy-arrayksi lopuksi\n",
        "    X = np.array(X)\n",
        "    y_orig = np.array(y_orig)\n",
        "    # Varmistetaan y_orig muoto (samples, horizon, 1) jos targets_original oli (N, 1)\n",
        "    if y_orig.ndim == 2 and targets_original.ndim == 2 and targets_original.shape[1] == 1:\n",
        "         y_orig = y_orig[..., np.newaxis]\n",
        "         print(f\"Muutettu y_orig muotoon: {y_orig.shape}\")\n",
        "\n",
        "    return X, y_orig\n",
        "\n",
        "print(\"Osa 3: Funktiot datan käsittelyyn - OK\")"
      ],
      "metadata": {
        "id": "t6ke7BZj5tZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 4. Pääskriptin Suoritus: Datan Käsittely\n",
        "\n",
        "# === PÄÄSKRIPTIN SUORITUSLOGIIKKA ALKAA TÄSTÄ ===\n",
        "\n",
        "# --- Alustetaan muuttujat siltä varalta, että jokin vaihe epäonnistuu ---\n",
        "df_raw = None\n",
        "df_engineered = None\n",
        "train_loader = None\n",
        "valid_loader = None\n",
        "test_loader = None\n",
        "o3_scaler = None\n",
        "feature_scaler = None\n",
        "INPUT_SIZE = None\n",
        "model = None\n",
        "test_preds_orig = None\n",
        "test_targets_orig = None\n",
        "test_timestamps = None\n",
        "X_train, y_train_original, X_valid, y_valid_original, X_test, y_test_original = [None]*6\n",
        "y_train_scaled, y_valid_scaled = None, None\n",
        "\n",
        "# --- Ladataan data ---\n",
        "df_raw_full = load_data(LOCAL_DATA_PATH) # Ladataan ensin kaikki sarakkeet\n",
        "\n",
        "if df_raw_full is not None:\n",
        "    try: # Lisätään try-except koko datan käsittelylohkon ympärille\n",
        "        # --- TARKISTETAAN TARVITTAVAT SARAKKEET ---\n",
        "        print(\"\\nTarkistetaan vaadittujen sarakkeiden olemassaolo...\")\n",
        "        required_cols_for_features = ORIGINAL_FEATURE_COLUMNS\n",
        "        all_required_cols = list(set(required_cols_for_features + [TARGET_COLUMN]))\n",
        "\n",
        "        missing_cols = [col for col in all_required_cols if col not in df_raw_full.columns]\n",
        "\n",
        "        if missing_cols:\n",
        "            print(f\"\\nVIRHE: Seuraavia vaadittuja sarakkeita ei löytynyt ladatusta datasta: {missing_cols}\")\n",
        "            raise ValueError(f\"Vaadittuja sarakkeita puuttuu, ei voida jatkaa: {missing_cols}\")\n",
        "        else:\n",
        "            print(\"Kaikki vaaditut sarakkeet löytyivät.\")\n",
        "            # Valitaan vain ne sarakkeet, jotka määriteltiin ORIGINAL_FEATURE_COLUMNS-listassa\n",
        "            df_raw = df_raw_full[ORIGINAL_FEATURE_COLUMNS].copy()\n",
        "\n",
        "        # --- Ominaisuuksien muokkaus ---\n",
        "        df_engineered = feature_engineer(df_raw)\n",
        "        if df_engineered is None: raise ValueError(\"Ominaisuuksien muokkaus epäonnistui.\")\n",
        "\n",
        "        FINAL_FEATURE_COLUMNS = df_engineered.columns.tolist()\n",
        "        INPUT_SIZE = len(FINAL_FEATURE_COLUMNS)\n",
        "        if INPUT_SIZE == 0: raise ValueError(\"Ominaisuuksien muokkauksen jälkeen ei jäänyt yhtään ominaisuutta.\")\n",
        "        print(f\"\\nLopullinen ominaisuuksien määrä (INPUT_SIZE): {INPUT_SIZE}\")\n",
        "        print(f\"Lopulliset ominaisuudet mallille: {FINAL_FEATURE_COLUMNS}\")\n",
        "\n",
        "        # --- Datan Jako (Train, Validation, Test) ---\n",
        "        n = len(df_engineered)\n",
        "        min_data_len_needed = (SEQUENCE_LENGTH + PREDICTION_HORIZON) * 3 # Karkea arvio\n",
        "        if n < min_data_len_needed:\n",
        "             print(f\"VAROITUS: Datan pituus ({n}) voi olla liian lyhyt jakoon ja sekvenssien luontiin (tarvitaan arviolta > {min_data_len_needed}).\")\n",
        "             # Ei nosteta virhettä vielä, mutta tarkistetaan jaon jälkeen\n",
        "\n",
        "        test_split_idx = int(n * (1 - TEST_SPLIT_RATIO))\n",
        "        valid_split_idx = int(test_split_idx * (1 - VALID_SPLIT_RATIO / (1 - TEST_SPLIT_RATIO)))\n",
        "\n",
        "        df_train = df_engineered[:valid_split_idx]\n",
        "        df_valid = df_engineered[valid_split_idx:test_split_idx]\n",
        "        df_test = df_engineered[test_split_idx:]\n",
        "\n",
        "        # Varmistetaan, että jokaisessa jaossa on tarpeeksi dataa sekvensseille\n",
        "        min_len_for_seq = SEQUENCE_LENGTH + PREDICTION_HORIZON\n",
        "        if len(df_train) < min_len_for_seq or len(df_valid) < min_len_for_seq or len(df_test) < min_len_for_seq:\n",
        "            print(f\"Train len: {len(df_train)}, Valid len: {len(df_valid)}, Test len: {len(df_test)}, Min required for sequence: {min_len_for_seq}\")\n",
        "            raise ValueError(\"Liian vähän dataa yhdessä tai useammassa jaossa sekvenssien luontia varten.\")\n",
        "\n",
        "        print(f\"\\nDatan jako:\")\n",
        "        print(f\"Train: {df_train.shape[0]} riviä ({df_train.index.min()} - {df_train.index.max()})\")\n",
        "        print(f\"Valid: {df_valid.shape[0]} riviä ({df_valid.index.min()} - {df_valid.index.max()})\")\n",
        "        print(f\"Test:  {df_test.shape[0]} riviä ({df_test.index.min()} - {df_test.index.max()})\")\n",
        "\n",
        "        # --- Skaalaus ---\n",
        "        feature_scaler = StandardScaler()\n",
        "        scaled_train_features = feature_scaler.fit_transform(df_train)\n",
        "        scaled_valid_features = feature_scaler.transform(df_valid)\n",
        "        scaled_test_features = feature_scaler.transform(df_test)\n",
        "        print(\"Ominaisuudet skaalattu (sovitettu vain harjoitusdataan).\")\n",
        "\n",
        "        o3_scaler = StandardScaler()\n",
        "        o3_scaler.fit(df_raw.loc[df_train.index, [TARGET_COLUMN]])\n",
        "        print(\"Erillinen skaalain luotu ja sovitettu kohdemuuttujalle (O3).\")\n",
        "\n",
        "        # Haetaan ALKUPERÄISET O3-kohdearvot jakojen mukaisesti\n",
        "        o3_train_targets_original = df_raw.loc[df_train.index, [TARGET_COLUMN]].values\n",
        "        o3_valid_targets_original = df_raw.loc[df_valid.index, [TARGET_COLUMN]].values\n",
        "        o3_test_targets_original = df_raw.loc[df_test.index, [TARGET_COLUMN]].values\n",
        "\n",
        "\n",
        "        # --- Sekvenssien Luonti ---\n",
        "        print(\"\\nLuodaan aikasarjasekvenssejä...\")\n",
        "        X_train, y_train_original = create_sequences(scaled_train_features, o3_train_targets_original, SEQUENCE_LENGTH, PREDICTION_HORIZON)\n",
        "        X_valid, y_valid_original = create_sequences(scaled_valid_features, o3_valid_targets_original, SEQUENCE_LENGTH, PREDICTION_HORIZON)\n",
        "        X_test, y_test_original = create_sequences(scaled_test_features, o3_test_targets_original, SEQUENCE_LENGTH, PREDICTION_HORIZON)\n",
        "\n",
        "        if X_train.size == 0 or X_valid.size == 0 or X_test.size == 0:\n",
        "             raise ValueError(\"Sekvenssien luonti epäonnistui (yksi tai useampi X on tyhjä).\")\n",
        "\n",
        "        # Skaalataan y-arvot (kohdearvot)\n",
        "        # Muoto y_..._original on nyt (samples, horizon, 1)\n",
        "        y_train_scaled = o3_scaler.transform(y_train_original.reshape(-1, 1)).reshape(y_train_original.shape)\n",
        "        y_valid_scaled = o3_scaler.transform(y_valid_original.reshape(-1, 1)).reshape(y_valid_original.shape)\n",
        "        # y_test_scaled ei välttämättä tarvita, koska test_loader käyttää originalia\n",
        "        print(\"Kohdearvot (y) skaalattu koulutusta ja validointia varten.\")\n",
        "\n",
        "        # --- Muunnos PyTorch Tensoreiksi ---\n",
        "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "        y_train_tensor = torch.tensor(y_train_scaled, dtype=torch.float32)\n",
        "        X_valid_tensor = torch.tensor(X_valid, dtype=torch.float32)\n",
        "        y_valid_tensor = torch.tensor(y_valid_scaled, dtype=torch.float32)\n",
        "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "        y_test_tensor_original = torch.tensor(y_test_original, dtype=torch.float32) # Muoto (samples, horizon, 1)\n",
        "\n",
        "        # --- DataLoaderien Luonti ---\n",
        "        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "        valid_dataset = TensorDataset(X_valid_tensor, y_valid_tensor)\n",
        "        valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "        test_dataset = TensorDataset(X_test_tensor, y_test_tensor_original) # Käyttää alkuperäistä y:tä\n",
        "        test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "        print(\"\\nDataloaderit luotu.\")\n",
        "\n",
        "        # Tallennetaan testiaikaleimat\n",
        "        # Varmistetaan, että df_test ei ole tyhjä ja indeksi on riittävä\n",
        "        if not df_test.empty and len(df_test) >= SEQUENCE_LENGTH:\n",
        "            try:\n",
        "                test_start_index_loc = df_engineered.index.get_loc(df_test.index[0])\n",
        "                test_start_indices = test_start_index_loc + SEQUENCE_LENGTH\n",
        "                end_index = test_start_indices + len(X_test)\n",
        "                if end_index <= len(df_engineered.index):\n",
        "                    test_timestamps = df_engineered.index[test_start_indices : end_index]\n",
        "                    print(f\"Testiaikaleimat luotu ({len(test_timestamps)} kpl).\")\n",
        "                else:\n",
        "                    print(f\"VAROITUS: Ei voitu määrittää kaikkia testiaikaleimoja, loppuindeksi ({end_index}) ylittää datan pituuden ({len(df_engineered.index)}).\")\n",
        "                    test_timestamps = None\n",
        "            except KeyError:\n",
        "                 print(\"VAROITUS: Testijoukon alkuaikaleimaa ei löytynyt alkuperäisestä indeksistä.\")\n",
        "                 test_timestamps = None\n",
        "        else:\n",
        "             print(\"VAROITUS: Testidata liian lyhyt tai tyhjä aikaleimojen luontiin.\")\n",
        "             test_timestamps = None\n",
        "\n",
        "\n",
        "        print(f\"\\nSekvenssien lopulliset muodot:\")\n",
        "        print(f\"X_train: {X_train.shape}, y_train_scaled: {y_train_scaled.shape}\")\n",
        "        print(f\"X_valid: {X_valid.shape}, y_valid_scaled: {y_valid_scaled.shape}\")\n",
        "        # Käytetään tensorin muotoa testille, koska sitä käytetään DataLoaderissa\n",
        "        print(f\"X_test:  {X_test.shape}, y_test_original (tensor): {y_test_tensor_original.shape}\")\n",
        "\n",
        "        print(\"\\nOsa 4: Datan käsittely - VALMIS\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n---> VIRHE DATAN KÄSITTELYSSÄ (Osa 4) <---\")\n",
        "        print(f\"Virhetyyppi: {type(e).__name__}\")\n",
        "        print(f\"Virheilmoitus: {e}\")\n",
        "        traceback.print_exc()\n",
        "        # Asetetaan kriittiset muuttujat Noneksi, jotta myöhemmät vaiheet eivät suoritu\n",
        "        train_loader = None\n",
        "        valid_loader = None\n",
        "        test_loader = None\n",
        "        INPUT_SIZE = None\n",
        "        o3_scaler = None\n",
        "        feature_scaler = None\n",
        "        print(\"----------------------------------------------\")\n",
        "\n",
        "\n",
        "else: # Jos df_raw_full is None\n",
        "    print(\"Datan lataus epäonnistui kokonaan. Skriptin suoritus keskeytetty.\")\n",
        "    INPUT_SIZE = None # Varmistetaan Noneksi"
      ],
      "metadata": {
        "id": "jC-dSyfa54Yr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 5. GRU-Mallin Määrittely ja Koulutusfunktio\n",
        "\n",
        "class GRUModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout_prob):\n",
        "        super(GRUModel, self).__init__()\n",
        "        # Tarkistetaan syötteiden tyypit ja arvot\n",
        "        assert isinstance(input_size, int) and input_size > 0, f\"input_size ({input_size}) oltava positiivinen kokonaisluku\"\n",
        "        assert isinstance(hidden_size, int) and hidden_size > 0, \"hidden_size oltava positiivinen kokonaisluku\"\n",
        "        assert isinstance(num_layers, int) and num_layers > 0, \"num_layers oltava positiivinen kokonaisluku\"\n",
        "        assert isinstance(output_size, int) and output_size > 0, \"output_size oltava positiivinen kokonaisluku\"\n",
        "        assert isinstance(dropout_prob, float) and 0.0 <= dropout_prob < 1.0, \"dropout_prob oltava liukuluku välillä [0, 1)\"\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        # Käytä dropoutia vain jos kerroksia on enemmän kuin yksi\n",
        "        gru_dropout = dropout_prob if num_layers > 1 else 0.0\n",
        "        self.gru = nn.GRU(input_size, hidden_size, num_layers,\n",
        "                          batch_first=True, dropout=gru_dropout)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x muoto: (batch, seq_len, input_size)\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        # GRU:n output muoto: (batch, seq_len, hidden_size)\n",
        "        # hn muoto: (num_layers, batch, hidden_size)\n",
        "        out, _ = self.gru(x, h0)\n",
        "        # Otetaan viimeisen aika-askeleen piilotila kaikilta kerroksilta,\n",
        "        # ja käytetään vain viimeisen kerroksen tilaa? Ei, otetaan output viimeiseltä askeleelta.\n",
        "        out = out[:, -1, :] # Muoto: (batch, hidden_size)\n",
        "        out = self.fc(out)  # Muoto: (batch, output_size) eli (batch, 24)\n",
        "        return out\n",
        "\n",
        "def train_model(model, train_loader, valid_loader, criterion, optimizer, epochs, device, patience):\n",
        "    \"\"\"Kouluttaa mallin ja käyttää Early Stoppingia (KORJATTU .squeeze(-1)).\"\"\"\n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        "    best_valid_loss = float('inf')\n",
        "    epochs_no_improve = 0\n",
        "    best_model_state = None # Tähän tallennetaan parhaan mallin tila\n",
        "\n",
        "    if not isinstance(model, nn.Module): raise TypeError(\"Vaaditaan PyTorch-malli.\")\n",
        "    if not isinstance(train_loader, DataLoader): raise TypeError(\"Vaaditaan DataLoader train_loaderille.\")\n",
        "    if not isinstance(valid_loader, DataLoader): raise TypeError(\"Vaaditaan DataLoader valid_loaderille.\")\n",
        "    # Lisää tarkistuksia tarvittaessa...\n",
        "\n",
        "    print(f\"\\nAloitetaan koulutus {epochs} epochilla...\")\n",
        "    for epoch in tqdm(range(epochs), desc=\"Epochs\"):\n",
        "        model.train() # Koulutustila\n",
        "        running_train_loss = 0.0\n",
        "        batch_count = 0\n",
        "        try: # Try-except yksittäisen epochin ympärille\n",
        "            for inputs, targets_scaled in train_loader:\n",
        "                batch_count += 1\n",
        "                inputs, targets_scaled = inputs.to(device), targets_scaled.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                outputs_scaled = model(inputs) # Ennusteet, muoto (batch, 24)\n",
        "\n",
        "                # --- Käsittele kohdemuoto ---\n",
        "                if targets_scaled.ndim == outputs_scaled.ndim + 1 and targets_scaled.shape[-1] == 1:\n",
        "                    targets_squeezed = targets_scaled.squeeze(-1) # Muoto (batch, 24)\n",
        "                elif targets_scaled.shape == outputs_scaled.shape:\n",
        "                    targets_squeezed = targets_scaled # Muodot täsmäävät jo\n",
        "                else:\n",
        "                     # Muodot eivät täsmää, eikä squeeze auta -> virhe\n",
        "                     print(f\"\\nVIRHE Epoch {epoch+1}, Batch {batch_count} (Train): Muodot eivät täsmää loss-laskentaa varten!\")\n",
        "                     print(f\"Output shape: {outputs_scaled.shape}, Target shape: {targets_scaled.shape}\")\n",
        "                     raise RuntimeError(f\"Muodot eivät täsmää loss-laskentaa varten: {outputs_scaled.shape} vs {targets_scaled.shape}\")\n",
        "\n",
        "                loss = criterion(outputs_scaled, targets_squeezed) # Lasketaan häviö\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                running_train_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        except Exception as e:\n",
        "             print(f\"\\nVIRHE koulutusloopissa (Epoch {epoch+1}, Batch {batch_count}): {e}\")\n",
        "             traceback.print_exc()\n",
        "             print(\"Keskeytetään koulutus.\")\n",
        "             return model, None, None # Palautetaan None, jos koulutus keskeytyy virheeseen\n",
        "\n",
        "\n",
        "        epoch_train_loss = running_train_loss / len(train_loader.dataset) if len(train_loader.dataset) > 0 else 0\n",
        "        train_losses.append(epoch_train_loss)\n",
        "\n",
        "        # Validointi\n",
        "        model.eval() # Evaluointitila\n",
        "        running_valid_loss = 0.0\n",
        "        valid_batch_count = 0\n",
        "        try: # Try-except myös validointiin\n",
        "            with torch.no_grad():\n",
        "                for inputs, targets_scaled in valid_loader:\n",
        "                    valid_batch_count += 1\n",
        "                    inputs, targets_scaled = inputs.to(device), targets_scaled.to(device)\n",
        "                    outputs_scaled = model(inputs)\n",
        "\n",
        "                    # --- Käsittele kohdemuoto ---\n",
        "                    if targets_scaled.ndim == outputs_scaled.ndim + 1 and targets_scaled.shape[-1] == 1:\n",
        "                        targets_squeezed = targets_scaled.squeeze(-1)\n",
        "                    elif targets_scaled.shape == outputs_scaled.shape:\n",
        "                        targets_squeezed = targets_scaled\n",
        "                    else:\n",
        "                         print(f\"\\nVIRHE Epoch {epoch+1} (Valid), Batch {valid_batch_count}: Muodot eivät täsmää loss-laskentaa varten!\")\n",
        "                         print(f\"Output shape: {outputs_scaled.shape}, Target shape: {targets_scaled.shape}\")\n",
        "                         raise RuntimeError(f\"Muodot eivät täsmää validointi loss-laskentaa varten: {outputs_scaled.shape} vs {targets_scaled.shape}\")\n",
        "\n",
        "\n",
        "                    loss = criterion(outputs_scaled, targets_squeezed)\n",
        "                    running_valid_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        except Exception as e:\n",
        "             print(f\"\\nVIRHE validointiloopissa (Epoch {epoch+1}, Batch {valid_batch_count}): {e}\")\n",
        "             traceback.print_exc()\n",
        "             print(\"Keskeytetään koulutus.\")\n",
        "             return model, train_losses, None # Palauta tähänastiset treenihäviöt\n",
        "\n",
        "\n",
        "        epoch_valid_loss = running_valid_loss / len(valid_loader.dataset) if len(valid_loader.dataset) > 0 else 0\n",
        "        valid_losses.append(epoch_valid_loss)\n",
        "\n",
        "        # Tulostetaan epochin tiedot\n",
        "        print(f\"Epoch {epoch+1:02d}/{epochs} - Train Loss: {epoch_train_loss:.6f} - Valid Loss: {epoch_valid_loss:.6f}\", end=\"\")\n",
        "\n",
        "        # Early Stopping Check\n",
        "        if epoch_valid_loss < best_valid_loss:\n",
        "            best_valid_loss = epoch_valid_loss\n",
        "            epochs_no_improve = 0\n",
        "            try: # Lisätty try-except varmuuden vuoksi\n",
        "                 best_model_state = copy.deepcopy(model.state_dict())\n",
        "                 print(\" (Uusi paras!)\")\n",
        "            except Exception as e_state:\n",
        "                 print(f\" (VIRHE mallin tilan tallennuksessa: {e_state})\")\n",
        "                 best_model_state = None # Älä käytä viallista tilaa\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            print(f\" (Ei parannusta {epochs_no_improve}/{patience})\")\n",
        "\n",
        "        if epochs_no_improve >= patience:\n",
        "            print(f\"\\nEarly stopping {patience} epochin jälkeen ilman parannusta.\")\n",
        "            break\n",
        "\n",
        "    # Palauta paras löydetty mallin tila (jos löytyi ja tallennus onnistui)\n",
        "    if best_model_state:\n",
        "         print(\"\\nLadataan paras malli Early Stoppingin perusteella.\")\n",
        "         try:\n",
        "              model.load_state_dict(best_model_state)\n",
        "         except Exception as e_load:\n",
        "              print(f\"VIRHE parhaan mallin tilan latauksessa: {e_load}\")\n",
        "              print(\"Jatketaan viimeisimmällä mallilla.\")\n",
        "    elif epochs > 0 and train_losses is not None : # Jos ei early stopping, mutta ajettiin edes yksi epoch ilman virhettä\n",
        "         print(\"\\nKoulutus päättyi ilman Early Stoppingia. Käytetään viimeisintä mallia.\")\n",
        "    # Muuten (jos koulutus keskeytyi heti tai epochs=0), malli säilyy sellaisena kuin se oli\n",
        "\n",
        "\n",
        "    return model, train_losses, valid_losses\n",
        "\n",
        "print(\"Osa 5: Mallin ja koulutusfunktion määrittely - OK\")"
      ],
      "metadata": {
        "id": "33PXrP0C6EAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 6. Mallin Koulutus (Suoritus)\n",
        "\n",
        "# --- Koulutetaan malli (jos data ja asetukset ok) ---\n",
        "# Lisätty debug-tuloste ennen ehtoa\n",
        "print(f\"\\nTarkistetaan ennen koulutusta: train_loader is {'olemassa' if train_loader is not None else 'None'}, INPUT_SIZE = {INPUT_SIZE}\")\n",
        "\n",
        "# Alustetaan model Noneksi siltä varalta että koulutus ei käynnisty tai epäonnistuu\n",
        "model = None\n",
        "train_losses = None\n",
        "valid_losses = None\n",
        "\n",
        "if train_loader is not None and INPUT_SIZE is not None:\n",
        "    # --- Mallin, häviöfunktion ja optimoijan alustus ---\n",
        "    # Varmistetaan, että INPUT_SIZE on kelvollinen\n",
        "    if isinstance(INPUT_SIZE, int) and INPUT_SIZE > 0:\n",
        "        try: # Try-except mallin alustuksen ympärille\n",
        "            model = GRUModel(INPUT_SIZE, HIDDEN_SIZE, NUM_LAYERS, OUTPUT_SIZE, DROPOUT_PROB).to(device)\n",
        "            criterion = nn.MSELoss()\n",
        "            optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "            print(\"\\n--- GRU-Malli ---\")\n",
        "            print(model)\n",
        "            print(f\"Ominaisuuksien määrä (Input size): {INPUT_SIZE}\")\n",
        "            param_count = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "            print(f\"Koulutettavien parametrien määrä: {param_count}\")\n",
        "            print(\"---------------------\\n\")\n",
        "\n",
        "            # --- Koulutetaan malli ---\n",
        "            # Try-except itse train_model kutsun ympärille\n",
        "            try:\n",
        "                model, train_losses, valid_losses = train_model(\n",
        "                    model, train_loader, valid_loader, criterion, optimizer, EPOCHS, device, EARLY_STOPPING_PATIENCE\n",
        "                )\n",
        "                # Tarkistetaan paluuarvot\n",
        "                if train_losses is None or valid_losses is None:\n",
        "                     print(\"\\nKoulutus keskeytyi virheeseen train_model-funktiossa.\")\n",
        "                     model = None # Aseta malli Noneksi, jos koulutus epäonnistui\n",
        "                else:\n",
        "                     print(\"\\nKoulutus valmis.\")\n",
        "\n",
        "                     # --- Piirretään häviökäyrät (vain jos koulutus onnistui) ---\n",
        "                     if train_losses and valid_losses: # Varmista että listat eivät ole tyhjiä\n",
        "                        plt.figure(figsize=(10, 5))\n",
        "                        plt.plot(train_losses, label='Training Loss')\n",
        "                        plt.plot(valid_losses, label='Validation Loss')\n",
        "                        plt.title('Training and Validation Loss')\n",
        "                        plt.xlabel('Epoch')\n",
        "                        plt.ylabel('Loss (MSE)')\n",
        "                        # Käytä log-skaalaa vain jos minimihäviö on positiivinen ja > 0\n",
        "                        min_loss = min(min(train_losses, default=1.0), min(valid_losses, default=1.0))\n",
        "                        if min_loss > 1e-9 :\n",
        "                           plt.yscale('log')\n",
        "                           print(\"Käytetään logaritmista skaalaa häviökuvaajassa.\")\n",
        "                        else:\n",
        "                           print(\"Käytetään lineaarista skaalaa häviökuvaajassa.\")\n",
        "                        plt.legend()\n",
        "                        plt.grid(True, linestyle=':', alpha=0.7)\n",
        "                        plt.show()\n",
        "                     else:\n",
        "                          print(\"Häviölistat ovat tyhjiä, ei voida piirtää kuvaajaa.\")\n",
        "\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"\\nVIRHE train_model-kutsun aikana: {e}\")\n",
        "                traceback.print_exc()\n",
        "                model = None # Aseta malli Noneksi\n",
        "\n",
        "        except Exception as e:\n",
        "             print(f\"\\nVIRHE mallin alustuksessa: {e}\")\n",
        "             traceback.print_exc()\n",
        "             model = None # Aseta malli Noneksi\n",
        "\n",
        "    else:\n",
        "        print(f\"\\nKoulutusta ei aloiteta, virheellinen INPUT_SIZE: {INPUT_SIZE}\")\n",
        "        model = None # Estetään jatko\n",
        "\n",
        "else:\n",
        "    print(\"\\nKoulutusta ei voida aloittaa, koska dataa ei ole ladattu/käsitelty oikein (train_loader=None) tai INPUT_SIZE puuttuu/on virheellinen.\")\n",
        "    model = None # Estetään jatko\n",
        "\n",
        "print(\"\\nOsa 6: Koulutuksen suoritus - VALMIS (tai ohitettu/epäonnistunut)\")"
      ],
      "metadata": {
        "id": "fxbcqSN86NXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 7. Mallin Arviointi ja Vertailu (Funktiot) - PARANNETTU VIRHEENKÄSITTELY\n",
        "\n",
        "def calculate_baseline_persistence(targets_original_np, prediction_horizon):\n",
        "    \"\"\"Laskee naiivin persistenssi-baselinen (jakson eka arvo toistuu).\"\"\"\n",
        "    print(\"Lasketaan Baseline-ennuste (jokainen 24h jakso = jakson eka arvo)...\")\n",
        "    try:\n",
        "        # Oletetaan targets_original_np muoto (samples, horizon) tai (samples, horizon, 1)\n",
        "        if targets_original_np.ndim == 3 and targets_original_np.shape[-1] == 1:\n",
        "             # Varmistetaan että ei olla tyhjä\n",
        "             if targets_original_np.shape[0] == 0: return np.zeros((0, prediction_horizon))\n",
        "             first_vals_squeezed = targets_original_np[:, 0, 0] # Muoto (samples,)\n",
        "             first_vals_for_repeat = first_vals_squeezed[:, np.newaxis] # Muoto (samples, 1)\n",
        "        elif targets_original_np.ndim == 2:\n",
        "             if targets_original_np.shape[0] == 0: return np.zeros((0, prediction_horizon))\n",
        "             first_vals_for_repeat = targets_original_np[:, 0:1] # Muoto (samples, 1)\n",
        "        else:\n",
        "             print(f\"VAROITUS: Odottamaton muoto ({targets_original_np.shape}) baseline-laskennassa!\")\n",
        "             return np.zeros((targets_original_np.shape[0] if targets_original_np.ndim > 0 else 0, prediction_horizon))\n",
        "\n",
        "        if first_vals_for_repeat.size == 0:\n",
        "             print(\"VAROITUS: Baseline sai tyhjän taulukon, palautetaan nollia.\")\n",
        "             return np.zeros((targets_original_np.shape[0], prediction_horizon))\n",
        "\n",
        "        baseline_preds = np.repeat(first_vals_for_repeat, prediction_horizon, axis=1) # Muoto (samples, horizon)\n",
        "\n",
        "        # Tarkistetaan lopullinen muoto\n",
        "        expected_shape = (targets_original_np.shape[0], prediction_horizon)\n",
        "        if baseline_preds.shape != expected_shape:\n",
        "             print(f\"VAROITUS: Baseline lopputuloksen muoto ({baseline_preds.shape}) ei ole odotettu ({expected_shape}). Yritetään korjata.\")\n",
        "             try:\n",
        "                  baseline_preds = baseline_preds.reshape(expected_shape)\n",
        "             except:\n",
        "                  print(\"VIRHE: Baseline-muodon korjaus epäonnistui.\")\n",
        "                  return np.zeros(expected_shape)\n",
        "\n",
        "        return baseline_preds\n",
        "    except Exception as e:\n",
        "        print(f\"VIRHE baseline-laskennassa: {e}\")\n",
        "        traceback.print_exc()\n",
        "        try: # Yritetään palauttaa oikean muotoisia nollia\n",
        "             return np.zeros((targets_original_np.shape[0], prediction_horizon))\n",
        "        except: return None\n",
        "\n",
        "\n",
        "def evaluate_model_performance(model, test_loader, device, o3_scaler, o3_threshold_8h, prediction_horizon):\n",
        "    \"\"\"Arvioi mallia testidatalla, laskee metriikat ja vertaa baselineen (PARANNETTU VIRHEIDENKÄSITTELY).\"\"\"\n",
        "    print(\"\\n--- evaluate_model_performance -funktion suoritus alkaa ---\")\n",
        "\n",
        "    # Alkutarkistukset\n",
        "    if model is None: print(\"evaluate_model_performance: Malli puuttuu.\"); return None, None\n",
        "    if test_loader is None: print(\"evaluate_model_performance: Testilataaja puuttuu.\"); return None, None\n",
        "    if o3_scaler is None: print(\"evaluate_model_performance: O3-skaalain puuttuu.\"); return None, None\n",
        "\n",
        "    preds_original_scale = None\n",
        "    targets_original_squeezed = None # Alustetaan Noneksi\n",
        "\n",
        "    try: # Kääritään koko toiminnallisuus try-exceptiin\n",
        "        model.eval() # Arviointitila\n",
        "        all_preds_scaled_list = []\n",
        "        all_targets_original_list = []\n",
        "\n",
        "        print(\"Aloitetaan ennusteiden tekeminen testidatalla...\")\n",
        "        if len(test_loader.dataset) == 0:\n",
        "             print(\"Testidata on tyhjä, ei voida tehdä ennusteita.\")\n",
        "             return None, None\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # Huom: test_loader tuottaa nyt (inputs, targets_original_batch)\n",
        "            for inputs, targets_original_batch in tqdm(test_loader, desc=\"Testaus (evaluate)\"):\n",
        "                inputs = inputs.to(device)\n",
        "                outputs_scaled = model(inputs)\n",
        "                all_preds_scaled_list.append(outputs_scaled.cpu().numpy())\n",
        "                # targets_original_batch muoto: (batch, horizon, 1)\n",
        "                all_targets_original_list.append(targets_original_batch.cpu().numpy())\n",
        "        print(\"Ennusteiden tekeminen valmis.\")\n",
        "\n",
        "        # Varmista, ettei listat ole tyhjiä ennen concatenatea\n",
        "        if not all_preds_scaled_list or not all_targets_original_list:\n",
        "            print(\"VIRHE: Ennusteiden tai kohteiden keräys epäonnistui (listat tyhjiä).\")\n",
        "            return None, None\n",
        "\n",
        "        all_preds_scaled = np.concatenate(all_preds_scaled_list, axis=0)\n",
        "        all_targets_original = np.concatenate(all_targets_original_list, axis=0) # Muoto (samples, horizon, 1)\n",
        "\n",
        "        print(\"Aloitetaan ennusteiden skaalauksen kääntö...\")\n",
        "        n_samples = all_preds_scaled.shape[0]\n",
        "        n_features_out = all_preds_scaled.shape[1]\n",
        "        preds_reshaped = all_preds_scaled.reshape(-1, 1)\n",
        "        preds_original_scale = o3_scaler.inverse_transform(preds_reshaped).reshape(n_samples, n_features_out) # Muoto (samples, horizon)\n",
        "        print(\"GRU-mallin ennusteet käännetty alkuperäiseen skaalaan.\")\n",
        "\n",
        "        print(\"Aloitetaan kohdearvojen muodon tarkistus/muokkaus...\")\n",
        "        if all_targets_original.ndim == 3 and all_targets_original.shape[-1] == 1:\n",
        "            print(f\"Muutetaan kohdemuoto {all_targets_original.shape} -> 2D käyttämällä squeeze(-1)...\")\n",
        "            targets_original_squeezed = all_targets_original.squeeze(-1) # Muoto (samples, horizon)\n",
        "        elif all_targets_original.ndim == 2:\n",
        "             targets_original_squeezed = all_targets_original # Muoto on jo oikea\n",
        "             print(f\"Kohdemuoto on jo 2D: {targets_original_squeezed.shape}\")\n",
        "        else:\n",
        "            print(f\"VIRHE: Odottamaton kohdemuoto ({all_targets_original.shape}) metriikoiden laskentaa varten!\")\n",
        "            raise ValueError(\"Virheellinen kohdemuoto metriikoiden laskentaan.\")\n",
        "\n",
        "        print(\"Kohdemuoto tarkistettu/muokattu.\")\n",
        "        if targets_original_squeezed is None: raise ValueError(\"targets_original_squeezed on None muokkauksen jälkeen!\")\n",
        "        if targets_original_squeezed.shape != preds_original_scale.shape:\n",
        "             raise ValueError(f\"Muodot eivät täsmää ennen metriikoiden laskentaa: Pred={preds_original_scale.shape}, Target={targets_original_squeezed.shape}\")\n",
        "\n",
        "\n",
        "        # --- Laske regressiometriikat (GRU) ---\n",
        "        print(\"Lasketaan GRU-mallin regressiometriikat...\")\n",
        "        rmse_gru = np.sqrt(mean_squared_error(targets_original_squeezed, preds_original_scale))\n",
        "        mae_gru = mean_absolute_error(targets_original_squeezed, preds_original_scale)\n",
        "        print(f\"\\n--- GRU-Mallin Arviointi (kaikki {prediction_horizon} tuntia) ---\")\n",
        "        print(f\"RMSE: {rmse_gru:.4f} µg/m³\")\n",
        "        print(f\"MAE:  {mae_gru:.4f} µg/m³\")\n",
        "\n",
        "        # --- Laske Baseline ---\n",
        "        baseline_preds_original = calculate_baseline_persistence(all_targets_original, prediction_horizon) # Käyttää 3D-muotoa sisäisesti\n",
        "        if baseline_preds_original is None: raise ValueError(\"Baseline-laskenta palautti None.\")\n",
        "\n",
        "        # --- Laske regressiometriikat (Baseline) ---\n",
        "        print(\"Lasketaan Baseline-mallin regressiometriikat...\")\n",
        "        if baseline_preds_original.shape != targets_original_squeezed.shape:\n",
        "             print(f\"VAROITUS: Baseline-ennusteen muoto ({baseline_preds_original.shape}) ei täsmää kohteen muotoon ({targets_original_squeezed.shape})\")\n",
        "             rmse_baseline, mae_baseline = None, None\n",
        "        else:\n",
        "            rmse_baseline = np.sqrt(mean_squared_error(targets_original_squeezed, baseline_preds_original))\n",
        "            mae_baseline = mean_absolute_error(targets_original_squeezed, baseline_preds_original)\n",
        "            print(f\"\\n--- Baseline-Mallin Arviointi (Naiivi Persistenssi) ---\")\n",
        "            print(f\"RMSE: {rmse_baseline:.4f} µg/m³\")\n",
        "            print(f\"MAE:  {mae_baseline:.4f} µg/m³\")\n",
        "\n",
        "        # --- Vertailu ---\n",
        "        print(\"\\n--- Vertailu Baselineen ---\")\n",
        "        # ... (vertailutulostukset kuten ennen) ...\n",
        "        if rmse_gru is not None and rmse_baseline is not None:\n",
        "            improvement_rmse = rmse_baseline - rmse_gru\n",
        "            print(f\"GRU vs Baseline RMSE: {improvement_rmse:+.4f} µg/m³ ({'GRU parempi' if improvement_rmse > 0 else 'Baseline parempi tai sama'})\")\n",
        "        else: print(\"RMSE-vertailua ei voida tehdä.\")\n",
        "        if mae_gru is not None and mae_baseline is not None:\n",
        "            improvement_mae = mae_baseline - mae_gru\n",
        "            print(f\"GRU vs Baseline MAE:  {improvement_mae:+.4f} µg/m³ ({'GRU parempi' if improvement_mae > 0 else 'Baseline parempi tai sama'})\")\n",
        "        else: print(\"MAE-vertailua ei voida tehdä.\")\n",
        "\n",
        "        # --- 8h Liukuvan keskiarvon laskenta ---\n",
        "        targets_for_rolling = targets_original_squeezed # Käytetään jo tarkistettua 2D-muotoa\n",
        "        warnings_actual = []\n",
        "        warnings_pred = []\n",
        "        print(f\"\\nLasketaan 8h liukuvia keskiarvoja ja verrataan kynnysarvoon ({o3_threshold_8h} µg/m³)...\")\n",
        "\n",
        "        # Varmistetaan vielä muodot ennen looppia\n",
        "        if preds_original_scale.shape != targets_for_rolling.shape:\n",
        "             raise ValueError(f\"Muodot eivät vieläkään täsmää ennen liukuvien keskiarvojen laskentaa: Pred={preds_original_scale.shape}, Target={targets_for_rolling.shape}\")\n",
        "\n",
        "        for i in range(n_samples):\n",
        "            actual_24h = targets_for_rolling[i, :]\n",
        "            pred_24h = preds_original_scale[i, :]\n",
        "            actual_series = pd.Series(actual_24h)\n",
        "            pred_series = pd.Series(pred_24h)\n",
        "            actual_8h_avg = actual_series.rolling(window=8, min_periods=1).mean()\n",
        "            pred_8h_avg = pred_series.rolling(window=8, min_periods=1).mean()\n",
        "            actual_warning_triggered = actual_8h_avg.max() > o3_threshold_8h\n",
        "            pred_warning_triggered = pred_8h_avg.max() > o3_threshold_8h\n",
        "            warnings_actual.append(actual_warning_triggered)\n",
        "            warnings_pred.append(pred_warning_triggered)\n",
        "\n",
        "        warnings_actual = np.array(warnings_actual)\n",
        "        warnings_pred = np.array(warnings_pred)\n",
        "        print(\"Liukuvien keskiarvojen laskenta valmis.\")\n",
        "\n",
        "        # --- Tulosta 8h varoitusmetriikat ---\n",
        "        print(\"\\n--- 8h Liukuvan Keskiarvon Varoitustason Ylityksen Arviointi (GRU-malli) ---\")\n",
        "        # ... (tulostukset kuten ennen) ...\n",
        "        print(f\"Todellisia varoitusjaksoja testidatassa (> {o3_threshold_8h} µg/m³): {warnings_actual.sum()} / {n_samples}\")\n",
        "        print(f\"Ennustettuja varoitusjaksoja (GRU):                      {warnings_pred.sum()} / {n_samples}\")\n",
        "\n",
        "        if warnings_actual.sum() > 0 or warnings_pred.sum() > 0:\n",
        "            print(\"\\nSekaannusmatriisi (Confusion Matrix) varoituksille (GRU):\")\n",
        "            cm = confusion_matrix(warnings_actual, warnings_pred, labels=[False, True])\n",
        "            cm_df = pd.DataFrame(cm, index=['Todellinen EI Varoitusta', 'Todellinen KYLLÄ Varoitus'],\n",
        "                               columns=['Ennuste EI', 'Ennuste KYLLÄ'])\n",
        "            print(cm_df)\n",
        "            print(\"\\nLuokitteluraportti varoituksille (GRU):\")\n",
        "            report = classification_report(warnings_actual, warnings_pred, target_names=['Ei Varoitusta', 'Varoitus'], labels=[False, True], zero_division=0)\n",
        "            print(report)\n",
        "            recall_warning = cm[1, 1] / (cm[1, 0] + cm[1, 1]) if (cm[1, 0] + cm[1, 1]) > 0 else 0\n",
        "            precision_warning = cm[1, 1] / (cm[0, 1] + cm[1, 1]) if (cm[0, 1] + cm[1, 1]) > 0 else 0\n",
        "            print(f\"\\n---> TÄRKEIMMÄT VAROITUSMETRIIKAT:\")\n",
        "            print(f\"  Recall (Herkkyys) 'Varoitus'-luokalle: {recall_warning:.4f}\")\n",
        "            print(f\"    (Kuinka monta % todellisista varoitusjaksoista tunnistettiin?)\\n\")\n",
        "            print(f\"  Precision (Tarkkuus) 'Varoitus'-luokalle: {precision_warning:.4f}\")\n",
        "            print(f\"    (Kuinka monta % mallin antamista varoituksista oli oikeita?)\\n\")\n",
        "        else:\n",
        "            print(\"\\nEi todellisia eikä ennustettuja varoitusjaksoja testidatassa kynnysarvolla.\")\n",
        "            print(\"   -> Luokittelumetriikoita ei voida laskea.\")\n",
        "\n",
        "\n",
        "        print(\"\\n--- evaluate_model_performance -funktion suoritus päättyi onnistuneesti ---\")\n",
        "        # Palauta alkuperäiset ennusteet ja kohteet (squeezeituna)\n",
        "        return preds_original_scale, targets_original_squeezed # Palautetaan puristettu kohde\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n-----> VIRHE evaluate_model_performance -FUNKTIOSSA <-----\")\n",
        "        print(f\"Virhetyyppi: {type(e).__name__}\")\n",
        "        print(f\"Virheilmoitus: {e}\")\n",
        "        print(\"Traceback:\")\n",
        "        traceback.print_exc() # Tulosta koko traceback\n",
        "        print(\"---------------------------------------------------------\")\n",
        "        print(\"Palautetaan None, None, koska arviointi epäonnistui.\")\n",
        "        return None, None # Palauta None virhetilanteessa\n",
        "\n",
        "print(\"Osa 7: Arviointifunktioiden määrittely - OK\")"
      ],
      "metadata": {
        "id": "zM8l1xNO8i8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 8. Mallin Arviointi (Suoritus) (Oikea Sijainti)\n",
        "\n",
        "# --- Alustetaan tulosmuuttujat ---\n",
        "if 'test_preds_orig' not in locals(): test_preds_orig = None\n",
        "if 'test_targets_orig' not in locals(): test_targets_orig = None\n",
        "evaluation_successful = False # Lipuke onnistumiselle\n",
        "\n",
        "# --- Suoritetaan arviointi (jos malli koulutettu ja funktio määritelty) ---\n",
        "# Tarkistetaan, onko model olemassa ja koulutettu (ei None)\n",
        "if 'model' in locals() and model is not None:\n",
        "    # Tarkistetaan, onko arviointifunktio määritelty\n",
        "    if 'evaluate_model_performance' in locals():\n",
        "        # Varmista myös muiden tarvittavien muuttujien olemassaolo\n",
        "        if 'test_loader' in locals() and test_loader is not None and \\\n",
        "           'o3_scaler' in locals() and o3_scaler is not None and \\\n",
        "           'device' in locals() and \\\n",
        "           'O3_THRESHOLD_8H_AVG' in locals() and \\\n",
        "           'PREDICTION_HORIZON' in locals():\n",
        "\n",
        "            print(\"\\n--- Mallin Arviointi (Suoritus) ---\")\n",
        "            # Kutsutaan paranneltua arviointifunktiota\n",
        "            temp_preds, temp_targets = evaluate_model_performance(\n",
        "                model, test_loader, device, o3_scaler, O3_THRESHOLD_8H_AVG, PREDICTION_HORIZON\n",
        "            )\n",
        "            # Päivitä globaalit muuttujat vain jos palautus ei ollut None\n",
        "            if temp_preds is not None and temp_targets is not None:\n",
        "                 test_preds_orig = temp_preds\n",
        "                 test_targets_orig = temp_targets\n",
        "                 evaluation_successful = True\n",
        "                 print(\"Arviointi suoritettu onnistuneesti.\")\n",
        "            else:\n",
        "                 print(\"Arviointi epäonnistui (evaluate_model_performance palautti None).\")\n",
        "                 test_preds_orig, test_targets_orig = None, None # Varmista Noneksi\n",
        "\n",
        "        else:\n",
        "            print(\"\\nArviointia ei voida suorittaa puuttuvien muuttujien vuoksi (test_loader, o3_scaler, tms.).\")\n",
        "    else:\n",
        "        print(\"\\nArviointia ei voida suorittaa, koska `evaluate_model_performance`-funktiota ei ole määritelty (aja Osa 7).\")\n",
        "else:\n",
        "     print(\"\\nArviointia ei voida suorittaa, koska mallia (`model`) ei ole koulutettu onnistuneesti (aja Osa 6).\")\n",
        "\n",
        "if evaluation_successful:\n",
        "     print(\"\\nOsa 8: Arvioinnin suoritus - VALMIS\")\n",
        "else:\n",
        "     print(\"\\nOsa 8: Arvioinnin suoritus - EPÄONNISTUI / OHITETTIIN\")"
      ],
      "metadata": {
        "id": "iv9eBCqY9OjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 9. Viimeisimmän Ennustejakson Huippuarvo (Oikea Sijainti)\n",
        "\n",
        "print(\"\\n--- Analysoidaan viimeisintä ennustejaksoa ---\")\n",
        "\n",
        "# Varmistetaan, että arvioinnin tulokset ovat olemassa ja oikean tyyppisiä\n",
        "# (Oletetaan, että Osa 8, joka kutsuu evaluate_model_performance, on ajettu)\n",
        "latest_analysis_possible = False\n",
        "if 'test_preds_orig' in locals() and isinstance(test_preds_orig, np.ndarray) and \\\n",
        "   'test_timestamps' in locals() and test_timestamps is not None:\n",
        "\n",
        "    if len(test_preds_orig) > 0 and len(test_timestamps) == len(test_preds_orig):\n",
        "        latest_analysis_possible = True\n",
        "        try:\n",
        "            # Otetaan viimeisin ennustettu 24h jakso\n",
        "            latest_prediction_sequence = test_preds_orig[-1] # Muoto (24,)\n",
        "\n",
        "            # Otetaan viimeisen ennustejakson alkuaika\n",
        "            prediction_start_time = test_timestamps[-1]\n",
        "\n",
        "            # Etsitään korkein arvo ja sen indeksi (0-23) jaksolta\n",
        "            max_index = np.argmax(latest_prediction_sequence)\n",
        "            max_value = latest_prediction_sequence[max_index]\n",
        "\n",
        "            # Lasketaan korkeimman arvon tarkka aika\n",
        "            time_of_max = prediction_start_time + pd.Timedelta(hours=int(max_index))\n",
        "\n",
        "            print(f\"\\nViimeisin ennustettu 24h jakso alkaa: {prediction_start_time.strftime('%Y-%m-%d %H:%M')}\")\n",
        "            print(\"-\" * 40)\n",
        "            print(f\"Korkein ennustettu O3-arvo: {max_value:.2f} µg/m³\")\n",
        "            print(f\"Ajankohta: {time_of_max.strftime('%A, %d.%m.%Y klo %H:%M')}\")\n",
        "            print(\"-\" * 40)\n",
        "\n",
        "        except IndexError:\n",
        "             print(\"\\nVirhe viimeisimmän jakson indeksissä (todennäköisesti tyhjä data).\")\n",
        "             latest_analysis_possible = False # Merkitään epäonnistuneeksi\n",
        "        except Exception as e:\n",
        "            print(f\"\\nVirhe viimeisimmän ennustejakson analysoinnissa: {e}\")\n",
        "            traceback.print_exc()\n",
        "            latest_analysis_possible = False # Merkitään epäonnistuneeksi\n",
        "\n",
        "    else:\n",
        "        print(\"\\nEi voitu analysoida viimeisintä jaksoa: Ennusteita tai aikaleimoja ei löytynyt tai niiden pituudet eivät täsmää.\")\n",
        "else:\n",
        "    print(\"\\nEi voitu analysoida viimeisintä jaksoa, koska arvioinnin tuloksia ('test_preds_orig', 'test_timestamps') ei ole saatavilla (Aja ensin Osa 8).\")\n",
        "\n",
        "if latest_analysis_possible:\n",
        "     print(\"\\nOsa 9: Huippuarvon analyysi - VALMIS\")\n",
        "else:\n",
        "     print(\"\\nOsa 9: Huippuarvon analyysi - EPÄONNISTUI / OHITETTIIN\")"
      ],
      "metadata": {
        "id": "ip0vRGbs9xgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 10. Visualisointi (Suoritus) (Oikea Sijainti)\n",
        "\n",
        "print(\"\\n--- Visualisointi (Suoritus) ---\")\n",
        "# --- Suoritetaan visualisointi (jos arviointi onnistui ja palautti tulokset) ---\n",
        "# Varmistetaan myös test_timestamps muuttujan olemassaolo\n",
        "if 'test_timestamps' not in locals(): test_timestamps = None\n",
        "\n",
        "# Tarkistetaan, että molemmat (ennusteet JA kohteet) ovat olemassa ja validit\n",
        "if 'test_preds_orig' in locals() and isinstance(test_preds_orig, np.ndarray) and \\\n",
        "   'test_targets_orig' in locals() and isinstance(test_targets_orig, np.ndarray):\n",
        "\n",
        "    if test_timestamps is not None:\n",
        "        num_test_samples = len(test_preds_orig)\n",
        "\n",
        "        # Tarkistetaan pituudet ennen jatkamista\n",
        "        lengths_ok = (num_test_samples > 0 and\n",
        "                      test_targets_orig.shape[0] == num_test_samples and\n",
        "                      len(test_timestamps) == num_test_samples)\n",
        "\n",
        "        if lengths_ok:\n",
        "            # --- Kuvaaja 1: Esimerkkijakson ennuste vs. Todellinen ---\n",
        "            sample_idx = np.random.randint(0, num_test_samples)\n",
        "            print(f\"\\nPiirretään visualisoinnit testijaksolle #{sample_idx} (indeksi)...\")\n",
        "\n",
        "            try: # Try-except kuvaajan piirron ympärille\n",
        "                plt.figure(figsize=(16, 7))\n",
        "                start_time = test_timestamps[sample_idx]\n",
        "                time_axis = pd.date_range(start=start_time, periods=PREDICTION_HORIZON, freq='h')\n",
        "\n",
        "                targets_plot = test_targets_orig[sample_idx, :] # Pitäisi olla 1D (horizon,)\n",
        "                if targets_plot.ndim != 1: raise ValueError(f\"targets_plot muoto {targets_plot.shape}, odotettiin 1D\")\n",
        "\n",
        "                plt.plot(time_axis, targets_plot, label='Todellinen O3', marker='.', linewidth=1.5, alpha=0.8, color='royalblue', zorder=3)\n",
        "                plt.plot(time_axis, test_preds_orig[sample_idx, :], label='Ennuste O3 (GRU)', marker='.', linestyle='--', linewidth=1.5, alpha=0.8, color='darkorange', zorder=4)\n",
        "\n",
        "                try: # Try-except liukuville keskiarvoille\n",
        "                    actual_series_sample = pd.Series(targets_plot, index=time_axis)\n",
        "                    pred_series_sample = pd.Series(test_preds_orig[sample_idx, :], index=time_axis)\n",
        "                    actual_8h_avg_sample = actual_series_sample.rolling(window=8, min_periods=1).mean()\n",
        "                    pred_8h_avg_sample = pred_series_sample.rolling(window=8, min_periods=1).mean()\n",
        "\n",
        "                    plt.plot(time_axis, actual_8h_avg_sample, label='Todellinen 8h ka.', color='blue', linestyle='-', linewidth=2.5, alpha=0.5, zorder=1)\n",
        "                    plt.plot(time_axis, pred_8h_avg_sample, label='Ennustettu 8h ka.', color='red', linestyle=':', linewidth=2.5, alpha=0.5, zorder=2)\n",
        "                except Exception as e_roll:\n",
        "                     print(f\"VAROITUS: Virhe liukuvien keskiarvojen laskennassa tai piirrossa: {e_roll}\")\n",
        "\n",
        "                plt.axhline(O3_THRESHOLD_8H_AVG, color='crimson', linestyle='-.', linewidth=2, label=f'8h Varoitusraja ({O3_THRESHOLD_8H_AVG} µg/m³)', zorder=5)\n",
        "                plt.title(f'O3 Ennuste vs Todellinen - Testijakso #{sample_idx} (Alkaen {start_time.strftime(\"%Y-%m-%d %H:%M\")})', fontsize=14)\n",
        "                plt.xlabel('Aika', fontsize=12); plt.ylabel('O3 Pitoisuus (µg/m³)', fontsize=12)\n",
        "                plt.legend(loc='best', fontsize=10); plt.grid(True, linestyle=':', alpha=0.6)\n",
        "                plt.xticks(rotation=30, ha='right'); plt.tight_layout(); plt.show()\n",
        "\n",
        "            except Exception as e_fig1:\n",
        "                 print(f\"VIRHE Kuvaaja 1 piirrossa: {e_fig1}\")\n",
        "                 traceback.print_exc()\n",
        "\n",
        "\n",
        "            # --- Kuvaaja 2: Hajontakuvaaja (Ennuste t+1 vs Todellinen t+1) ---\n",
        "            try: # Try-except kuvaajan piirron ympärille\n",
        "                plt.figure(figsize=(7, 7))\n",
        "                preds_t_plus_1 = test_preds_orig[:, 0]\n",
        "                targets_t_plus_1 = test_targets_orig[:, 0] # Pitäisi olla 1D (samples,)\n",
        "\n",
        "                if targets_t_plus_1.ndim != 1 or preds_t_plus_1.ndim != 1:\n",
        "                     raise ValueError(f\"Hajontakuvaajan datamuodot väärin: Target={targets_t_plus_1.shape}, Pred={preds_t_plus_1.shape}\")\n",
        "\n",
        "                plt.scatter(targets_t_plus_1, preds_t_plus_1, alpha=0.3, label='Ennusteet (t+1)', s=20, edgecolors='k', linewidth=0.5)\n",
        "                valid_targets = targets_t_plus_1[~np.isnan(targets_t_plus_1) & ~np.isinf(targets_t_plus_1)]\n",
        "                valid_preds = preds_t_plus_1[~np.isnan(preds_t_plus_1) & ~np.isinf(preds_t_plus_1)]\n",
        "\n",
        "                if len(valid_targets) > 0 and len(valid_preds) > 0:\n",
        "                     min_val = min(valid_targets.min(), valid_preds.min()) - 5\n",
        "                     max_val = max(valid_targets.max(), valid_preds.max()) + 5\n",
        "                     if np.isfinite(min_val) and np.isfinite(max_val) and max_val > min_val:\n",
        "                         plt.plot([min_val, max_val], [min_val, max_val], color='red', linestyle='--', linewidth=2, label='Ihanteellinen (y=x)')\n",
        "                         plt.xlim(min_val, max_val); plt.ylim(min_val, max_val)\n",
        "                     else: print(\"VAROITUS: Ei voitu asettaa järkeviä akseleiden rajoja hajontakuvaajalle.\")\n",
        "                else: print(\"VAROITUS: Ei voitu määrittää akseleiden rajoja hajontakuvaajalle (ei validia dataa).\")\n",
        "\n",
        "                plt.title('Hajontakuvaaja: Ennuste vs Todellinen (tunti t+1)', fontsize=14)\n",
        "                plt.xlabel('Todellinen O3 (t+1) [µg/m³]', fontsize=12); plt.ylabel('Ennustettu O3 (t+1) [µg/m³]', fontsize=12)\n",
        "                plt.grid(True, linestyle=':', alpha=0.6); plt.legend(fontsize=10)\n",
        "                plt.gca().set_aspect('equal', adjustable='box'); plt.tight_layout(); plt.show()\n",
        "\n",
        "            except Exception as e_fig2:\n",
        "                 print(f\"VIRHE Kuvaaja 2 piirrossa: {e_fig2}\")\n",
        "                 traceback.print_exc()\n",
        "\n",
        "        else:\n",
        "            print(\"Testidataa ei löytynyt visualisointia varten tai pituudet eivät täsmää.\")\n",
        "            # Tulostetaan pituudet debuggausta varten\n",
        "            print(f\"Num test samples (preds): {num_test_samples if test_preds_orig is not None else 'N/A'}\")\n",
        "            if test_targets_orig is not None: print(f\"Targets shape: {test_targets_orig.shape}\")\n",
        "            if test_timestamps is not None: print(f\"Timestamps len: {len(test_timestamps)}\")\n",
        "\n",
        "    else:\n",
        "        missing_vars_msg = []\n",
        "        if test_preds_orig is None: missing_vars_msg.append('test_preds_orig')\n",
        "        if test_targets_orig is None: missing_vars_msg.append('test_targets_orig')\n",
        "        if test_timestamps is None: missing_vars_msg.append('test_timestamps')\n",
        "        print(f\"\\nVisualisointia ei voida suorittaa puuttuvien/virheellisten tulosten vuoksi: {missing_vars_msg}\")\n",
        "else:\n",
        "     # Jos päädyttiin tänne, joko malli puuttui tai arviointi epäonnistui aiemmin\n",
        "     print(\"\\nVisualisointia ei suoriteta, koska mallia ei ole koulutettu tai arviointi epäonnistui/ohitettiin.\")\n",
        "\n",
        "\n",
        "# Varmistetaan, että skriptin lopputuloste tulee aina\n",
        "if 'print' in locals():\n",
        "     print(\"\\n--- Skriptilohkon (Osa 10) suoritus päättyi ---\")"
      ],
      "metadata": {
        "id": "2W1BPd3b96g4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}