{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmbN3bZBrqPUZ3af44yHtv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rrwiren/ilmanlaatu-ennuste-helsinki/blob/main/Arima_pilkottu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNdQ3lZJJcgj"
      },
      "outputs": [],
      "source": [
        "# @title 0. Esitiedot ja Tavoite (ARIMA)\n",
        "\"\"\"\n",
        "Otsoniennuste Helsinki - ARIMA-malli\n",
        "\n",
        "Tavoite:\n",
        "1. Ladata uusi esikäsitelty data (sis. pilvisyys) Parquet-tiedostosta.\n",
        "2. Sovittaa ARIMA (AutoRegressive Integrated Moving Average) -malli\n",
        "   Otsoni [µg/m³] -aikasarjaan.\n",
        "3. Tehdä ennusteita testijaksolle (seuraavat 24 tuntia).\n",
        "4. Arvioida mallin suorituskykyä (RMSE, MAE) ja verrata baselineen.\n",
        "\n",
        "HUOM: Perus-ARIMA-malli käyttää vain kohdemuuttujan (Otsoni) omaa\n",
        "historiaa ennustamiseen, EI muita säämuuttujia (kuten lämpötila, pilvisyys).\n",
        "Jos halutaan sisällyttää muita muuttujia, tarvitaan ARIMAX tai SARIMAX -malleja.\n",
        "\"\"\"\n",
        "print(\"Osa 0: Esitiedot - OK\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 1. Tuonnit ja Asetukset (ARIMA) - Kokeillaan AR(1)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "import io\n",
        "import os\n",
        "import warnings # Varoitusten hallintaan\n",
        "\n",
        "# Tilastollinen mallinnus ja aikasarja-analyysi\n",
        "from statsmodels.tsa.stattools import adfuller # Stationaarisuustesti\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf # ACF/PACF-kuvaajat\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "\n",
        "# Mahdollisesti hyödyllinen automaattiseen kertalukujen valintaan\n",
        "try:\n",
        "    import pmdarima as pm\n",
        "    AUTO_ARIMA_AVAILABLE = True\n",
        "except ImportError:\n",
        "    # print(\"VAROITUS: Kirjastoa 'pmdarima' ei löytynyt. auto_arima ei ole käytettävissä.\")\n",
        "    AUTO_ARIMA_AVAILABLE = False # Varmistetaan Falseksi\n",
        "\n",
        "# Arviointimetriikat\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "# Asetukset kuvaajille\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "# Estetään turhia varoituksia\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# --- Data-asetukset ---\n",
        "BASE_GITHUB_URL = 'https://raw.githubusercontent.com/rrwiren/ilmanlaatu-ennuste-helsinki/main/'\n",
        "PARQUET_PATH = 'data/processed/processed_Helsinki_O3_Weather_Cloudiness_2024_2025_v3.parquet'\n",
        "DATA_URL = BASE_GITHUB_URL + PARQUET_PATH\n",
        "TARGET_COLUMN = 'Otsoni [µg/m³]'\n",
        "\n",
        "# --- Mallinnusasetukset ---\n",
        "FORECAST_HORIZON = 24\n",
        "TEST_SPLIT_RATIO = 0.15\n",
        "# TEST_START_DATE = '2025-03-15' # Vaihtoehtoinen\n",
        "\n",
        "# ARIMA-parametrit (p, d, q)\n",
        "# *** MUUTOS TÄSSÄ: Kokeillaan yksinkertaisempaa AR(1) eli (1, 0, 0) mallia ***\n",
        "# d=0 päätettiin aiemmin stationaarisuuden perusteella\n",
        "ARIMA_ORDER = (1, 0, 0) # Testataan p=1, d=0, q=0\n",
        "\n",
        "# Käytetäänkö pmdarima.auto_arimaa (ei käytössä nyt)\n",
        "USE_AUTO_ARIMA = False # Asetetaan Falseksi varmuuden vuoksi\n",
        "\n",
        "print(\"Osa 1: Tuonnit ja Asetukset - OK (ARIMA_ORDER vaihdettu)\")\n",
        "if AUTO_ARIMA_AVAILABLE and USE_AUTO_ARIMA:\n",
        "     print(\"pmdarima löytyi, mutta auto_arima ei ole nyt käytössä (USE_AUTO_ARIMA=False).\")\n",
        "elif not AUTO_ARIMA_AVAILABLE:\n",
        "     print(\"pmdarima EI löytynyt, kertaluvut (p,q) pitää määrittää manuaalisesti.\")"
      ],
      "metadata": {
        "id": "iuxK-eXDOfyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 2. Datan Lataus ja Peruskäsittely (ARIMA)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "import io\n",
        "import traceback # Virheiden jäljitykseen\n",
        "\n",
        "print(\"--- Aloitetaan Datan Lataus ja Peruskäsittely ---\")\n",
        "\n",
        "# Alustetaan muuttujat Noneksi siltä varalta, että jokin vaihe epäonnistuu\n",
        "data_series = None\n",
        "train_data = None\n",
        "test_data = None\n",
        "\n",
        "try:\n",
        "    # 1. Lataa data Parquet-tiedostosta URL:n kautta\n",
        "    print(f\"Ladataan dataa: {DATA_URL}\")\n",
        "    response = requests.get(DATA_URL)\n",
        "    response.raise_for_status() # Tarkista latausvirheet\n",
        "    # Lue data suoraan muistiin Parquet-muodosta\n",
        "    df_processed = pd.read_parquet(io.BytesIO(response.content))\n",
        "    print(f\"Data ladattu, muoto: {df_processed.shape}\")\n",
        "    print(f\"Sarakkeet: {df_processed.columns.tolist()}\")\n",
        "\n",
        "    # 2. Varmista DatetimeIndex\n",
        "    if not isinstance(df_processed.index, pd.DatetimeIndex):\n",
        "        print(\"Indeksi ei ole DatetimeIndex. Yritetään muuntaa...\")\n",
        "        try:\n",
        "            df_processed.index = pd.to_datetime(df_processed.index)\n",
        "            # Jos aikavyöhykettä ei ole, mutta oletetaan että se on paikallinen\n",
        "            if df_processed.index.tz is None:\n",
        "                 print(\"Asetetaan aikavyöhykkeeksi Europe/Helsinki...\")\n",
        "                 # Käytetään robustimpaa tapaa, joka voi käsitellä DST-ongelmia paremmin\n",
        "                 df_processed = df_processed.tz_localize('Europe/Helsinki', ambiguous='NaT', nonexistent='NaT')\n",
        "                 rows_before_nat = len(df_processed)\n",
        "                 df_processed = df_processed.dropna(axis=0, subset=[df_processed.index.name]) # Poista NaT-rivit\n",
        "                 if len(df_processed) < rows_before_nat:\n",
        "                      print(f\"Poistettu {rows_before_nat - len(df_processed)} riviä aikavyöhykkeen asetuksen (NaT) vuoksi.\")\n",
        "\n",
        "            # Tai jos se on UTC, muunnetaan\n",
        "            elif str(df_processed.index.tz).lower() == 'utc':\n",
        "                 print(\"Muunnetaan UTC -> Europe/Helsinki...\")\n",
        "                 df_processed = df_processed.tz_convert('Europe/Helsinki')\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"VIRHE: Aikaleimaindeksin käsittely epäonnistui: {e}\")\n",
        "            raise # Nosta virhe, koska indeksi on kriittinen\n",
        "\n",
        "    df_processed.sort_index(inplace=True)\n",
        "    print(f\"Data aikaväliltä: {df_processed.index.min()} - {df_processed.index.max()}\")\n",
        "\n",
        "    # 3. Valitse vain kohdesarake (Otsoni) ARIMA-mallia varten\n",
        "    if TARGET_COLUMN not in df_processed.columns:\n",
        "        print(f\"VIRHE: Kohdesaraketta '{TARGET_COLUMN}' ei löytynyt datasta!\")\n",
        "        raise KeyError(f\"Sarake '{TARGET_COLUMN}' puuttuu.\")\n",
        "\n",
        "    data_series = df_processed[TARGET_COLUMN].copy()\n",
        "\n",
        "    # Muunnetaan datatyyppi floatiksi varmuuden vuoksi\n",
        "    data_series = pd.to_numeric(data_series, errors='coerce')\n",
        "\n",
        "    # 4. Käsittele mahdolliset puuttuvat arvot kohdesarjassa\n",
        "    initial_length = len(data_series)\n",
        "    data_series.dropna(inplace=True)\n",
        "    removed_na = initial_length - len(data_series)\n",
        "    if removed_na > 0:\n",
        "        print(f\"Poistettu {removed_na} puuttuvaa arvoa kohdesarjasta.\")\n",
        "\n",
        "    if data_series.empty:\n",
        "        raise ValueError(\"Kohdesarake on tyhjä tai sisältää vain puuttuvia arvoja.\")\n",
        "\n",
        "    # Tarkistetaan datan tiheys (oletus tunti)\n",
        "    try:\n",
        "        inferred_freq = pd.infer_freq(data_series.index)\n",
        "        print(f\"Päätelty datan tiheys: {inferred_freq}\")\n",
        "        if inferred_freq != 'h' and inferred_freq != 'H':\n",
        "             print(\"VAROITUS: Datan tiheys ei ole täsmälleen tunti ('H'). Tämä voi vaikuttaa ARIMA-malliin.\")\n",
        "             # Yritetään asettaa tiheys tunniksi, jos puuttuvia aikaleimoja on vähän\n",
        "             # data_series = data_series.asfreq('H')\n",
        "             # print(\"Yritetty asettaa tiheys tunniksi. Uudet NaN-arvot tulee käsitellä.\")\n",
        "    except Exception as e_freq:\n",
        "         print(f\"VAROITUS: Datan tiheyden päättely epäonnistui: {e_freq}\")\n",
        "\n",
        "\n",
        "    # 5. Jaa data harjoitus- ja testijoukkoihin\n",
        "    # Käytetään TEST_SPLIT_RATIO -suhdetta lopusta\n",
        "    split_index = int(len(data_series) * (1 - TEST_SPLIT_RATIO))\n",
        "    train_data = data_series[:split_index]\n",
        "    test_data = data_series[split_index:]\n",
        "\n",
        "    # TAI jos TEST_START_DATE on määritelty osassa 1:\n",
        "    # if 'TEST_START_DATE' in locals() and TEST_START_DATE is not None:\n",
        "    #    print(f\"Käytetään testijakson aloituspäivää: {TEST_START_DATE}\")\n",
        "    #    try:\n",
        "    #        test_start_dt = pd.Timestamp(TEST_START_DATE, tz='Europe/Helsinki') # Määritä aikavyöhyke\n",
        "    #        train_data = data_series[data_series.index < test_start_dt]\n",
        "    #        test_data = data_series[data_series.index >= test_start_dt]\n",
        "    #    except Exception as e_date:\n",
        "    #        print(f\"VIRHE testijakson aloituspäivän käytössä: {e_date}. Käytetään ratio-jakoa.\")\n",
        "    #        split_index = int(len(data_series) * (1 - TEST_SPLIT_RATIO))\n",
        "    #        train_data = data_series[:split_index]\n",
        "    #        test_data = data_series[split_index:]\n",
        "    # else: # Käytä ratio-jakoa jos päivää ei määritelty\n",
        "    #    split_index = int(len(data_series) * (1 - TEST_SPLIT_RATIO))\n",
        "    #    train_data = data_series[:split_index]\n",
        "    #    test_data = data_series[split_index:]\n",
        "\n",
        "\n",
        "    print(f\"\\nDatan jako:\")\n",
        "    print(f\"Harjoitusdata: {len(train_data)} havaintoa ({train_data.index.min()} - {train_data.index.max()})\")\n",
        "    print(f\"Testidata:     {len(test_data)} havaintoa ({test_data.index.min()} - {test_data.index.max()})\")\n",
        "\n",
        "    if len(train_data) == 0 or len(test_data) == 0:\n",
        "         raise ValueError(\"Harjoitus- tai testidata on tyhjä jaon jälkeen.\")\n",
        "\n",
        "    if len(test_data) < FORECAST_HORIZON:\n",
        "        print(f\"VAROITUS: Testidata ({len(test_data)}) on lyhyempi kuin ennustehorisontti ({FORECAST_HORIZON}). Arviointi voi olla epätäydellinen.\")\n",
        "\n",
        "\n",
        "    # 6. Visualisoi aikasarja\n",
        "    print(\"\\nVisualisoidaan aikasarja...\")\n",
        "    plt.figure(figsize=(14, 7))\n",
        "    plt.plot(train_data.index, train_data, label='Harjoitusdata', color='royalblue')\n",
        "    plt.plot(test_data.index, test_data, label='Testidata', color='darkorange')\n",
        "    plt.title(f'{TARGET_COLUMN} Aikasarja')\n",
        "    plt.xlabel('Aika')\n",
        "    plt.ylabel('Otsoni (µg/m³)')\n",
        "    plt.legend()\n",
        "    plt.grid(True, linestyle=':')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\nOsa 2: Datan Lataus ja Peruskäsittely - OK\")\n",
        "\n",
        "except KeyError as e:\n",
        "     print(f\"\\nVIRHE: Saraketta ei löytynyt: {e}. Tarkista TARGET_COLUMN.\")\n",
        "     data_series = None; train_data = None; test_data = None\n",
        "except FileNotFoundError:\n",
        "     print(f\"\\nVIRHE: Tiedostoa ei löytynyt paikallisesta polusta eikä lataus URL:sta onnistunut.\")\n",
        "     data_series = None; train_data = None; test_data = None\n",
        "except requests.exceptions.RequestException as e:\n",
        "     print(f\"\\nVIRHE: Datan lataus URL:sta epäonnistui: {e}\")\n",
        "     data_series = None; train_data = None; test_data = None\n",
        "except ValueError as e:\n",
        "     print(f\"\\nVIRHE datan käsittelyssä (ValueError): {e}\")\n",
        "     data_series = None; train_data = None; test_data = None\n",
        "except Exception as e:\n",
        "     print(f\"\\nOdottamaton VIRHE datan latauksessa tai peruskäsittelyssä: {e}\")\n",
        "     traceback.print_exc()\n",
        "     data_series = None; train_data = None; test_data = None"
      ],
      "metadata": {
        "id": "iHbSZwRRLDZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 3. Stationaarisuuden Tarkastelu ja Differointi (ARIMA)\n",
        "\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np # Varmistetaan numpy tuonti\n",
        "\n",
        "print(\"--- Aloitetaan Stationaarisuuden Tarkastelu ---\")\n",
        "\n",
        "# Varmistetaan, että train_data on olemassa edellisestä solusta\n",
        "if 'train_data' in locals() and train_data is not None and not train_data.empty:\n",
        "\n",
        "    # Funktio ADF-testin suorittamiseen ja tulosten tulkintaan\n",
        "    def perform_adf_test(series, series_name=\"Series\"):\n",
        "        \"\"\"Suorittaa ADF-testin ja tulostaa tulokset selkeästi.\"\"\"\n",
        "        print(f\"\\nSuoritetaan ADF-testi sarjalle: {series_name}\")\n",
        "        # Poista NaN-arvot ennen testiä\n",
        "        result = adfuller(series.dropna())\n",
        "        print(f'ADF Statistic: {result[0]:.4f}')\n",
        "        print(f'p-value: {result[1]:.4f}')\n",
        "        print('Critical Values:')\n",
        "        for key, value in result[4].items():\n",
        "            print(f'\\t{key}: {value:.4f}')\n",
        "\n",
        "        # Tulkinta\n",
        "        if result[1] <= 0.05:\n",
        "            print(f\"-> Tulos: Hylätään nollahypoteesi (p <= 0.05). Sarja '{series_name}' on todennäköisesti stationaarinen.\")\n",
        "            return True # Stationaarinen\n",
        "        else:\n",
        "            print(f\"-> Tulos: Ei voida hylätä nollahypoteesia (p > 0.05). Sarja '{series_name}' EI todennäköisesti ole stationaarinen.\")\n",
        "            return False # Ei stationaarinen\n",
        "\n",
        "    # 1. Testaa alkuperäinen harjoitusdata\n",
        "    is_stationary_orig = perform_adf_test(train_data, \"Alkuperäinen harjoitusdata\")\n",
        "    d = 0 # Alustetaan differoinnin kertaluku\n",
        "    stationary_train_data = train_data # Oletuksena käytetään alkuperäistä, jos se on stationaarinen\n",
        "\n",
        "    # 2. Jos alkuperäinen ei ole stationaarinen, kokeile ensimmäistä differenssiä\n",
        "    if not is_stationary_orig:\n",
        "        print(\"\\nDifferoidaan sarja (1. kertaluku)...\")\n",
        "        train_data_diff1 = train_data.diff().dropna()\n",
        "        is_stationary_diff1 = perform_adf_test(train_data_diff1, \"1. differenssi\")\n",
        "        if is_stationary_diff1:\n",
        "            d = 1\n",
        "            stationary_train_data = train_data_diff1\n",
        "            print(f\"\\n-> Differoinnin kertaluvuksi (d) asetetaan: {d}\")\n",
        "        else:\n",
        "            # 3. Jos ensimmäinen differenssi ei ole stationaarinen, kokeile toista (harvinaisempaa)\n",
        "            print(\"\\nDifferoidaan sarja (2. kertaluku)...\")\n",
        "            train_data_diff2 = train_data_diff1.diff().dropna()\n",
        "            is_stationary_diff2 = perform_adf_test(train_data_diff2, \"2. differenssi\")\n",
        "            if is_stationary_diff2:\n",
        "                d = 2\n",
        "                stationary_train_data = train_data_diff2\n",
        "                print(f\"\\n-> Differoinnin kertaluvuksi (d) asetetaan: {d}\")\n",
        "            else:\n",
        "                print(\"\\nVAROITUS: Sarja ei näytä tulevan stationaariseksi edes toisella differoinnilla.\")\n",
        "                print(\"Käytetään silti toista differenssiä jatkossa, mutta mallin tulokset voivat olla epäluotettavia.\")\n",
        "                d = 2 # Käytetään arvoa 2, vaikka testi ei menisi läpi\n",
        "                stationary_train_data = train_data_diff2\n",
        "    else:\n",
        "        print(f\"\\n-> Differoinnin kertaluvuksi (d) asetetaan: {d}\")\n",
        "\n",
        "\n",
        "    # 4. Visualisoi alkuperäinen ja mahdollinen differoitu sarja\n",
        "    plt.figure(figsize=(14, 8))\n",
        "\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.plot(train_data.index, train_data, label='Alkuperäinen harjoitusdata')\n",
        "    plt.title('Alkuperäinen Otsoni Aikasarja (Harjoitusdata)')\n",
        "    plt.legend()\n",
        "    plt.grid(True, linestyle=':')\n",
        "\n",
        "    # Piirrä differoitu sarja vain jos differointia tehtiin\n",
        "    if d > 0:\n",
        "        plt.subplot(2, 1, 2)\n",
        "        plt.plot(stationary_train_data.index, stationary_train_data, label=f'{d}. differenssi', color='orange')\n",
        "        plt.title(f'{d}. Asteen Differoitu Aikasarja')\n",
        "        plt.legend()\n",
        "        plt.grid(True, linestyle=':')\n",
        "    elif 'stationary_train_data' not in locals(): # Jos d=0, mutta muuttujaa ei jostain syystä asetettu\n",
        "         stationary_train_data = train_data # Varmistus\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Tallennetaan differoinnin kertaluku myöhempää käyttöä varten\n",
        "    ARIMA_ORDER = (ARIMA_ORDER[0], d, ARIMA_ORDER[2]) # Päivitetään d-arvo\n",
        "    print(f\"\\nARIMA-mallin differoinnin kertaluku 'd' on nyt: {d}\")\n",
        "    print(\"Seuraavassa vaiheessa määritetään 'p' ja 'q' ACF/PACF-kuvaajien avulla.\")\n",
        "    print(\"\\nOsa 3: Stationaarisuuden Tarkastelu - OK\")\n",
        "\n",
        "else:\n",
        "    print(\"VIRHE: Harjoitusdataa ('train_data') ei löytynyt edellisestä solusta. Aja edellinen solu uudelleen.\")\n",
        "    # Asetetaan d varmuuden vuoksi Noneksi, jos data puuttuu\n",
        "    d = None\n",
        "    stationary_train_data = None"
      ],
      "metadata": {
        "id": "J56jlD5ZLaAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 4. ARIMA Kertalukujen (p, q) Määritys (ACF/PACF)\n",
        "\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"--- Määritetään ARIMA kertalukuja p ja q (d=0) ---\")\n",
        "\n",
        "# Varmistetaan, että stationaarinen data on olemassa edellisestä solusta\n",
        "# Koska d=0, käytämme alkuperäistä harjoitusdataa (joka on tallessa stationary_train_data -muuttujassa)\n",
        "if 'stationary_train_data' in locals() and stationary_train_data is not None and not stationary_train_data.empty:\n",
        "\n",
        "    # Asetetaan piirrettävien viiveiden (lags) määrä\n",
        "    # Esim. 72 näyttää 3 päivän korrelaatiot tunneittain\n",
        "    n_lags = 72\n",
        "\n",
        "    print(f\"\\nPiirretään ACF ja PACF {n_lags} viiveellä stationaariselle harjoitusdatalle...\")\n",
        "\n",
        "    fig, axes = plt.subplots(2, 1, figsize=(12, 8))\n",
        "\n",
        "    # Autokorrelaatiofunktio (ACF) - auttaa määrittämään q:n\n",
        "    plot_acf(stationary_train_data.dropna(), lags=n_lags, ax=axes[0], title=f'Autokorrelaatiofunktio (ACF) (d={d})')\n",
        "    axes[0].grid(True, linestyle=':')\n",
        "\n",
        "    # Osittaisautokorrelaatiofunktio (PACF) - auttaa määrittämään p:n\n",
        "    # Käytetään oletusmetodia ('yw' tai 'ywm'), joka on yleensä ok\n",
        "    plot_pacf(stationary_train_data.dropna(), lags=n_lags, ax=axes[1], title=f'Osittaisautokorrelaatiofunktio (PACF) (d={d})', method='ywm')\n",
        "    axes[1].grid(True, linestyle=':')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\n--- Kuvaajien tulkintaohjeet ---\")\n",
        "    print(\"Tarkastele yllä olevia kuvaajia:\")\n",
        "    print(\"1. PACF-kuvaaja (ylempi): Etsi kohta (lag), jonka jälkeen siniset pylväät pysyvät merkittävyysalueen (sininen/harmaa alue) sisällä.\")\n",
        "    print(\"   Tämä kohta viittaa mahdolliseen **p**-arvoon (AR-kertaluku). Jos pylväät 'häipyvät' hitaasti, AR-osa on merkittävä.\")\n",
        "    print(\"2. ACF-kuvaaja (alempi): Etsi kohta (lag), jonka jälkeen pylväät pysyvät merkittävyysalueen sisällä.\")\n",
        "    print(\"   Tämä kohta viittaa mahdolliseen **q**-arvoon (MA-kertaluku). Jos pylväät 'häipyvät' hitaasti, MA-osa on merkittävä.\")\n",
        "    print(\"3. Jos molemmat näyttävät häipyvän hitaasti, kokeile pieniä p:n ja q:n arvoja (esim. p=1, q=1 tai p=2, q=1 jne.).\")\n",
        "    print(\"4. Huomioi mahdolliset vahvat piikit kausiluonteisilla viiveillä (esim. 24, 48). Ne voivat viitata SARIMA-mallin tarpeeseen.\")\n",
        "    print(\"\\nPäättele kuvaajien perusteella sopivat p ja q -arvot ja päivitä ne `ARIMA_ORDER`-muuttujaan seuraavaa vaihetta varten.\")\n",
        "    print(f\"(Muista, että d={d} on jo päätetty).\")\n",
        "    # Muistutus nykyisestä placeholder-arvosta\n",
        "    print(f\"Nykyinen ARIMA_ORDER placeholder (ennen p/q päivitystä): {ARIMA_ORDER}\")\n",
        "    print(\"\\nOsa 4: ACF/PACF-analyysi - OK\")\n",
        "\n",
        "\n",
        "else:\n",
        "    print(\"VIRHE: Stationaarista harjoitusdataa ('stationary_train_data') ei löytynyt edellisestä solusta.\")\n",
        "    # Estetäänkö jatko? Ehkä parempi antaa jatkaa, mutta varoittaa\n",
        "    print(\"VAROITUS: Ei voida piirtää ACF/PACF-kuvaajia. p:n ja q:n määritys jää arvailun varaan.\")"
      ],
      "metadata": {
        "id": "JC81HRLaNI8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 5. ARIMA-Mallin Sovitus (ARIMA) - Lisätty Index Check & Param Print\n",
        "\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "import traceback\n",
        "import numpy as np # Varmistetaan numpy tuonti\n",
        "\n",
        "print(\"--- Aloitetaan ARIMA-mallin sovitus ---\")\n",
        "\n",
        "# Varmistetaan, että harjoitusdata ja kertaluvut ovat olemassa\n",
        "model_fit = None # Alustetaan Noneksi\n",
        "\n",
        "if 'train_data' in locals() and train_data is not None and not train_data.empty and \\\n",
        "   'ARIMA_ORDER' in locals() and isinstance(ARIMA_ORDER, tuple) and len(ARIMA_ORDER) == 3:\n",
        "\n",
        "    p, d, q = ARIMA_ORDER\n",
        "    print(f\"Käytetään ARIMA-kertalukuja: p={p}, d={d}, q={q}\")\n",
        "\n",
        "    # ---> LISÄTTY TARKISTUKSIA TÄHÄN <---\n",
        "    print(f\"\\nTarkistetaan train_data ennen sovitusta...\")\n",
        "    print(f\"train_data pituus: {len(train_data)}\")\n",
        "    nan_count = train_data.isnull().sum()\n",
        "    inf_count = np.isinf(train_data).sum()\n",
        "    dup_index_count = train_data.index.duplicated().sum()\n",
        "    inferred_freq = pd.infer_freq(train_data.index)\n",
        "    print(f\"NaN-arvoja: {nan_count}\")\n",
        "    print(f\"Inf-arvoja: {inf_count}\")\n",
        "    print(f\"Duplikaatti-indeksejä: {dup_index_count}\")\n",
        "    print(f\"Päätelty indeksi-frekvenssi: {inferred_freq}\")\n",
        "\n",
        "    # Yritetään asettaa frekvenssi H, jos se puuttuu, mutta varoen\n",
        "    if inferred_freq is None:\n",
        "        print(\"VAROITUS: Indeksin frekvenssiä ei voitu päätellä. Yritetään asettaa 'H'...\")\n",
        "        try:\n",
        "            # Luo kopio, jotta alkuperäinen train_data ei muutu jos asfreq epäonnistuu\n",
        "            train_data_freq = train_data.asfreq('H')\n",
        "            # Tarkista tuliko lisää NaN-arvoja\n",
        "            new_nan = train_data_freq.isnull().sum() - nan_count\n",
        "            if new_nan > 0:\n",
        "                print(f\"VAROITUS: asfreq('H') lisäsi {new_nan} NaN-arvoa. Harkitse niiden täyttämistä tai älä käytä asfreq.\")\n",
        "                # Tässä vaiheessa emme käytä train_data_freq, jos se lisää NaNneja\n",
        "            else:\n",
        "                print(\"asfreq('H') onnistui lisäämättä NaN-arvoja.\")\n",
        "                # Voit halutessasi käyttää tätä: train_data = train_data_freq\n",
        "        except Exception as e_freq:\n",
        "            print(f\"VAROITUS: asfreq('H') epäonnistui: {e_freq}\")\n",
        "\n",
        "\n",
        "    if nan_count > 0 or inf_count > 0 or dup_index_count > 0:\n",
        "         print(\"VIRHE: Harjoitusdatassa on NaN/Inf/Duplikaatti-indeksi arvoja! Ei voida sovittaa mallia luotettavasti.\")\n",
        "         model_fit = None # Estetään jatko\n",
        "    else:\n",
        "        print(\"Harjoitusdata vaikuttaa olevan kunnossa (ei NaN/Inf/Dup).\")\n",
        "        try:\n",
        "            # 1. Alusta ARIMA-malli\n",
        "            # Poistetaan freq-argumentti varmuuden vuoksi\n",
        "            model = ARIMA(train_data, order=ARIMA_ORDER)\n",
        "\n",
        "            # 2. Sovita malli harjoitusdataan\n",
        "            print(\"Sovitus käynnissä...\")\n",
        "            model_fit = model.fit()\n",
        "            print(\"Sovitus valmis.\")\n",
        "\n",
        "            # ---> LISÄTTY TARKISTUS TÄHÄN <---\n",
        "            print(\"\\n--- Sovitetut Parametrit ---\")\n",
        "            print(model_fit.params)\n",
        "            print(\"--------------------------\")\n",
        "\n",
        "            # 3. Tulosta mallin yhteenveto\n",
        "            print(\"\\n--- Mallin Yhteenveto ---\")\n",
        "            print(model_fit.summary())\n",
        "            print(\"------------------------\")\n",
        "            # ... (Tulkintaohjeet pysyvät samoina) ...\n",
        "            print(\"\\nTulkintaohjeita Yhteenvetoon:\")\n",
        "            print(\"- coef: Kertoimien arvot...\")\n",
        "            # ... (loput ohjeet) ...\n",
        "\n",
        "            print(\"\\nOsa 5: ARIMA-mallin sovitus - OK\")\n",
        "\n",
        "        except ValueError as ve:\n",
        "            print(f\"\\nVIRHE ARIMA-mallin sovituksessa (ValueError): {ve}\")\n",
        "            traceback.print_exc()\n",
        "            model_fit = None\n",
        "        except Exception as e:\n",
        "            print(f\"\\nOdottamaton VIRHE ARIMA-mallin sovituksessa: {e}\")\n",
        "            traceback.print_exc()\n",
        "            model_fit = None\n",
        "\n",
        "else:\n",
        "    print(\"VIRHE: Harjoitusdataa ('train_data') tai ARIMA-kertalukuja ('ARIMA_ORDER') ei löytynyt.\")\n",
        "    model_fit = None"
      ],
      "metadata": {
        "id": "s6EvLdDiPvAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 6. Ennusteiden Tekeminen (ARIMA) - VAIHDETTU .predict()-metodiin\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import traceback\n",
        "\n",
        "print(\"--- Aloitetaan ennusteiden tekeminen sovitetulla ARIMA-mallilla (käyttäen .predict()) ---\")\n",
        "\n",
        "# Varmistetaan, että sovitettu malli ja testidata ovat olemassa\n",
        "forecast_values = None # Alustetaan Noneksi\n",
        "\n",
        "if 'model_fit' in locals() and model_fit is not None and \\\n",
        "   'train_data' in locals() and train_data is not None and \\\n",
        "   'test_data' in locals() and test_data is not None and not test_data.empty:\n",
        "\n",
        "    try:\n",
        "        # 1. Määritä ennusteen alku- ja loppuindeksit/askeleet\n",
        "        n_train = len(train_data)\n",
        "        n_forecast_steps = len(test_data)\n",
        "        forecast_start_index = n_train # Ensimmäinen ennustettava indeksi on heti harjoitusdatan jälkeen\n",
        "        forecast_end_index = n_train + n_forecast_steps - 1 # Viimeinen ennustettava indeksi\n",
        "\n",
        "        print(f\"Tehdään {n_forecast_steps} askeleen ennuste testijaksolle käyttäen .predict(start={forecast_start_index}, end={forecast_end_index})...\")\n",
        "\n",
        "\n",
        "        if n_forecast_steps > 0:\n",
        "            # 2. *** MUUTOS TÄSSÄ: Käytä .predict() ***\n",
        "            # Tämä ennustaa arvot määritellylle indeksivälille perustuen malliin\n",
        "            forecast_mean = model_fit.predict(start=forecast_start_index, end=forecast_end_index)\n",
        "\n",
        "            # .predict() palauttaa suoraan Pandas Seriesin, jos malli alustettiin Seriesillä\n",
        "            if isinstance(forecast_mean, pd.Series):\n",
        "                 forecast_values = forecast_mean\n",
        "                 # Tarkistetaan indeksi\n",
        "                 if not forecast_values.index.equals(test_data.index[:n_forecast_steps]):\n",
        "                      print(\"VAROITUS: Ennusteen indeksi ei täsmää täysin testidatan indeksiin. Yritetään korjata...\")\n",
        "                      try:\n",
        "                           forecast_values.index = test_data.index[:n_forecast_steps]\n",
        "                      except Exception as e_idx:\n",
        "                           print(f\"Ennusteen indeksin korjaus epäonnistui: {e_idx}\")\n",
        "                           # Voitaisiin asettaa forecast_values = None, mutta yritetään jatkaa\n",
        "\n",
        "                 print(\".predict()-ennusteet laskettu.\")\n",
        "\n",
        "                 # 3. Tulosta ennusteiden alku ja loppu\n",
        "                 print(\"\\nEnnusteiden alku:\")\n",
        "                 print(forecast_values.head())\n",
        "                 print(\"\\nEnnusteiden loppu:\")\n",
        "                 print(forecast_values.tail())\n",
        "\n",
        "                 # Tarkistetaan NaN-arvot\n",
        "                 nan_in_forecast = forecast_values.isnull().sum()\n",
        "                 if nan_in_forecast > 0:\n",
        "                      print(f\"\\nVAROITUS: Ennuste sisältää {nan_in_forecast} NaN-arvoa!\")\n",
        "\n",
        "            else:\n",
        "                 print(f\"VIRHE: .predict() ei palauttanut odotettua Pandas Series -objektia (tyyppi: {type(forecast_mean)})\")\n",
        "                 forecast_values = None\n",
        "\n",
        "        else:\n",
        "             print(\"Testidata tyhjä tai ennusteaskelia nolla, ei voida tehdä ennustetta.\")\n",
        "             forecast_values = None\n",
        "\n",
        "\n",
        "        print(\"\\nOsa 6: Ennusteiden tekeminen (.predict()) - OK\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nOdottamaton VIRHE ennusteiden tekemisessä (.predict()): {e}\")\n",
        "        traceback.print_exc()\n",
        "        forecast_values = None\n",
        "\n",
        "else:\n",
        "    print(\"VIRHE: Sovitettua mallia ('model_fit'), harjoitusdataa ('train_data') tai testidataa ('test_data') ei löytynyt.\")\n",
        "    forecast_values = None"
      ],
      "metadata": {
        "id": "1mT-YjD5PxD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 7. Tulosten Arviointi ja Vertailu (ARIMA) - LISÄTTY O3_THRESHOLD MÄÄRITTELY\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import traceback # Tuotu jo aiemmin, mutta varmistetaan\n",
        "\n",
        "# --- VARMISTETAAN PARAMETRIEN MÄÄRITTELY TÄSSÄ SOLUSSA ---\n",
        "# Lisätään puuttuva muuttuja suoraan tähän soluun\n",
        "O3_THRESHOLD_8H_AVG = 85 # µg/m³ (Kokeillaan pienempää, vaikka virallinen varoitusraja)\n",
        "# Varmistetaan myös prediction_horizon (vaikka se todennäköisesti onkin jo muistissa)\n",
        "if 'PREDICTION_HORIZON' not in locals(): PREDICTION_HORIZON = 24\n",
        "# Varmistetaan ARIMA_ORDER referenssiä varten\n",
        "if 'ARIMA_ORDER' not in locals(): ARIMA_ORDER = ('?', '?', '?') # Placeholder, jos ei löydy\n",
        "# ----------------------------------------------------------\n",
        "\n",
        "print(\"--- Aloitetaan ARIMA-ennusteiden arviointi ---\")\n",
        "\n",
        "# Varmistetaan ennusteiden ja testidatan olemassaolo\n",
        "evaluation_possible = False\n",
        "rmse_arima = None; mae_arima = None\n",
        "rmse_baseline = None; mae_baseline = None\n",
        "baseline_forecast = None\n",
        "\n",
        "if 'forecast_values' in locals() and isinstance(forecast_values, pd.Series) and not forecast_values.empty and \\\n",
        "   'test_data' in locals() and isinstance(test_data, pd.Series) and not test_data.empty:\n",
        "\n",
        "    if len(forecast_values) == len(test_data):\n",
        "        print(f\"Arvioidaan {len(test_data)} ennustepistettä.\")\n",
        "        evaluation_possible = True\n",
        "        common_index = test_data.index\n",
        "        try:\n",
        "            if not forecast_values.empty:\n",
        "                forecast_values = forecast_values.reindex(common_index)\n",
        "                if forecast_values.isnull().any():\n",
        "                     print(\"VAROITUS: NaN-arvoja ennusteessa indeksin kohdistuksen jälkeen. Täytetään ffill/bfill.\")\n",
        "                     forecast_values = forecast_values.ffill().bfill()\n",
        "                     if forecast_values.isnull().any():\n",
        "                          print(\"VIRHE: Ei voitu täyttää kaikkia NaN-arvoja ennusteesta.\")\n",
        "                          evaluation_possible = False\n",
        "                if test_data.isnull().any():\n",
        "                     print(\"VAROITUS: test_data sisältää NaN-arvoja ennen arviointia. Yritetään täyttää...\")\n",
        "                     test_data = test_data.ffill().bfill()\n",
        "                     if test_data.isnull().any():\n",
        "                          print(\"VIRHE: Ei voitu täyttää NaN-arvoja testidatasta.\")\n",
        "                          evaluation_possible = False\n",
        "            else:\n",
        "                print(\"VIRHE: 'forecast_values' on tyhjä ennen reindexiä.\")\n",
        "                evaluation_possible = False\n",
        "        except Exception as e_reindex:\n",
        "            print(f\"VIRHE indeksin kohdistuksessa: {e_reindex}\")\n",
        "            evaluation_possible = False\n",
        "    else:\n",
        "        print(f\"VIRHE: Ennusteiden ({len(forecast_values)}) ja testidatan ({len(test_data)}) pituudet eivät täsmää.\")\n",
        "else:\n",
        "    missing_eval_vars = []\n",
        "    if 'forecast_values' not in locals() or not isinstance(forecast_values, pd.Series) or forecast_values.empty: missing_eval_vars.append('forecast_values')\n",
        "    if 'test_data' not in locals() or not isinstance(test_data, pd.Series) or test_data.empty: missing_eval_vars.append('test_data')\n",
        "    print(f\"VIRHE: Arviointiin tarvittavia muuttujia puuttuu tai ne ovat tyhjiä: {missing_eval_vars}.\")\n",
        "\n",
        "# --- Metriikoiden laskenta (vain jos evaluation_possible on True) ---\n",
        "if evaluation_possible:\n",
        "    try:\n",
        "        # --- Baseline-laskenta ---\n",
        "        def calculate_baseline_persistence_arima(targets_series, prediction_horizon):\n",
        "            \"\"\"Laskee naiivin persistenssi-baselinen Seriesille.\"\"\"\n",
        "            print(\"Lasketaan Baseline-ennuste (jakson eka arvo toistuu)...\")\n",
        "            # ... (funktion sisältö kuten edellisessä vastauksessa) ...\n",
        "            try:\n",
        "                if targets_series.empty: return pd.Series(dtype=float)\n",
        "                first_val = targets_series.iloc[0]\n",
        "                baseline_preds_np = np.repeat(first_val, len(targets_series))\n",
        "                baseline_preds = pd.Series(baseline_preds_np, index=targets_series.index)\n",
        "                return baseline_preds\n",
        "            except Exception as e_base:\n",
        "                print(f\"VIRHE baseline-laskennassa: {e_base}\")\n",
        "                return None\n",
        "\n",
        "        baseline_forecast = calculate_baseline_persistence_arima(test_data, PREDICTION_HORIZON)\n",
        "\n",
        "        # --- Regressiometriikat ---\n",
        "        print(\"\\nLasketaan regressiometriikat...\")\n",
        "        rmse_arima = np.sqrt(mean_squared_error(test_data, forecast_values))\n",
        "        mae_arima = mean_absolute_error(test_data, forecast_values)\n",
        "        print(f\"\\n--- ARIMA({ARIMA_ORDER[0]},{ARIMA_ORDER[1]},{ARIMA_ORDER[2]}) Mallin Arviointi ---\")\n",
        "        print(f\"RMSE: {rmse_arima:.4f} µg/m³\")\n",
        "        print(f\"MAE:  {mae_arima:.4f} µg/m³\")\n",
        "\n",
        "        if baseline_forecast is not None and len(baseline_forecast) == len(test_data):\n",
        "            if baseline_forecast.isnull().any():\n",
        "                print(\"VAROITUS: Baseline-ennuste sisältää NaN-arvoja. Täytetään.\")\n",
        "                baseline_forecast = baseline_forecast.ffill().bfill()\n",
        "            if not baseline_forecast.isnull().any():\n",
        "                rmse_baseline = np.sqrt(mean_squared_error(test_data, baseline_forecast))\n",
        "                mae_baseline = mean_absolute_error(test_data, baseline_forecast)\n",
        "                print(f\"\\n--- Baseline-Mallin Arviointi (Naiivi Persistenssi) ---\")\n",
        "                print(f\"RMSE: {rmse_baseline:.4f} µg/m³\")\n",
        "                print(f\"MAE:  {mae_baseline:.4f} µg/m³\")\n",
        "                # --- Vertailu ---\n",
        "                print(\"\\n--- Vertailu Baselineen ---\")\n",
        "                if rmse_arima is not None and rmse_baseline is not None:\n",
        "                    improvement_rmse = rmse_baseline - rmse_arima\n",
        "                    print(f\"ARIMA vs Baseline RMSE: {improvement_rmse:+.4f} µg/m³ ({'ARIMA parempi' if improvement_rmse > 0 else 'Baseline parempi tai sama'})\")\n",
        "                else: print(\"RMSE-vertailua ei voida tehdä.\")\n",
        "                if mae_arima is not None and mae_baseline is not None:\n",
        "                    improvement_mae = mae_baseline - mae_arima\n",
        "                    print(f\"ARIMA vs Baseline MAE:  {improvement_mae:+.4f} µg/m³ ({'ARIMA parempi' if improvement_mae > 0 else 'Baseline parempi tai sama'})\")\n",
        "                else: print(\"MAE-vertailua ei voida tehdä.\")\n",
        "            else: print(\"\\nBaseline-metriikoita ei voitu laskea NaN-arvojen vuoksi.\")\n",
        "        else: print(\"\\nBaseline-ennustetta ei voitu laskea tai sen pituus ei täsmää.\")\n",
        "\n",
        "        # --- 8h Liukuvan keskiarvon arviointi ---\n",
        "        # Käytetään nyt solun alussa määriteltyä O3_THRESHOLD_8H_AVG\n",
        "        print(f\"\\nLasketaan 8h liukuvia keskiarvoja koko testijaksolle ja verrataan kynnysarvoon ({O3_THRESHOLD_8H_AVG} µg/m³)...\")\n",
        "        try:\n",
        "            actual_series_8h = test_data.rolling(window=8, min_periods=1).mean()\n",
        "            pred_series_8h = forecast_values.rolling(window=8, min_periods=1).mean()\n",
        "            actual_warning_hours = actual_series_8h > O3_THRESHOLD_8H_AVG\n",
        "            pred_warning_hours = pred_series_8h > O3_THRESHOLD_8H_AVG\n",
        "            n_samples_eval = len(test_data)\n",
        "            print(\"\\n--- 8h Liukuvan Keskiarvon Varoitustason Ylityksen Arviointi (ARIMA - Tuntitaso) ---\")\n",
        "            print(f\"Todellisia varoitustunteja testidatassa (> {O3_THRESHOLD_8H_AVG} µg/m³): {actual_warning_hours.sum()} / {n_samples_eval}\")\n",
        "            print(f\"Ennustettuja varoitustunteja (ARIMA):                      {pred_warning_hours.sum()} / {n_samples_eval}\")\n",
        "\n",
        "            if actual_warning_hours.sum() > 0 or pred_warning_hours.sum() > 0:\n",
        "                print(\"\\nSekaannusmatriisi (Confusion Matrix) varoituksille (ARIMA - Tuntitaso):\")\n",
        "                cm = confusion_matrix(actual_warning_hours, pred_warning_hours, labels=[False, True])\n",
        "                cm_df = pd.DataFrame(cm, index=['Todellinen EI Varoitusta', 'Todellinen KYLLÄ Varoitus'],\n",
        "                                   columns=['Ennuste EI', 'Ennuste KYLLÄ'])\n",
        "                print(cm_df)\n",
        "                print(\"\\nLuokitteluraportti varoituksille (ARIMA - Tuntitaso):\")\n",
        "                report = classification_report(actual_warning_hours, pred_warning_hours, target_names=['Ei Varoitusta', 'Varoitus'], labels=[False, True], zero_division=0)\n",
        "                print(report)\n",
        "                TN, FP, FN, TP = cm.ravel()\n",
        "                recall_warning = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "                precision_warning = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "                print(f\"\\n---> TÄRKEIMMÄT VAROITUSMETRIIKAT (Tuntitaso):\")\n",
        "                print(f\"  Recall (Herkkyys) 'Varoitus'-luokalle: {recall_warning:.4f}\")\n",
        "                print(f\"  Precision (Tarkkuus) 'Varoitus'-luokalle: {precision_warning:.4f}\")\n",
        "            else:\n",
        "                print(\"\\nEi todellisia eikä ennustettuja varoitustunteja testidatassa kynnysarvolla.\")\n",
        "\n",
        "            print(\"\\nOsa 7: Tulosten Arviointi - OK\")\n",
        "\n",
        "        except Exception as e_8h:\n",
        "            print(f\"VIRHE 8h liukuvan keskiarvon laskennassa tai arvioinnissa: {e_8h}\")\n",
        "            traceback.print_exc()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nVIRHE tulosten arvioinnissa: {e}\")\n",
        "        traceback.print_exc()\n",
        "else:\n",
        "     print(\"\\nArviointia ei voida suorittaa, koska ennusteet tai testidata puuttuvat/ovat virheellisiä.\")"
      ],
      "metadata": {
        "id": "46elTJYQSr2_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}