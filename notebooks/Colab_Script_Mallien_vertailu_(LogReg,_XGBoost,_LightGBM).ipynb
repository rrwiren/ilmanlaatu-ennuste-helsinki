{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rrwiren/ilmanlaatu-ennuste-helsinki/blob/main/Colab_Script_Mallien_vertailu_(LogReg%2C_XGBoost%2C_LightGBM).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Colab Script: Model Comparison (Logistic Regression, XGBoost, LightGBM)\n",
        "\n",
        "Loads and prepares data, trains all three models sequentially for ozone\n",
        "spike prediction, calculates key evaluation metrics, stores them\n",
        "for comparison, and displays the final comparison table.\n",
        "\"\"\"\n",
        "\n",
        "# Kirjastojen tuonti\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "import requests\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import traceback\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "import re\n",
        "\n",
        "# Koneoppimiskirjastot\n",
        "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression # Logistinen Regressio\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
        "                             roc_auc_score, precision_recall_curve, auc,\n",
        "                             confusion_matrix, classification_report)\n",
        "\n",
        "print(\"--- Model Comparison Script (LogReg, XGBoost, LightGBM) ---\")\n",
        "\n",
        "# --- Globaali sanakirja mallien vertailuun ---\n",
        "model_comparison_metrics = {}\n",
        "\n",
        "# --- Funktiot datan lataamiseen ja peruspuhdistukseen ---\n",
        "# (Sama kuin aiemmin)\n",
        "def load_and_clean_data(raw_url, data_type='weather', cols_to_keep=None):\n",
        "    \"\"\"Lataa ja esikäsittelee datan, pitäen vain tarvittavat sarakkeet.\"\"\"\n",
        "    print(f\"\\nLadataan {data_type} dataa: {raw_url}\")\n",
        "    df_local = None\n",
        "    try:\n",
        "        response = requests.get(raw_url)\n",
        "        response.raise_for_status()\n",
        "        encoding = 'utf-8' if data_type == 'weather' else 'iso-8859-1'\n",
        "        csv_content = io.StringIO(response.content.decode(encoding))\n",
        "        if data_type == 'ozone':\n",
        "             column_names_ozone = [\"Havaintoasema\", \"Vuosi\", \"Kuukausi\", \"Päivä\", \"Aika [Paikallinen aika]\", \"Otsoni [µg/m³]\"]\n",
        "             df_local = pd.read_csv(\n",
        "                  csv_content, sep=',', decimal=',', skiprows=1, header=None,\n",
        "                  names=column_names_ozone, quoting=csv.QUOTE_NONNUMERIC, low_memory=False)\n",
        "             target_col = \"Otsoni [µg/m³]\"\n",
        "             if target_col in df_local.columns: df_local[target_col] = pd.to_numeric(df_local[target_col], errors='coerce')\n",
        "             else: raise ValueError(f\"Otsonisarake '{target_col}' ei löytynyt.\")\n",
        "        elif data_type == 'weather':\n",
        "            df_local = pd.read_csv(csv_content, sep=',', decimal='.', low_memory=False)\n",
        "            df_local.columns = df_local.columns.str.strip()\n",
        "            weather_cols_to_convert = ['Lämpötilan keskiarvo [°C]', 'Keskituulen nopeus [m/s]', 'Tuulen suunnan keskiarvo [°]', 'Ilmanpaineen keskiarvo [hPa]']\n",
        "            for col in weather_cols_to_convert:\n",
        "                 if col in df_local.columns: df_local[col] = pd.to_numeric(df_local[col], errors='coerce')\n",
        "        else: raise ValueError(f\"Tuntematon data_type: {data_type}\")\n",
        "        year_col, month_col, day_col, time_col = 'Vuosi', 'Kuukausi', 'Päivä', 'Aika [Paikallinen aika]'\n",
        "        required_dt_cols = [year_col, month_col, day_col, time_col]\n",
        "        if not all(col in df_local.columns for col in required_dt_cols): raise ValueError(f\"Aikaleiman luontiin vaadittavia sarakkeita puuttuu: {required_dt_cols}\")\n",
        "        df_local[year_col] = pd.to_numeric(df_local[year_col], errors='coerce').astype('Int64'); df_local[month_col] = pd.to_numeric(df_local[month_col], errors='coerce').astype('Int64'); df_local[day_col] = pd.to_numeric(df_local[day_col], errors='coerce').astype('Int64')\n",
        "        if df_local[required_dt_cols].isnull().any().any(): df_local.dropna(subset=required_dt_cols, inplace=True)\n",
        "        df_local[year_col] = df_local[year_col].astype(str); df_local[month_col] = df_local[month_col].astype(str).str.zfill(2); df_local[day_col] = df_local[day_col].astype(str).str.zfill(2); df_local[time_col] = df_local[time_col].astype(str)\n",
        "        time_str = df_local[time_col].str.replace('24:00', '00:00', regex=False)\n",
        "        datetime_str = df_local[year_col] + '-' + df_local[month_col] + '-' + df_local[day_col] + ' ' + time_str\n",
        "        df_local['Timestamp'] = pd.to_datetime(datetime_str, format='%Y-%m-%d %H:%M', errors='coerce')\n",
        "        df_local.loc[df_local[time_col] == '24:00', 'Timestamp'] += pd.Timedelta(days=1)\n",
        "        cols_to_select = ['Timestamp'] + (cols_to_keep if cols_to_keep else []); missing_cols = [col for col in cols_to_select if col not in df_local.columns]\n",
        "        if missing_cols: raise ValueError(f\"Vaadittuja sarakkeita puuttuu datasta: {missing_cols}\")\n",
        "        df_local = df_local[cols_to_select].copy()\n",
        "        df_local.dropna(subset=['Timestamp'] + (cols_to_keep if cols_to_keep else []), inplace=True)\n",
        "        df_local.set_index('Timestamp', inplace=True); df_local.sort_index(inplace=True)\n",
        "        duplicates = df_local.index.duplicated(keep='first')\n",
        "        if duplicates.sum() > 0: df_local = df_local[~duplicates]\n",
        "        print(f\"Datan ({data_type}) käsittely valmis, muoto: {df_local.shape}\")\n",
        "        if df_local.empty: print(f\"VAROITUS: {data_type} DataFrame on tyhjä!\")\n",
        "        return df_local\n",
        "    except requests.exceptions.RequestException as e: print(f\"Virhe datan haussa URL:sta ({data_type}): {e}\"); return None\n",
        "    except Exception as e: print(f\"Virhe datan käsittelyssä ({data_type}): {e}\"); traceback.print_exc(); return None\n",
        "\n",
        "# --- 1. Datan lataus ---\n",
        "ozone_url = \"https://raw.githubusercontent.com/rrwiren/ilmanlaatu-ennuste-helsinki/main/data/raw/Helsinki%20Kallio%202_%201.4.2020%20-%201.4.2025_f5d0d5ac-9f7d-4833-a70b-c1afe4dc935a.csv\"\n",
        "weather_url = \"https://raw.githubusercontent.com/rrwiren/ilmanlaatu-ennuste-helsinki/main/data/raw/Helsinki%20Kaisaniemi_%201.4.2020%20-%201.4.2025_d5590617-bf91-46c7-96f4-1fb70892265d.csv\"\n",
        "o3_col = \"Otsoni [µg/m³]\"\n",
        "weather_cols = ['Lämpötilan keskiarvo [°C]', 'Keskituulen nopeus [m/s]', 'Ilmanpaineen keskiarvo [hPa]']\n",
        "df_ozone = load_and_clean_data(ozone_url, data_type='ozone', cols_to_keep=[o3_col])\n",
        "df_weather = load_and_clean_data(weather_url, data_type='weather', cols_to_keep=weather_cols)\n",
        "\n",
        "# --- 2. Datan yhdistäminen & RESAMPLE ---\n",
        "df_merged = None\n",
        "if df_ozone is not None and not df_ozone.empty and df_weather is not None and not df_weather.empty:\n",
        "    print(\"\\nYhdistetään otsoni- ja säädata...\")\n",
        "    df_merged_raw = pd.merge(df_ozone, df_weather, left_index=True, right_index=True, how='inner')\n",
        "    df_merged_raw.dropna(inplace=True)\n",
        "    if not df_merged_raw.empty:\n",
        "        print(\"Uudelleenotanta ('resample') tunneittaiseen taajuuteen...\")\n",
        "        df_merged = df_merged_raw.resample('h').mean()\n",
        "        nan_after_resample = df_merged.isnull().sum().sum()\n",
        "        if nan_after_resample > 0:\n",
        "            print(f\"Löytyi {nan_after_resample} NaN-arvoa resamplen jälkeen. Interpoloidaan (time)...\")\n",
        "            df_merged.interpolate(method='time', inplace=True)\n",
        "            df_merged.fillna(method='ffill', inplace=True); df_merged.fillna(method='bfill', inplace=True)\n",
        "        if df_merged.isnull().any().any(): df_merged.dropna(inplace=True)\n",
        "        if df_merged.empty: print(\"Virhe: Data tyhjä resamplen jälkeen.\"); df_merged = None\n",
        "        else: print(\"Datan yhdistäminen ja resample onnistui.\")\n",
        "    else: print(\"Virhe: Yhdistetty data tyhjä ennen resamplea.\"); df_merged = None\n",
        "\n",
        "# Jatka vain jos data ok\n",
        "if df_merged is not None:\n",
        "\n",
        "    # --- 3. Piikkien määrittely ---\n",
        "    print(\"\\n--- 3. Piikkien määrittely ---\")\n",
        "    spike_threshold = df_merged[o3_col].quantile(0.90)\n",
        "    df_merged['onko_piikki'] = (df_merged[o3_col] > spike_threshold).astype(int)\n",
        "    print(f\"Piikin kynnysarvo ({0.90*100:.0f}. persentiili): {spike_threshold:.2f} µg/m³\")\n",
        "\n",
        "    # --- 4. Piirteiden muokkaus ---\n",
        "    print(\"\\n--- 4. Piirteiden muokkaus ---\")\n",
        "    print(\"Luodaan aikaan perustuvia piirteitä...\")\n",
        "    df_merged['hour_sin'] = np.sin(2 * np.pi * df_merged.index.hour / 24); df_merged['hour_cos'] = np.cos(2 * np.pi * df_merged.index.hour / 24)\n",
        "    df_merged['dayofweek_sin'] = np.sin(2 * np.pi * df_merged.index.dayofweek / 7); df_merged['dayofweek_cos'] = np.cos(2 * np.pi * df_merged.index.dayofweek / 7)\n",
        "    df_merged['month_sin'] = np.sin(2 * np.pi * df_merged.index.month / 12); df_merged['month_cos'] = np.cos(2 * np.pi * df_merged.index.month / 12)\n",
        "    features_to_lag = [o3_col] + weather_cols; lag_periods = [1, 2, 3, 6, 12, 24, 48, 72]\n",
        "    print(f\"Luodaan viivepiirteet {lag_periods} tunnin jaksoilla...\")\n",
        "    for col in features_to_lag:\n",
        "        for lag in lag_periods:\n",
        "            sanitized_col_name = re.sub(r'[\\[\\]<>°/³\\s]', '_', col)\n",
        "            df_merged[f'{sanitized_col_name}_lag{lag}'] = df_merged[col].shift(lag)\n",
        "    rolling_window_hours = [3, 6, 12, 24, 48]\n",
        "    print(f\"Luodaan liukuvia tilastoja {rolling_window_hours} tunnin ikkunoilla...\")\n",
        "    for window in rolling_window_hours:\n",
        "        shifted_o3 = df_merged[o3_col].shift(1)\n",
        "        sanitized_o3_col_name = re.sub(r'[\\[\\]<>°/³\\s]', '_', o3_col)\n",
        "        df_merged[f'{sanitized_o3_col_name}_roll_mean_{window}h'] = shifted_o3.rolling(window=window).mean()\n",
        "        df_merged[f'{sanitized_o3_col_name}_roll_std_{window}h'] = shifted_o3.rolling(window=window).std()\n",
        "    initial_rows = len(df_merged); df_merged.dropna(inplace=True)\n",
        "    print(f\"Poistettu {initial_rows - len(df_merged)} riviä piirteiden muokkauksen jälkeen.\")\n",
        "    if df_merged.empty: print(\"Virhe: Data tyhjä piirteiden muokkauksen jälkeen.\"); df_merged = None\n",
        "\n",
        "if df_merged is not None:\n",
        "    # --- 5. Datan jako opetus- ja testijoukkoihin ---\n",
        "    print(\"\\n--- 5. Datan jako opetus- ja testijoukkoihin ---\")\n",
        "    target = 'onko_piikki'\n",
        "    features_orig_names = [col for col in df_merged.columns if col not in [o3_col, target]]\n",
        "    X = df_merged[features_orig_names]\n",
        "    y = df_merged[target]\n",
        "    print(\"Puhdistetaan sarakkeiden nimet...\")\n",
        "    def sanitize_col_names(df_or_list):\n",
        "        if isinstance(df_or_list, pd.DataFrame): cols = df_or_list.columns\n",
        "        elif isinstance(df_or_list, list): cols = df_or_list\n",
        "        else: return df_or_list\n",
        "        new_cols = []\n",
        "        for col in cols:\n",
        "            new_col = str(col); new_col = re.sub(r'[\\[\\]<>°/³]', '', new_col); new_col = re.sub(r'\\s+', '_', new_col)\n",
        "            new_cols.append(new_col)\n",
        "        if isinstance(df_or_list, pd.DataFrame): df_or_list.columns = new_cols; return df_or_list\n",
        "        elif isinstance(df_or_list, list): return new_cols\n",
        "    X = sanitize_col_names(X.copy())\n",
        "    features = X.columns.tolist()\n",
        "    print(\"Sarakkeiden nimet puhdistettu.\")\n",
        "    test_size = 0.15\n",
        "    split_index = int(len(X) * (1 - test_size))\n",
        "    X_train, X_test = X.iloc[:split_index], X.iloc[split_index:]\n",
        "    y_train, y_test = y.iloc[:split_index], y.iloc[split_index:]\n",
        "    print(f\"Opetusdata: {X_train.index.min()} - {X_train.index.max()} ({len(X_train)} riviä)\")\n",
        "    print(f\"Testidata: {X_test.index.min()} - {X_test.index.max()} ({len(X_test)} riviä)\")\n",
        "\n",
        "    # --- 6. Piirteiden skaalaus ---\n",
        "    print(\"\\n--- 6. Skaalataan piirteet ---\")\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    X_train_scaled = pd.DataFrame(X_train_scaled, index=X_train.index, columns=features)\n",
        "    X_test_scaled = pd.DataFrame(X_test_scaled, index=X_test.index, columns=features)\n",
        "    print(\"Skaalaus valmis.\")\n",
        "\n",
        "    # --- 7. Malli 1: Logistinen Regressio ---\n",
        "    print(\"\\n--- 7. Malli 1: Logistinen Regressio ---\")\n",
        "    try:\n",
        "        log_reg_model = LogisticRegression(class_weight='balanced', random_state=42, solver='liblinear', max_iter=200)\n",
        "        print(\"Koulutetaan Logistista Regressiota...\")\n",
        "        log_reg_model.fit(X_train_scaled, y_train)\n",
        "        print(\"Malli koulutettu.\")\n",
        "        y_pred_logreg = log_reg_model.predict(X_test_scaled)\n",
        "        y_pred_proba_logreg = log_reg_model.predict_proba(X_test_scaled)[:, 1]\n",
        "        print(\"\\nLogistisen Regression evaluointi:\")\n",
        "        print(classification_report(y_test, y_pred_logreg, zero_division=0))\n",
        "        # Laske metriikat\n",
        "        accuracy_logreg = accuracy_score(y_test, y_pred_logreg)\n",
        "        precision_spike_logreg = precision_score(y_test, y_pred_logreg, pos_label=1, zero_division=0)\n",
        "        recall_spike_logreg = recall_score(y_test, y_pred_logreg, pos_label=1, zero_division=0)\n",
        "        f1_spike_logreg = f1_score(y_test, y_pred_logreg, pos_label=1, zero_division=0)\n",
        "        roc_auc_logreg = roc_auc_score(y_test, y_pred_proba_logreg)\n",
        "        precision_curve_logreg, recall_curve_logreg, _ = precision_recall_curve(y_test, y_pred_proba_logreg)\n",
        "        pr_auc_logreg = auc(recall_curve_logreg, precision_curve_logreg)\n",
        "        # Tallenna metriikat\n",
        "        model_comparison_metrics['Logistic Regression'] = {\n",
        "            'Accuracy': accuracy_logreg, 'Precision (Spike)': precision_spike_logreg,\n",
        "            'Recall (Spike)': recall_spike_logreg, 'F1-score (Spike)': f1_spike_logreg,\n",
        "            'ROC AUC': roc_auc_logreg, 'PR AUC': pr_auc_logreg }\n",
        "        print(\"Logistisen Regression metriikat tallennettu.\")\n",
        "    except Exception as e_logreg: print(f\"Virhe Logistisen Regression ajossa: {e_logreg}\"); traceback.print_exc()\n",
        "\n",
        "    # --- 8. Malli 2: XGBoost ---\n",
        "    print(\"\\n--- 8. Malli 2: XGBoost ---\")\n",
        "    try:\n",
        "        ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1) if np.sum(y_train == 1) > 0 else 1\n",
        "        print(f\"Laskettu scale_pos_weight: {ratio:.2f}\")\n",
        "        xgb_model = xgb.XGBClassifier(\n",
        "            objective='binary:logistic', eval_metric='logloss', scale_pos_weight=ratio,\n",
        "            n_estimators=100, learning_rate=0.1, max_depth=5, subsample=0.8,\n",
        "            colsample_bytree=0.8, random_state=42, n_jobs=-1)\n",
        "        print(\"Koulutetaan XGBoost-mallia...\")\n",
        "        xgb_model.fit(X_train_scaled, y_train, eval_set=[(X_test_scaled, y_test)], verbose=False)\n",
        "        print(\"Malli koulutettu.\")\n",
        "        y_pred_xgb = xgb_model.predict(X_test_scaled)\n",
        "        y_pred_proba_xgb = xgb_model.predict_proba(X_test_scaled)[:, 1]\n",
        "        print(\"\\nXGBoost-luokittelijan evaluointi:\")\n",
        "        print(classification_report(y_test, y_pred_xgb, zero_division=0))\n",
        "        # Laske metriikat\n",
        "        accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
        "        precision_spike_xgb = precision_score(y_test, y_pred_xgb, pos_label=1, zero_division=0)\n",
        "        recall_spike_xgb = recall_score(y_test, y_pred_xgb, pos_label=1, zero_division=0)\n",
        "        f1_spike_xgb = f1_score(y_test, y_pred_xgb, pos_label=1, zero_division=0)\n",
        "        roc_auc_xgb = roc_auc_score(y_test, y_pred_proba_xgb)\n",
        "        precision_curve_xgb, recall_curve_xgb, _ = precision_recall_curve(y_test, y_pred_proba_xgb)\n",
        "        pr_auc_xgb = auc(recall_curve_xgb, precision_curve_xgb)\n",
        "        # Tallenna metriikat\n",
        "        model_comparison_metrics['XGBoost'] = {\n",
        "            'Accuracy': accuracy_xgb, 'Precision (Spike)': precision_spike_xgb,\n",
        "            'Recall (Spike)': recall_spike_xgb, 'F1-score (Spike)': f1_spike_xgb,\n",
        "            'ROC AUC': roc_auc_xgb, 'PR AUC': pr_auc_xgb }\n",
        "        print(\"XGBoostin metriikat tallennettu.\")\n",
        "        # Visualisoinnit XGBoostille (esimerkkinä)\n",
        "        # ... (Confusion matrix, PR curve, Feature importance kuten aiemmin)...\n",
        "\n",
        "    except Exception as e_xgb: print(f\"Virhe XGBoost-mallin ajossa: {e_xgb}\"); traceback.print_exc()\n",
        "\n",
        "    # --- 9. Malli 3: LightGBM ---\n",
        "    print(\"\\n--- 9. Malli 3: LightGBM ---\")\n",
        "    try:\n",
        "        # ratio laskettu jo aiemmin\n",
        "        print(f\"Käytetään scale_pos_weight / class_weight='balanced'\")\n",
        "        lgbm_model = lgb.LGBMClassifier(\n",
        "            objective='binary', metric='logloss', class_weight='balanced', # Käytä class_weight='balanced'\n",
        "            n_estimators=100, learning_rate=0.1, num_leaves=31, max_depth=-1,\n",
        "            subsample=0.8, colsample_bytree=0.8, random_state=42, n_jobs=-1)\n",
        "        print(\"Koulutetaan LightGBM-mallia...\")\n",
        "        lgbm_model.fit(X_train_scaled, y_train, eval_set=[(X_test_scaled, y_test)])\n",
        "        print(\"Malli koulutettu.\")\n",
        "        y_pred_lgbm = lgbm_model.predict(X_test_scaled)\n",
        "        y_pred_proba_lgbm = lgbm_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "        print(\"\\nLightGBM-luokittelijan evaluointi:\")\n",
        "        print(classification_report(y_test, y_pred_lgbm, zero_division=0))\n",
        "        # Laske metriikat\n",
        "        accuracy_lgbm = accuracy_score(y_test, y_pred_lgbm)\n",
        "        precision_spike_lgbm = precision_score(y_test, y_pred_lgbm, pos_label=1, zero_division=0)\n",
        "        recall_spike_lgbm = recall_score(y_test, y_pred_lgbm, pos_label=1, zero_division=0)\n",
        "        f1_spike_lgbm = f1_score(y_test, y_pred_lgbm, pos_label=1, zero_division=0)\n",
        "        roc_auc_lgbm = roc_auc_score(y_test, y_pred_proba_lgbm)\n",
        "        precision_curve_lgbm, recall_curve_lgbm, _ = precision_recall_curve(y_test, y_pred_proba_lgbm)\n",
        "        pr_auc_lgbm = auc(recall_curve_lgbm, precision_curve_lgbm)\n",
        "        # Tallenna metriikat\n",
        "        model_comparison_metrics['LightGBM'] = {\n",
        "            'Accuracy': accuracy_lgbm, 'Precision (Spike)': precision_spike_lgbm,\n",
        "            'Recall (Spike)': recall_spike_lgbm, 'F1-score (Spike)': f1_spike_lgbm,\n",
        "            'ROC AUC': roc_auc_lgbm, 'PR AUC': pr_auc_lgbm }\n",
        "        print(\"LightGBM:n metriikat tallennettu.\")\n",
        "        # Visualisoinnit LightGBM:lle (voit lisätä kuten XGBoostille)\n",
        "        # ...\n",
        "\n",
        "    except Exception as e_lgbm: print(f\"Virhe LightGBM-mallin ajossa: {e_lgbm}\"); traceback.print_exc()\n",
        "\n",
        "\n",
        "    # --- 10. Mallien vertailu ---\n",
        "    print(\"\\n--- 10. Mallien vertailu ---\")\n",
        "    if model_comparison_metrics:\n",
        "        comparison_df = pd.DataFrame.from_dict(model_comparison_metrics, orient='index')\n",
        "        comparison_df = comparison_df.round(4)\n",
        "        # Järjestä esim. PR AUC tai F1-score (Spike) mukaan\n",
        "        comparison_df.sort_values(by='PR AUC', ascending=False, inplace=True)\n",
        "        print(comparison_df)\n",
        "    else:\n",
        "        print(\"Metriikoita ei tallennettu vertailua varten.\")\n",
        "\n",
        "\n",
        "else: # df_merged is None or empty\n",
        "    print(\"\\nEi voitu jatkaa mallinnukseen, koska datan yhdistäminen/muokkaus epäonnistui.\")\n",
        "\n",
        "\n",
        "print(\"\\n--- Vertailuscripti päättyi ---\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Model Comparison Script (LogReg, XGBoost, LightGBM) ---\n",
            "\n",
            "Ladataan ozone dataa: https://raw.githubusercontent.com/rrwiren/ilmanlaatu-ennuste-helsinki/main/data/raw/Helsinki%20Kallio%202_%201.4.2020%20-%201.4.2025_f5d0d5ac-9f7d-4833-a70b-c1afe4dc935a.csv\n",
            "Datan (ozone) käsittely valmis, muoto: (43180, 1)\n",
            "\n",
            "Ladataan weather dataa: https://raw.githubusercontent.com/rrwiren/ilmanlaatu-ennuste-helsinki/main/data/raw/Helsinki%20Kaisaniemi_%201.4.2020%20-%201.4.2025_d5590617-bf91-46c7-96f4-1fb70892265d.csv\n",
            "Datan (weather) käsittely valmis, muoto: (43463, 3)\n",
            "\n",
            "Yhdistetään otsoni- ja säädata...\n",
            "Uudelleenotanta ('resample') tunneittaiseen taajuuteen...\n",
            "Löytyi 4180 NaN-arvoa resamplen jälkeen. Interpoloidaan (time)...\n",
            "Datan yhdistäminen ja resample onnistui.\n",
            "\n",
            "--- 3. Piikkien määrittely ---\n",
            "Piikin kynnysarvo (90. persentiili): 77.10 µg/m³\n",
            "\n",
            "--- 4. Piirteiden muokkaus ---\n",
            "Luodaan aikaan perustuvia piirteitä...\n",
            "Luodaan viivepiirteet [1, 2, 3, 6, 12, 24, 48, 72] tunnin jaksoilla...\n",
            "Luodaan liukuvia tilastoja [3, 6, 12, 24, 48] tunnin ikkunoilla...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-b0cf27cd8454>:106: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df_merged.fillna(method='ffill', inplace=True); df_merged.fillna(method='bfill', inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Poistettu 72 riviä piirteiden muokkauksen jälkeen.\n",
            "\n",
            "--- 5. Datan jako opetus- ja testijoukkoihin ---\n",
            "Puhdistetaan sarakkeiden nimet...\n",
            "Sarakkeiden nimet puhdistettu.\n",
            "Opetusdata: 2020-04-04 00:00:00 - 2024-07-02 08:00:00 (37209 riviä)\n",
            "Testidata: 2024-07-02 09:00:00 - 2025-04-01 23:00:00 (6567 riviä)\n",
            "\n",
            "--- 6. Skaalataan piirteet ---\n",
            "Skaalaus valmis.\n",
            "\n",
            "--- 7. Malli 1: Logistinen Regressio ---\n",
            "Koulutetaan Logistista Regressiota...\n",
            "Malli koulutettu.\n",
            "\n",
            "Logistisen Regression evaluointi:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.95      0.97      6110\n",
            "           1       0.57      0.94      0.71       457\n",
            "\n",
            "    accuracy                           0.95      6567\n",
            "   macro avg       0.78      0.94      0.84      6567\n",
            "weighted avg       0.97      0.95      0.95      6567\n",
            "\n",
            "Logistisen Regression metriikat tallennettu.\n",
            "\n",
            "--- 8. Malli 2: XGBoost ---\n",
            "Laskettu scale_pos_weight: 8.59\n",
            "Koulutetaan XGBoost-mallia...\n",
            "Malli koulutettu.\n",
            "\n",
            "XGBoost-luokittelijan evaluointi:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.97      0.98      6110\n",
            "           1       0.66      0.89      0.76       457\n",
            "\n",
            "    accuracy                           0.96      6567\n",
            "   macro avg       0.83      0.93      0.87      6567\n",
            "weighted avg       0.97      0.96      0.96      6567\n",
            "\n",
            "XGBoostin metriikat tallennettu.\n",
            "\n",
            "--- 9. Malli 3: LightGBM ---\n",
            "Käytetään scale_pos_weight / class_weight='balanced'\n",
            "Koulutetaan LightGBM-mallia...\n",
            "[LightGBM] [Info] Number of positive: 3881, number of negative: 33328\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022376 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 11407\n",
            "[LightGBM] [Info] Number of data points in the train set: 37209, number of used features: 51\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "Malli koulutettu.\n",
            "\n",
            "LightGBM-luokittelijan evaluointi:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.97      0.98      6110\n",
            "           1       0.68      0.89      0.77       457\n",
            "\n",
            "    accuracy                           0.96      6567\n",
            "   macro avg       0.84      0.93      0.87      6567\n",
            "weighted avg       0.97      0.96      0.97      6567\n",
            "\n",
            "LightGBM:n metriikat tallennettu.\n",
            "\n",
            "--- 10. Mallien vertailu ---\n",
            "                     Accuracy  Precision (Spike)  Recall (Spike)  \\\n",
            "XGBoost                0.9607             0.6628          0.8862   \n",
            "LightGBM               0.9631             0.6807          0.8862   \n",
            "Logistic Regression    0.9470             0.5726          0.9409   \n",
            "\n",
            "                     F1-score (Spike)  ROC AUC  PR AUC  \n",
            "XGBoost                        0.7584   0.9881  0.8998  \n",
            "LightGBM                       0.7700   0.9881  0.8975  \n",
            "Logistic Regression            0.7119   0.9877  0.8849  \n",
            "\n",
            "--- Vertailuscripti päättyi ---\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAO-eFYctPeA",
        "outputId": "317eb9fe-9703-4f78-9cb5-9c001564a180"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}